{"ast":null,"code":"import { share, mergeMap, fromArray, take, buffer, fromPromise, empty, tap, map, concat, filter, merge } from \"wonka\";\nimport { stringifyVariables, createRequest, formatDocument } from \"urql/core\";\nimport { isWrappingType, Kind, valueFromASTUntyped, buildClientSchema, isNullableType, isNonNullType, isListType, GraphQLObjectType, GraphQLInterfaceType, GraphQLUnionType, visit, visitWithTypeInfo, TypeInfo, isCompositeType, isAbstractType } from \"graphql\";\n\nfunction m() {\n  return (m = Object.assign || function (a) {\n    for (var b = 1; b < arguments.length; b++) {\n      var d,\n          c = arguments[b];\n\n      for (d in c) {\n        Object.prototype.hasOwnProperty.call(c, d) && (a[d] = c[d]);\n      }\n    }\n\n    return a;\n  }).apply(this, arguments);\n}\n\nfunction t(a) {\n  return a.name.value;\n}\n\nfunction u(a) {\n  return void 0 !== a.alias ? a.alias.value : t(a);\n}\n\nfunction v(a) {\n  return void 0 !== a.selectionSet ? a.selectionSet.selections : [];\n}\n\nfunction aa(a) {\n  return void 0 !== (a = a.typeCondition) ? t(a) : null;\n}\n\nfunction ba(a) {\n  return isWrappingType(a) ? ba(a.ofType) : a || null;\n}\n\nvar ca = new Set(),\n    A = [];\n\nfunction B(a, b) {\n  var c = \"\";\n  b.kind === Kind.INLINE_FRAGMENT ? c = a ? 'Inline Fragment on \"' + a + '\"' : \"Inline Fragment\" : b.kind === Kind.OPERATION_DEFINITION ? c = (b.name ? '\"' + b.name.value + '\"' : \"Unnamed\") + \" \" + b.operation : b.kind === Kind.FRAGMENT_DEFINITION && (c = '\"' + b.name.value + '\" Fragment');\n  c && A.push(c);\n}\n\nfunction da() {\n  return A.length ? \"\\n(Caused At: \" + A.join(\", \") + \")\" : \"\";\n}\n\nfunction C(a, b, c) {\n  if (!a) {\n    throw a = b || \"Minfied Error #\" + c + \"\\n\", \"production\" !== process.env.NODE_ENV && (a += da()), (c = Error(a + \"\\nhttps://github.com/FormidableLabs/urql-exchange-graphcache/blob/master/docs/help.md#\" + c)).name = \"Graphcache Error\", c;\n  }\n}\n\nfunction D(a, b) {\n  ca.has(a) || (console.warn(a + da() + \"\\nhttps://github.com/FormidableLabs/urql-exchange-graphcache/blob/master/docs/help.md#\" + b), ca.add(a));\n}\n\nfunction F(a, b) {\n  return b ? a + \"(\" + stringifyVariables(b) + \")\" : a;\n}\n\nfunction ea(a) {\n  var b = a.indexOf(\"(\");\n  return -1 < b ? {\n    fieldKey: a,\n    fieldName: a.slice(0, b),\n    arguments: JSON.parse(a.slice(b + 1, -1))\n  } : {\n    fieldKey: a,\n    fieldName: a,\n    arguments: null\n  };\n}\n\nvar fa = \"production\" === process.env.NODE_ENV && \"undefined\" != typeof Promise ? Promise.prototype.then.bind(Promise.resolve()) : function (a) {\n  return setTimeout(a, 0);\n};\n\nfunction G() {\n  return Object.create(null);\n}\n\nvar H = null,\n    I = null,\n    J = null;\n\nfunction ha() {\n  return {\n    optimistic: G(),\n    base: new Map(),\n    keys: []\n  };\n}\n\nfunction K(a, b) {\n  H = a;\n  I = new Set();\n  J = b;\n  \"production\" !== process.env.NODE_ENV && (A.length = 0);\n}\n\nfunction L() {\n  var c = H;\n  !c.gcScheduled && 0 < c.gcBatch.size && (c.gcScheduled = !0, fa(function a() {\n    ia(c);\n  }));\n  c.storage && !c.persistenceScheduled && (c.persistenceScheduled = !0, fa(function b() {\n    c.storage.write(c.persistenceBatch);\n    c.persistenceScheduled = !1;\n    c.persistenceBatch = G();\n  }));\n  J = I = H = null;\n  \"production\" !== process.env.NODE_ENV && (A.length = 0);\n}\n\nfunction M() {\n  C(null !== I, \"production\" !== process.env.NODE_ENV ? \"Invalid Cache call: The cache may only be accessed or mutated duringoperations like write or query, or as part of its resolvers, updaters, or optimistic configs.\" : \"\", 2);\n  return I;\n}\n\nfunction ka(a, b, c, d) {\n  J ? (void 0 === a.optimistic[J] && (a.optimistic[J] = new Map(), a.keys.unshift(J)), a = a.optimistic[J]) : a = a.base;\n  var e = a.get(b);\n  void 0 === e && a.set(b, e = G());\n  void 0 !== d || J ? e[c] = d : delete e[c];\n}\n\nfunction la(a, b, c) {\n  for (var d = 0, e = a.keys.length; d < e; d++) {\n    var f = a.optimistic[a.keys[d]].get(b);\n\n    if (void 0 !== f && c in f) {\n      return f[c];\n    }\n  }\n\n  return void 0 !== (a = a.base.get(b)) ? a[c] : void 0;\n}\n\nfunction ma(a, b) {\n  var c = a.keys.indexOf(b);\n  -1 < c && (delete a.optimistic[b], a.keys.splice(c, 1));\n}\n\nfunction na(a, b, c, d) {\n  var e = void 0 !== b[c] ? b[c] : 0;\n  b = b[c] = e + d | 0;\n  void 0 !== a && (0 >= b ? a.add(c) : 0 >= e && 0 < b && a.delete(c));\n}\n\nfunction oa(a, b, c, d) {\n  if (\"string\" == typeof c) {\n    na(a, b, c, d);\n  } else if (Array.isArray(c)) {\n    for (var e = 0, f = c.length; e < f; e++) {\n      var g = c[e];\n      g && na(a, b, g, d);\n    }\n  }\n}\n\nfunction pa(a, b, c) {\n  if (void 0 !== c) {\n    for (var d in c) {\n      b.has(d) || (a.push(ea(d)), b.add(d));\n    }\n  }\n}\n\nfunction qa(a, b, c, d) {\n  pa(a, b, d.base.get(c));\n\n  for (var e = 0, f = d.keys.length; e < f; e++) {\n    pa(a, b, d.optimistic[d.keys[e]].get(c));\n  }\n}\n\nfunction ia(a) {\n  a.gcScheduled = !1;\n  a.gcBatch.forEach(function (b) {\n    if (0 >= (a.refCount[b] || 0)) {\n      for (var c in a.refLock) {\n        var d = a.refLock[c];\n\n        if (0 < (d[b] || 0)) {\n          return;\n        }\n\n        delete d[b];\n      }\n\n      delete a.refCount[b];\n      a.gcBatch.delete(b);\n\n      if (void 0 !== (c = a.records.base.get(b)) && (a.records.base.delete(b), a.storage)) {\n        for (var e in c) {\n          a.persistenceBatch[\"r|\" + b + \".\" + e] = void 0;\n        }\n      }\n\n      if (void 0 !== (e = a.links.base.get(b))) {\n        a.links.base.delete(b);\n\n        for (var f in e) {\n          a.storage && (a.persistenceBatch[\"l|\" + b + \".\" + f] = void 0), oa(a.gcBatch, a.refCount, e[f], -1);\n        }\n      }\n    } else {\n      a.gcBatch.delete(b);\n    }\n  });\n}\n\nfunction N(a, b) {\n  \"__typename\" !== b && (a !== H.queryRootKey ? I.add(a) : void 0 !== b && I.add(a + \".\" + b));\n}\n\nfunction O(a, b) {\n  N(a, b);\n  return la(H.records, a, b);\n}\n\nfunction P(a, b) {\n  N(a, b);\n  return la(H.links, a, b);\n}\n\nfunction Q(a, b, c) {\n  N(a, b);\n  ka(H.records, a, b, c);\n  H.storage && !J && (H.persistenceBatch[\"r|\" + a + \".\" + b] = c);\n}\n\nfunction ra(a, b, c) {\n  var d = H;\n\n  if (J) {\n    var e = d.refLock[J] || (d.refLock[J] = G());\n    var f = d.links.optimistic[J];\n  } else {\n    d.storage && (d.persistenceBatch[\"l|\" + a + \".\" + b] = c);\n    e = d.refCount;\n    f = d.links.base;\n    var g = d.gcBatch;\n  }\n\n  f = void 0 !== (f = void 0 !== f ? f.get(a) : void 0) ? f[b] : null;\n  N(a, b);\n  ka(d.links, a, b, c);\n  oa(g, e, f, -1);\n  oa(g, e, c, 1);\n}\n\nfunction sa(a, b, c, d) {\n  if (!b) {\n    return !1;\n  }\n\n  var e = aa(a);\n\n  if (b === e) {\n    return !0;\n  }\n\n  \"production\" !== process.env.NODE_ENV && D(\"Heuristic Fragment Matching: A fragment is trying to match against the `\" + b + \"` type, but the type condition is `\" + e + \"`. Since GraphQL allows for interfaces `\" + e + \"` may be aninterface.\\nA schema needs to be defined for this match to be deterministic, otherwise the fragment will be matched heuristically!\", 16);\n  return !v(a).some(function (a) {\n    if (a.kind !== Kind.FIELD) {\n      return !1;\n    }\n\n    a = F(t(a), R(a, d.variables));\n    return !(void 0 !== O(c, a) || void 0 !== P(c, a));\n  });\n}\n\nfunction S(a, b, c, d) {\n  this.typename = a;\n  this.entityKey = b;\n  this.context = d;\n  this.indexStack = [0];\n  this.selectionStack = [c];\n}\n\nS.prototype.next = function () {\n  for (; 0 !== this.indexStack.length;) {\n    var a = this.indexStack[this.indexStack.length - 1]++,\n        b = this.selectionStack[this.selectionStack.length - 1];\n\n    if (a >= b.length) {\n      this.indexStack.pop(), this.selectionStack.pop();\n    } else {\n      a = b[a];\n\n      a: {\n        b = this.context.variables;\n        var c = a.directives;\n\n        if (void 0 !== c) {\n          for (var d = 0, e = c.length; d < e; d++) {\n            var f = c[d],\n                g = t(f),\n                h = \"include\" === g;\n\n            if ((h || \"skip\" === g) && (f = f.arguments ? f.arguments[0] : null) && \"if\" === t(f) && (\"boolean\" == typeof (f = valueFromASTUntyped(f.value, b)) || null === f)) {\n              b = h ? !!f : !f;\n              break a;\n            }\n          }\n        }\n\n        b = !0;\n      }\n\n      if (b) {\n        if (a.kind !== Kind.FIELD) {\n          if (void 0 !== (a = a.kind !== Kind.INLINE_FRAGMENT ? this.context.fragments[t(a)] : a) && (\"production\" !== process.env.NODE_ENV && B(this.typename, a), void 0 !== this.context.schemaPredicates ? this.context.schemaPredicates.isInterfaceOfType(aa(a), this.typename) : sa(a, this.typename, this.entityKey, this.context))) {\n            this.indexStack.push(0), this.selectionStack.push(v(a));\n          }\n        } else if (\"__typename\" !== t(a)) {\n          return a;\n        }\n      }\n    }\n  }\n};\n\nfunction T(a) {\n  return void 0 === a ? null : a;\n}\n\nfunction ta(a, b, c) {\n  K(a.data, 0);\n  a = ua(a, b, c);\n  L();\n  return a;\n}\n\nfunction ua(a, b, c) {\n  var d = U(b.query),\n      e = {\n    dependencies: M()\n  },\n      f = v(d),\n      g = a.getRootKey(d.operation);\n  a = {\n    parentTypeName: g,\n    parentKey: g,\n    parentFieldKey: \"\",\n    fieldName: \"\",\n    variables: V(d, b.variables),\n    fragments: W(b.query),\n    result: e,\n    store: a,\n    schemaPredicates: a.schemaPredicates\n  };\n  \"production\" !== process.env.NODE_ENV && B(g, d);\n  g === a.store.getRootKey(\"query\") ? va(a, g, f, c) : wa(a, g, f, c);\n  return e;\n}\n\nfunction xa(a, b, c) {\n  K(a.data, c);\n  var d = U(b.query);\n  c = {\n    dependencies: M()\n  };\n  var e = a.getRootKey(\"mutation\"),\n      f = a.getRootKey(d.operation);\n  C(f === e, \"production\" !== process.env.NODE_ENV ? \"writeOptimistic(...) was called with an operation that is not a mutation.\\nThis case is unsupported and should never occur.\" : \"\", 10);\n  \"production\" !== process.env.NODE_ENV && B(f, d);\n  a = {\n    parentTypeName: e,\n    parentKey: e,\n    parentFieldKey: \"\",\n    fieldName: \"\",\n    variables: V(d, b.variables),\n    fragments: W(b.query),\n    result: c,\n    store: a,\n    schemaPredicates: a.schemaPredicates,\n    optimistic: !0\n  };\n  b = G();\n  d = new S(f, f, v(d), a);\n\n  for (var g; void 0 !== (g = d.next());) {\n    if (void 0 !== g.selectionSet) {\n      var h = t(g),\n          k = a.store.optimisticMutations[h];\n\n      if (void 0 !== k) {\n        a.fieldName = h;\n        ya(a, T(k = k((f = R(g, a.variables)) || G(), a.store, a)), v(g));\n        b[h] = k;\n        void 0 !== (g = a.store.updates[e][h]) && g(b, f || G(), a.store, a);\n      }\n    }\n  }\n\n  L();\n  return c;\n}\n\nfunction za(a, b, c, d) {\n  b = W(b);\n  var e = Object.keys(b);\n\n  if (void 0 === (e = b[e[0]])) {\n    return \"production\" !== process.env.NODE_ENV ? D(\"writeFragment(...) was called with an empty fragment.\\nYou have to call it with at least one fragment in your GraphQL document.\", 11) : void 0;\n  }\n\n  var f = e.typeCondition.name.value;\n  c = m({\n    __typename: f\n  }, c);\n  var g = a.keyOfEntity(c);\n\n  if (!g) {\n    return \"production\" !== process.env.NODE_ENV ? D(\"Can't generate a key for writeFragment(...) data.\\nYou have to pass an `id` or `_id` field or create a custom `keys` config for `\" + f + \"`.\", 12) : void 0;\n  }\n\n  \"production\" !== process.env.NODE_ENV && B(f, e);\n  va(a = {\n    parentTypeName: f,\n    parentKey: g,\n    parentFieldKey: \"\",\n    fieldName: \"\",\n    variables: d || {},\n    fragments: b,\n    result: {\n      dependencies: M()\n    },\n    store: a,\n    schemaPredicates: a.schemaPredicates\n  }, g, v(e), c);\n}\n\nfunction va(a, b, c, d) {\n  var e = b === a.store.getRootKey(\"query\") ? b : d.__typename;\n\n  if (\"string\" == typeof e) {\n    Q(b, \"__typename\", e);\n    c = new S(e, b, c, a);\n\n    for (var f; void 0 !== (f = c.next());) {\n      var g = t(f),\n          h = R(f, a.variables);\n      h = F(g, h);\n      var k = d[u(f)],\n          l = b + \".\" + h;\n\n      if (\"production\" !== process.env.NODE_ENV) {\n        if (void 0 === k) {\n          g = a.optimistic ? \"\\nYour optimistic result may be missing a field!\" : \"\";\n          f = void 0 === f.selectionSet ? \"scalar (number, boolean, etc)\" : \"selection set\";\n          \"production\" !== process.env.NODE_ENV && D(\"Invalid undefined: The field at `\" + h + \"` is `undefined`, but the GraphQL query expects a \" + f + \" for this field.\" + g, 13);\n          continue;\n        } else {\n          a.schemaPredicates && e && a.schemaPredicates.isFieldAvailableOnType(e, g);\n        }\n      }\n\n      void 0 === f.selectionSet ? Q(b, h, k) : (g = T(k), ra(b, h, f = Aa(a, l, v(f), g)));\n    }\n  }\n}\n\nfunction Aa(a, b, c, d) {\n  if (Array.isArray(d)) {\n    for (var e = Array(d.length), f = 0, g = d.length; f < g; f++) {\n      var h = Aa(a, b + \".\" + f, c, d[f]);\n      e[f] = h;\n    }\n\n    return e;\n  }\n\n  if (null === d) {\n    return null;\n  }\n\n  f = null !== (e = a.store.keyOfEntity(d)) ? e : b;\n  g = d.__typename;\n  void 0 !== a.store.keys[d.__typename] || null !== e || \"string\" != typeof g || g.endsWith(\"Connection\") || g.endsWith(\"Edge\") || \"PageInfo\" === g || \"production\" !== process.env.NODE_ENV && D(\"Invalid key: The GraphQL query at the field at `\" + b + \"` has a selection set, but no key could be generated for the data at this field.\\nYou have to request `id` or `_id` fields for all selection sets or create a custom `keys` config for `\" + g + \"`.\\nEntities without keys will be embedded directly on the parent entity. If this is intentional, create a `keys` config for `\" + g + \"` that always returns null.\", 15);\n  va(a, f, c, d);\n  return f;\n}\n\nfunction wa(a, b, c, d) {\n  var e = b === a.store.getRootKey(\"mutation\") || b === a.store.getRootKey(\"subscription\");\n  c = new S(b, b, c, a);\n\n  for (var f; void 0 !== (f = c.next());) {\n    var g = t(f),\n        h = R(f, a.variables);\n    var k = F(g, h);\n    k = b + \".\" + k;\n\n    if (void 0 !== f.selectionSet) {\n      ya(a, T(d[u(f)]), v(f));\n    }\n\n    e && (a.parentTypeName = b, a.parentKey = b, a.parentFieldKey = k, a.fieldName = g, void 0 !== (f = a.store.updates[b][g]) && f(d, h || G(), a.store, a));\n  }\n}\n\nfunction ya(a, b, c) {\n  if (Array.isArray(b)) {\n    for (var d = Array(b.length), e = 0, f = b.length; e < f; e++) {\n      d[e] = ya(a, b[e], c);\n    }\n\n    return d;\n  }\n\n  null !== b && (null !== (d = a.store.keyOfEntity(b)) ? va(a, d, c, b) : wa(a, b.__typename, c, b));\n}\n\nfunction X(a, b, c, d, e) {\n  var g,\n      f = this;\n  this.gcScheduled = !1;\n\n  this.gc = function () {\n    ia(f.data);\n    f.gcScheduled = !1;\n  };\n\n  this.keyOfField = F;\n  this.resolvers = b || {};\n  this.optimisticMutations = d || {};\n  this.keys = e || {};\n  this.schemaPredicates = a;\n  this.updates = {\n    Mutation: c && c.Mutation || {},\n    Subscription: c && c.Subscription || {}\n  };\n  a ? (c = (b = a.schema).getQueryType(), a = b.getMutationType(), b = b.getSubscriptionType(), this.rootFields = {\n    query: c = c ? c.name : \"Query\",\n    mutation: a = a ? a.name : \"Mutation\",\n    subscription: b = b ? b.name : \"Subscription\"\n  }, this.rootNames = ((g = {})[c] = \"query\", g[a] = \"mutation\", g[b] = \"subscription\", g)) : (this.rootFields = {\n    query: \"Query\",\n    mutation: \"Mutation\",\n    subscription: \"Subscription\"\n  }, this.rootNames = {\n    Query: \"query\",\n    Mutation: \"mutation\",\n    Subscription: \"subscription\"\n  });\n\n  this.data = function ja(a) {\n    return {\n      persistenceScheduled: !1,\n      persistenceBatch: G(),\n      gcScheduled: !1,\n      queryRootKey: a,\n      gcBatch: new Set(),\n      refCount: G(),\n      refLock: G(),\n      links: ha(),\n      records: ha(),\n      storage: null\n    };\n  }(this.getRootKey(\"query\"));\n}\n\nX.prototype.getRootKey = function (a) {\n  return this.rootFields[a];\n};\n\nX.prototype.keyOfEntity = function (a) {\n  var b = a.__typename,\n      c = a.id,\n      d = a._id;\n\n  if (!b) {\n    return null;\n  }\n\n  if (void 0 !== this.rootNames[b]) {\n    return b;\n  }\n\n  var e;\n  this.keys[b] ? e = this.keys[b](a) : null != c ? e = \"\" + c : null != d && (e = \"\" + d);\n  return e ? b + \":\" + e : null;\n};\n\nX.prototype.resolveFieldByKey = function (a, b) {\n  if (null === (a = null !== a && \"string\" != typeof a ? this.keyOfEntity(a) : a)) {\n    return null;\n  }\n\n  var c = O(a, b);\n  return void 0 !== c ? c : (b = P(a, b)) ? b : null;\n};\n\nX.prototype.resolve = function (a, b, c) {\n  return this.resolveFieldByKey(a, F(b, c));\n};\n\nX.prototype.invalidateQuery = function (a, b) {\n  !function Ba(a, b, c) {\n    if (\"Query\" !== b) {\n      var d = O(b, \"__typename\");\n\n      if (\"string\" != typeof d) {\n        return;\n      }\n\n      Q(b, \"__typename\", void 0);\n    } else {\n      d = b;\n    }\n\n    c = new S(d, b, c, a);\n\n    for (var e; void 0 !== (e = c.next());) {\n      var f = t(e),\n          g = F(f, R(e, a.variables));\n      \"production\" !== process.env.NODE_ENV && a.schemaPredicates && d && a.schemaPredicates.isFieldAvailableOnType(d, f);\n\n      if (void 0 === e.selectionSet) {\n        Q(b, g, void 0);\n      } else if (e = v(e), f = P(b, g), ra(b, g, void 0), Q(b, g, void 0), Array.isArray(f)) {\n        g = 0;\n\n        for (var h = f.length; g < h; g++) {\n          var k = f[g];\n          null !== k && Ba(a, k, e);\n        }\n      } else {\n        f && Ba(a, f, e);\n      }\n    }\n  }(b = {\n    variables: V(a = U((b = createRequest(a, b)).query), b.variables),\n    fragments: W(b.query),\n    store: this,\n    schemaPredicates: this.schemaPredicates\n  }, b.store.getRootKey(\"query\"), v(a));\n};\n\nX.prototype.inspectFields = function (a) {\n  if (null !== (a = null !== a && \"string\" != typeof a ? this.keyOfEntity(a) : a)) {\n    var b = H.links,\n        c = H.records,\n        d = [],\n        e = new Set();\n    N(a);\n    qa(d, e, a, b);\n    qa(d, e, a, c);\n    a = d;\n  } else {\n    a = [];\n  }\n\n  return a;\n};\n\nX.prototype.updateQuery = function (a, b) {\n  a = createRequest(a.query, a.variables);\n  null !== (b = b(this.readQuery(a))) && ua(this, a, b);\n};\n\nX.prototype.readQuery = function (a) {\n  return Ca(this, createRequest(a.query, a.variables)).data;\n};\n\nX.prototype.readFragment = function (a, b, c) {\n  a = W(a);\n  var d = Object.keys(a);\n\n  if (void 0 === (d = a[d[0]])) {\n    \"production\" !== process.env.NODE_ENV && D(\"readFragment(...) was called with an empty fragment.\\nYou have to call it with at least one fragment in your GraphQL document.\", 6), c = null;\n  } else {\n    var e = d.typeCondition.name.value;\n    \"string\" == typeof b || b.__typename || (b.__typename = e);\n    (b = \"string\" != typeof b ? this.keyOfEntity(m({\n      __typename: e\n    }, b)) : b) ? (\"production\" !== process.env.NODE_ENV && B(e, d), c = Y({\n      parentTypeName: e,\n      parentKey: b,\n      parentFieldKey: \"\",\n      fieldName: \"\",\n      variables: c || {},\n      fragments: a,\n      partial: !1,\n      store: this,\n      schemaPredicates: this.schemaPredicates\n    }, b, v(d), G()) || null) : (\"production\" !== process.env.NODE_ENV && D(\"Can't generate a key for readFragment(...).\\nYou have to pass an `id` or `_id` field or create a custom `keys` config for `\" + e + \"`.\", 7), c = null);\n  }\n\n  return c;\n};\n\nX.prototype.writeFragment = function (a, b, c) {\n  za(this, a, b, c);\n};\n\nfunction R(a, b) {\n  if (void 0 === a.arguments || 0 === a.arguments.length) {\n    return null;\n  }\n\n  for (var c = G(), d = 0, e = 0, f = a.arguments.length; e < f; e++) {\n    var g = a.arguments[e],\n        h = valueFromASTUntyped(g.value, b);\n    null != h && (c[t(g)] = h, d++);\n  }\n\n  return 0 < d ? c : null;\n}\n\nfunction V(a, b) {\n  if (void 0 === a.variableDefinitions) {\n    return {};\n  }\n\n  var c = b || {};\n  return a.variableDefinitions.reduce(function (a, b) {\n    var d = t(b.variable),\n        e = c[d];\n\n    if (void 0 === e) {\n      if (void 0 !== b.defaultValue) {\n        e = valueFromASTUntyped(b.defaultValue, c);\n      } else {\n        return a;\n      }\n    }\n\n    a[d] = e;\n    return a;\n  }, G());\n}\n\nfunction Z(a) {\n  this.schema = buildClientSchema(a);\n}\n\nZ.prototype.isFieldNullable = function (a, b) {\n  return void 0 === (a = Da(this.schema, a, b)) ? !1 : isNullableType(a.type);\n};\n\nZ.prototype.isListNullable = function (a, b) {\n  if (void 0 === (a = Da(this.schema, a, b))) {\n    return !1;\n  }\n\n  a = isNonNullType(a.type) ? a.type.ofType : a.type;\n  return isListType(a) && isNullableType(a.ofType);\n};\n\nZ.prototype.isFieldAvailableOnType = function (a, b) {\n  return !!Da(this.schema, a, b);\n};\n\nZ.prototype.isInterfaceOfType = function (a, b) {\n  if (!b || !a) {\n    return !1;\n  }\n\n  if (b === a) {\n    return !0;\n  }\n\n  var c = this.schema.getType(a),\n      d = this.schema.getType(b);\n\n  if (c instanceof GraphQLObjectType) {\n    return c === d;\n  }\n\n  C(c instanceof GraphQLInterfaceType || c instanceof GraphQLUnionType, \"production\" !== process.env.NODE_ENV ? \"Invalid Abstract type: The type `\" + a + \"` is not an Interface or Union type in the defined schema, but a fragment in the GraphQL document is using it as a type condition.\" : \"\", 5);\n  Ea(d, b);\n  return this.schema.isPossibleType(c, d);\n};\n\nfunction Da(a, b, c) {\n  Ea(a = a.getType(b), b);\n\n  if (void 0 === (a = a.getFields()[c])) {\n    \"production\" !== process.env.NODE_ENV && D(\"Invalid field: The field `\" + c + \"` does not exist on `\" + b + \"`, but the GraphQL document expects it to exist.\\nTraversal will continue, however this may lead to undefined behavior!\", 4);\n  } else {\n    return a;\n  }\n}\n\nfunction Ea(a, b) {\n  C(a instanceof GraphQLObjectType, \"production\" !== process.env.NODE_ENV ? \"Invalid Object type: The type `\" + b + \"` is not an object in the defined schema, but the GraphQL document is traversing it.\" : \"\", 3);\n}\n\nfunction Fa(a) {\n  return a.kind === Kind.FRAGMENT_DEFINITION;\n}\n\nfunction Ga(a) {\n  return a.kind === Kind.OPERATION_DEFINITION;\n}\n\nfunction U(a) {\n  C(!!(a = a.definitions.find(Ga)), \"production\" !== process.env.NODE_ENV ? \"Invalid GraphQL document: All GraphQL documents must contain an OperationDefinitionnode for a query, subscription, or mutation.\" : \"\", 1);\n  return a;\n}\n\nfunction Ha(a, b) {\n  a[t(b)] = b;\n  return a;\n}\n\nfunction W(a) {\n  return a.definitions.filter(Fa).reduce(Ha, {});\n}\n\nfunction Ia(a, b, c) {\n  K(a.data, 0);\n  a = Ca(a, b, c);\n  L();\n  return a;\n}\n\nfunction Ca(a, b, c) {\n  var d = U(b.query),\n      e = a.getRootKey(d.operation),\n      f = v(d);\n  a = {\n    parentTypeName: e,\n    parentKey: e,\n    parentFieldKey: \"\",\n    fieldName: \"\",\n    variables: V(d, b.variables),\n    fragments: W(b.query),\n    partial: !1,\n    store: a,\n    schemaPredicates: a.schemaPredicates\n  };\n  \"production\" !== process.env.NODE_ENV && B(e, d);\n  c = c || G();\n  c = e !== a.store.getRootKey(\"query\") ? Ja(a, e, f, c) : Y(a, e, f, c);\n  return {\n    dependencies: M(),\n    partial: void 0 === c ? !1 : a.partial,\n    data: void 0 === c ? null : c\n  };\n}\n\nfunction Ja(a, b, c, d) {\n  if (\"string\" != typeof d.__typename) {\n    return d;\n  }\n\n  b = new S(b, b, c, a);\n  (c = G()).__typename = d.__typename;\n\n  for (var e; void 0 !== (e = b.next());) {\n    var f = u(e),\n        g = d[f];\n    void 0 !== e.selectionSet && null !== g ? (g = T(g), c[f] = Ka(a, v(e), g)) : c[f] = g;\n  }\n\n  return c;\n}\n\nfunction Ka(a, b, c) {\n  if (Array.isArray(c)) {\n    for (var d = Array(c.length), e = 0, f = c.length; e < f; e++) {\n      d[e] = Ka(a, b, c[e]);\n    }\n\n    return d;\n  }\n\n  if (null === c) {\n    return null;\n  }\n\n  return null !== (d = a.store.keyOfEntity(c)) ? void 0 === (a = Y(a, d, b, G())) ? null : a : Ja(a, c.__typename, b, c);\n}\n\nfunction Y(a, b, c, d) {\n  var e = a.store,\n      f = a.schemaPredicates,\n      g = b === e.getRootKey(\"query\"),\n      h = g ? b : O(b, \"__typename\");\n\n  if (\"string\" == typeof h) {\n    d.__typename = h;\n    c = new S(h, b, c, a);\n\n    for (var k, l = !1, p = !1; void 0 !== (k = c.next());) {\n      var r = t(k),\n          q = R(k, a.variables),\n          z = u(k),\n          E = F(r, q),\n          w = O(b, E),\n          n = b + \".\" + E;\n      \"production\" !== process.env.NODE_ENV && f && h && f.isFieldAvailableOnType(h, r);\n      var x = void 0,\n          y = e.resolvers[h];\n\n      if (void 0 !== y && \"function\" == typeof y[r]) {\n        if (a.parentTypeName = h, a.parentKey = b, a.parentFieldKey = n, a.fieldName = r, void 0 !== w && (d[z] = w), x = y[r](d, q || G(), e, a), void 0 !== k.selectionSet && (x = La(a, h, r, n, v(k), d[z] || G(), x)), void 0 !== f && null === x && !f.isFieldNullable(h, r)) {\n          return;\n        }\n      } else {\n        void 0 === k.selectionSet ? x = w : void 0 !== (q = P(b, E)) ? x = Ma(a, q, h, r, v(k), d[z]) : \"object\" == typeof w && null !== w && (x = w);\n      }\n\n      if (void 0 === x && void 0 !== f && f.isFieldNullable(h, r)) {\n        p = !0, d[z] = null;\n      } else {\n        if (void 0 === x) {\n          return;\n        }\n\n        l = !0;\n        d[z] = x;\n      }\n    }\n\n    p && (a.partial = !0);\n    return g && p && !l ? void 0 : d;\n  }\n}\n\nfunction La(a, b, c, d, e, f, g) {\n  if (Array.isArray(g)) {\n    var h = a.schemaPredicates;\n    h = void 0 === h || h.isListNullable(b, c);\n\n    for (var k = Array(g.length), l = 0, p = g.length; l < p; l++) {\n      var r = La(a, b, c, d + \".\" + l, e, void 0 !== f ? f[l] : void 0, g[l]);\n\n      if (void 0 !== r || h) {\n        k[l] = void 0 !== r ? r : null;\n      } else {\n        return;\n      }\n    }\n\n    return k;\n  }\n\n  if (null == g) {\n    return g;\n  }\n\n  if (\"string\" == typeof g || \"object\" == typeof g && \"string\" == typeof g.__typename) {\n    b = void 0 === f ? G() : f;\n\n    if (\"string\" == typeof g) {\n      a = Y(a, g, e, b);\n    } else {\n      a: if (c = a.schemaPredicates, d = a.store.keyOfEntity(g) || d, h = g.__typename, f = O(d, \"__typename\") || h, \"string\" != typeof f || h && f !== h) {\n        \"production\" !== process.env.NODE_ENV && D(\"Invalid resolver data: The resolver at `\" + d + \"` returned an invalid typename that could not be reconciled with the cache.\", 8), a = void 0;\n      } else {\n        b.__typename = f;\n        e = new S(f, d, e, a);\n\n        for (l = k = !1; void 0 !== (h = e.next());) {\n          p = t(h);\n          r = u(h);\n          var q = F(p, R(h, a.variables)),\n              z = d + \".\" + q,\n              E = O(d, q),\n              w = g[p];\n          \"production\" !== process.env.NODE_ENV && c && f && c.isFieldAvailableOnType(f, p);\n          var n = void 0;\n          void 0 !== w && void 0 === h.selectionSet ? n = w : void 0 === h.selectionSet ? n = E : void 0 !== w ? n = La(a, f, p, z, v(h), b[r], w) : void 0 !== (q = P(d, q)) ? n = Ma(a, q, f, p, v(h), b[r]) : \"object\" == typeof E && null !== E && (n = E);\n\n          if (void 0 === n && void 0 !== c && c.isFieldNullable(f, p)) {\n            l = !0, b[r] = null;\n          } else if (void 0 === n) {\n            a = void 0;\n            break a;\n          } else {\n            k = !0, b[r] = n;\n          }\n        }\n\n        l && (a.partial = !0);\n        a = k ? b : void 0;\n      }\n    }\n\n    return a;\n  }\n\n  \"production\" !== process.env.NODE_ENV && D(\"Invalid resolver value: The field at `\" + d + \"` is a scalar (number, boolean, etc), but the GraphQL query expects a selection set for this field.\", 9);\n}\n\nfunction Ma(a, b, c, d, e, f) {\n  if (Array.isArray(b)) {\n    var g = a.schemaPredicates;\n    g = void 0 !== g && g.isListNullable(c, d);\n\n    for (var h = Array(b.length), k = 0, l = b.length; k < l; k++) {\n      var p = Ma(a, b[k], c, d, e, void 0 !== f ? f[k] : void 0);\n\n      if (void 0 !== p || g) {\n        h[k] = void 0 !== p ? p : null;\n      } else {\n        return;\n      }\n    }\n\n    return h;\n  }\n\n  return null === b ? null : Y(a, b, e, void 0 === f ? G() : f);\n}\n\nfunction Na(a, b) {\n  return m(m({}, a), {\n    context: m(m({}, a.context), {\n      meta: m(m({}, a.context.meta), {\n        cacheOutcome: b\n      })\n    })\n  });\n}\n\nfunction Oa(a) {\n  return m(m({}, a), {\n    query: formatDocument(a.query)\n  });\n}\n\nfunction Pa(a) {\n  return \"query\" === a.operationName && \"network-only\" !== a.context.requestPolicy;\n}\n\nfunction Qa(a, b) {\n  return m(m({}, a), {\n    context: m(m({}, a.context), {\n      requestPolicy: b\n    })\n  });\n}\n\nfunction Ra(a) {\n  return Pa(a);\n}\n\nfunction Sa(a) {\n  return Na(a.operation, a.outcome);\n}\n\nfunction Ta(a) {\n  return \"miss\" === a.outcome;\n}\n\nfunction Ua(a) {\n  return \"miss\" !== a.outcome;\n}\n\nfunction Va(a) {\n  return !Pa(a);\n}\n\nfunction Ya(a) {\n  return \"populate\" !== t(a);\n}\n\nfunction Za(a, b) {\n  \"FragmentDefinition\" === b.kind && a.add(b.name.value);\n  return a;\n}\n\nfunction $a(a, b, c, d) {\n  function e(a, b) {\n    if (!(b = c[b.name])) {\n      return a;\n    }\n\n    for (var e = 0, f = b.length; e < f; e++) {\n      for (var l = b[e].fragment, p = t(l), w = ab(l), n = 0, x = w.length; n < x; n++) {\n        var y = w[n];\n        k.has(y) || (g[y] = d[y]);\n      }\n\n      h[p] = l;\n      a.push({\n        kind: Kind.FRAGMENT_SPREAD,\n        name: Xa(p)\n      });\n    }\n\n    return a;\n  }\n\n  var f = new TypeInfo(a),\n      g = G(),\n      h = G(),\n      k = new Set();\n  return visit(b, visitWithTypeInfo(f, {\n    Field: {\n      enter: function (b) {\n        if (b.directives) {\n          var c = b.directives.filter(Ya);\n\n          if (c.length !== b.directives.length) {\n            var d = ba(f.getType());\n            isCompositeType(d) ? d = isAbstractType(d) ? a.getPossibleTypes(d) : [d] : (\"production\" !== process.env.NODE_ENV && D(\"Invalid type: The type ` + type + ` is used with @populate but does not exist.\", 17), d = []);\n            d = d.reduce(e, []);\n            var g = v(b);\n            d = 0 !== g.length + d.length ? d.concat(g) : [{\n              kind: Kind.FIELD,\n              name: Xa(\"__typename\")\n            }];\n            return m(m({}, b), {\n              directives: c,\n              selectionSet: {\n                kind: Kind.SELECTION_SET,\n                selections: d\n              }\n            });\n          }\n        }\n      }\n    },\n    Document: {\n      enter: function (a) {\n        a.definitions.reduce(Za, k);\n      },\n      leave: function (a) {\n        var c,\n            b = [].concat(a.definitions);\n\n        for (c in h) {\n          b.push(h[c]);\n        }\n\n        for (var d in g) {\n          b.push(g[d]);\n        }\n\n        return m(m({}, a), {\n          definitions: b\n        });\n      }\n    }\n  }));\n}\n\nfunction Xa(a) {\n  return {\n    kind: Kind.NAME,\n    value: a\n  };\n}\n\nfunction ab(a) {\n  var b = [];\n  visit(a, {\n    FragmentSpread: function (a) {\n      b.push(t(a));\n    }\n  });\n  return b;\n}\n\nvar Store = X;\n\nvar cacheExchange = function (a) {\n  return function (b) {\n    function c(a) {\n      var b = a.operation,\n          c = a.error,\n          d = a.extensions,\n          f = \"query\" === b.operationName,\n          y = a.data,\n          k = b.key;\n\n      if (w.has(k)) {\n        w.delete(k);\n        var z = q.data;\n        delete z.refLock[k];\n        ma(z.records, k);\n        ma(z.links, k);\n      }\n\n      if (null != y) {\n        var l = ta(q, b, y).dependencies;\n\n        if (f) {\n          var n = Ia(q, b);\n          y = n.data;\n          n = n.dependencies;\n        } else {\n          y = Ia(q, b, y).data;\n        }\n      }\n\n      h(k = new Set(), l);\n      f && h(k, n);\n      g(a.operation, k);\n      f && void 0 !== n && e(a.operation, n);\n      return {\n        data: y,\n        error: c,\n        extensions: d,\n        operation: b\n      };\n    }\n\n    function d(a) {\n      var b = Ia(q, a),\n          c = b.data,\n          d = b.dependencies;\n      b = b.partial;\n      null === c ? d = \"miss\" : (e(a, d), d = b && \"cache-only\" !== a.context.requestPolicy ? \"partial\" : \"hit\");\n      return {\n        outcome: d,\n        operation: a,\n        data: c\n      };\n    }\n\n    function e(a, b) {\n      b.forEach(function (b) {\n        (x[b] || (x[b] = [])).push(a.key);\n        n.has(a.key) || n.set(a.key, \"network-only\" === a.context.requestPolicy ? Qa(a, \"cache-and-network\") : a);\n      });\n    }\n\n    function f(a) {\n      if (\"mutation\" === a.operationName && \"network-only\" !== a.context.requestPolicy) {\n        var b = a.key,\n            c = xa(q, a, b).dependencies;\n        0 !== c.size && (w.add(b), h(b = new Set(), c), g(a, b));\n      }\n    }\n\n    function g(a, b) {\n      b.forEach(function (b) {\n        if (b !== a.key) {\n          var c = n.get(b);\n          void 0 !== c && (n.delete(b), r.reexecuteOperation(Qa(c, \"cache-first\")));\n        }\n      });\n    }\n\n    function h(a, b) {\n      void 0 !== b && b.forEach(function c(b) {\n        var c = x[b];\n\n        if (void 0 !== c) {\n          x[b] = [];\n          b = 0;\n\n          for (var d = c.length; b < d; b++) {\n            a.add(c[b]);\n          }\n        }\n      });\n    }\n\n    function l(a) {\n      var b = a.operation,\n          c = a.outcome,\n          d = b.context.requestPolicy;\n      a = {\n        operation: Na(b, c),\n        data: a.data,\n        error: a.error,\n        extensions: a.extensions\n      };\n\n      if (\"cache-and-network\" === d || \"cache-first\" === d && \"partial\" === c) {\n        a.stale = !0, r.reexecuteOperation(Qa(b, \"network-only\"));\n      }\n\n      return a;\n    }\n\n    var p = b.forward,\n        r = b.client;\n    a || (a = {});\n    var q = new X(a.schema ? new Z(a.schema) : void 0, a.resolvers, a.updates, a.optimistic, a.keys);\n\n    if (a.storage) {\n      var z = a.storage;\n      var E = z.read().then(function k(a) {\n        var b = q.data,\n            c = z;\n        K(b, 0);\n\n        for (var d in a) {\n          var e = d.indexOf(\".\"),\n              f = d.slice(2, e);\n          e = d.slice(e + 1);\n\n          switch (d.charCodeAt(0)) {\n            case 108:\n              ra(f, e, a[d]);\n              break;\n\n            case 114:\n              Q(f, e, a[d]);\n          }\n        }\n\n        L();\n        b.storage = c;\n      });\n    }\n\n    var w = new Set(),\n        n = new Map(),\n        x = G();\n    return function (a) {\n      a = share(a);\n      var b = E ? mergeMap(fromArray)(take(1)(buffer(fromPromise(E))(a))) : empty;\n      a = share(tap(f)(map(Oa)(concat([b, a]))));\n      var e = share(map(d)(filter(Ra)(a)));\n      b = map(Sa)(filter(Ta)(e));\n      e = map(l)(filter(Ua)(e));\n      a = map(c)(p(merge([filter(Va)(a), b])));\n      return merge([a, e]);\n    };\n  };\n};\n\nvar clearDataState = L;\nvar initDataState = K;\n\nvar populateExchange = function (a) {\n  var b = a.schema;\n  return function (a) {\n    function c(a) {\n      \"teardown\" === a.operationName && p.delete(a.key);\n    }\n\n    function e(a) {\n      var b = a.key,\n          c = a.query;\n\n      if (\"query\" === a.operationName && (p.add(b), !l.has(b))) {\n        l.add(b);\n\n        a = function Wa(a, b) {\n          var c = [],\n              d = [],\n              e = new TypeInfo(a);\n          visit(b, visitWithTypeInfo(e, {\n            Field: function (a) {\n              if (a.selectionSet) {\n                var b = ba(e.getType());\n                C(b && !isAbstractType(b), \"production\" !== process.env.NODE_ENV ? \"Invalid TypeInfo state: Found no flat schema type when one was expected.\" : \"\", 18);\n                b = b.toString();\n                d.push({\n                  kind: Kind.FRAGMENT_DEFINITION,\n                  typeCondition: {\n                    kind: Kind.NAMED_TYPE,\n                    name: Xa(b)\n                  },\n                  name: Xa(b + \"_PopulateFragment_\"),\n                  selectionSet: a.selectionSet\n                });\n              }\n            },\n            FragmentDefinition: function (a) {\n              c.push(a);\n            }\n          }));\n          return [c, d];\n        }(k, c);\n\n        c = a[0];\n        a = a[1];\n\n        for (var d = 0, e = c.length; d < e; d++) {\n          var f = c[d];\n          r[t(f)] = f;\n        }\n\n        c = 0;\n\n        for (d = a.length; c < d; c++) {\n          f = t((e = a[c]).typeCondition), f = q[f] || (q[f] = []), e.name.value += f.length, f.push({\n            key: b,\n            fragment: e\n          });\n        }\n      }\n    }\n\n    function f(a) {\n      if (\"mutation\" !== a.operationName) {\n        return a;\n      }\n\n      var c,\n          b = G();\n\n      for (c in q) {\n        b[c] = q[c].filter(g);\n      }\n\n      return m(m({}, a), {\n        query: $a(k, a.query, b, r)\n      });\n    }\n\n    function g(a) {\n      return p.has(a.key);\n    }\n\n    var h = a.forward,\n        k = buildClientSchema(b),\n        l = new Set(),\n        p = new Set(),\n        r = G(),\n        q = G();\n    return function (a) {\n      return h(map(f)(tap(c)(tap(e)(a))));\n    };\n  };\n};\n\nvar query = Ia;\nvar read = Ca;\nvar write = ta;\nvar writeFragment = za;\nvar writeOptimistic = xa;\nexport { Store, cacheExchange, clearDataState, initDataState, populateExchange, query, read, write, writeFragment, writeOptimistic };","map":{"version":3,"sources":["../src/ast/node.ts","../src/helpers/help.ts","../src/store/keys.ts","../src/store/timing.ts","../src/store/data.ts","../src/operations/shared.ts","../src/ast/traversal.ts","../src/operations/write.ts","../src/store/store.ts","../src/operations/invalidate.ts","../src/operations/query.ts","../src/ast/variables.ts","../src/ast/schemaPredicates.ts","../src/cacheExchange.ts","../src/populateExchange.ts"],"names":["node","Kind","type","unwrapType","helpUrl","const","cache","Set","currentDebugStack","typename","identifier","invariant","condition","message","code","process","errorMessage","getDebugOutput","error","Error","console","fieldName","args","stringifyVariables","fieldKey","parenIndex","arguments","JSON","key","owner","defer","Promise","fn","let","currentData","currentDependencies","currentOptimisticKey","optimistic","makeDict","base","Map","keys","data","optimisticKey","gc","queryRootKey","persistenceScheduled","persistenceBatch","gcScheduled","gcBatch","refCount","refLock","links","makeNodeMap","records","storage","map","entityKey","value","undefined","keymap","entity","i","l","index","by","count","newCount","link","updateRCForEntity","Array","fieldInfos","seenFieldKeys","fieldInfoOfKey","extractNodeFields","updateRCForLink","linkNode","updateDependencies","readRecord","readLink","prevLinkNode","prevLink","clearOptimisticNodes","dotIndex","writeLink","writeRecord","clearDataState","ctx","typeCondition","getTypeCondition","warn","getSelectionSet","keyOfField","getName","getFieldArguments","SelectionIterator","select","this","shouldInclude","variables","fragmentNode","isFragmentHeuristicallyMatching","x","doc","operation","isFragmentNode","directives","directive","name","isInclude","arg","valueFromASTUntyped","vars","store","request","initDataState","startWrite","getMainOperation","result","dependencies","getCurrentDependencies","operationName","parentTypeName","parentKey","parentFieldKey","normalizeVariables","fragments","getFragments","schemaPredicates","pushDebugNode","writeSelection","writeRoot","mutationRootKey","iter","resolver","ensureData","resolverValue","updater","fieldArgs","query","names","Object","fragment","_extends","__typename","writeData","InMemoryData","fieldValue","getFieldAlias","advice","expected","fieldData","writeField","newData","isRootField","writeRootField","Store","resolvers","updates","optimisticMutations","queryType","mutationType","schema","subscriptionType","queryName","mutationName","subscriptionName","id","_id","field","createRequest","input","output","dataFragment","fieldSelect","childLink","invalidateSelection","read","rootKey","rootSelect","partial","readRoot","readSelection","originalData","fieldAlias","readRootField","isQuery","hasFields","hasPartials","dataFieldValue","resolveResolverResult","resolveLink","resolvedTypename","resultValue","prevData","childResult","isListNullable","readResolverResult","newLink","argsSize","def","SchemaPredicates","buildClientSchema","getField","isNullableType","isNonNullType","ofType","fieldname","abstractType","objectType","object","expectObjectType","op","outcome","context","meta","cacheOutcome","formatDocument","requestPolicy","opts","ref","hydration","entries","optimisticKeys","ops","deps","pendingOperations","dep","client","toRequestPolicy","writeOptimistic","collectPendingOperations","executePendingOperations","delete","write","queryDependencies","writeDependencies","ops$","sharedOps$","share","bufferedOps$","buffer","fromPromise","take","mergeMap","empty","concat","tap","cache$","inputOps$","filter","res","policy","addCacheOutcome","extensions","forward","merge","isCacheableQuery","cacheOps$","result$","cacheResult$","ogSchema","parsedOperations","activeOperations","userFragments","activeTypeFragments","activeSelections","s","addFragmentsToQuery","c","extractSelectionsFromQuery","current","extractedFragments","newFragments","typeInfo","TypeInfo","visitWithTypeInfo","Field","kind","nameNode","selectionSet","FragmentDefinition","requiredUserFragments","additionalFragments","existingFragmentsForQuery","enter","d","possibleTypes","p","possibleType","typeFrags","fragmentName","usedFragments","getUsedFragments","j","existingSelections","newSelections","selections","Document","set","definition","leave","definitions","isAbstractType","FragmentSpread","f"],"mappings":";;uFAuBEA,a,EAA2BA,U,EAAAA,iB,EAAAA,oB,EAAAA,gB,EAMOA,K,EAAAA,iB,EAAAA,Q,EAAAA,e,EAAAA,c,QAMlB,S;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;YAWhBE,C,EAAAA;wBAEmBA,C,IACVC,EAAAA,CAAWD,CAAAA,CAAAA,MAAXC,C,GAGFD,CAAAA,IAAQ,I;;;ACxCjBG,IAAMC,EAAAA,GAAQ,IAAIC,GAAJ,EAAdF;AAAAA,IAEaG,CAAAA,GAA8B,EAF3CH;;WAI8BI,C,EAAyBT,C,EAAAA;MACjDU,CAAAA,GAAa,E;aACCT,IAAAA,CAAAA,e,GAChBS,CAAAA,GAAaD,CAAAA,GAAAA,yBACcA,CADdA,GACcA,GADdA,GAET,iB,GACKT,CAAAA,CAAAA,IAAAA,KAAcC,IAAAA,CAAAA,oBAAdD,GAETU,CAAAA,GAAAA,CADaV,CAAAA,CAAAA,IAAAA,GAAAA,MAAgBA,CAAAA,CAAAA,IAAAA,CAAAA,KAAhBA,GAAgBA,GAAhBA,GAAqC,SAClDU,IADkD,GAClDA,GAAwBV,CAAAA,CAAAA,SAFfA,GAGAA,CAAAA,CAAAA,IAAAA,KAAcC,IAAAA,CAAAA,mBAAdD,KACTU,CAAAA,GAAa,MAAIV,CAAAA,CAAAA,IAAAA,CAAAA,KAAJ,GAAIA,YADRA,C;OAKTQ,CAAAA,CAAAA,IAAAA,CAAuBE,CAAvBF,C;;;;oBAME,mBAAmBA,CAAAA,CAAAA,IAAAA,CAAuB,IAAvBA,CAAnB,GAAkD,G,GAClD,E;;;AAENG,SAAAA,CAAAA,CACEC,CADFD,EAEEE,CAFFF,EAGEG,CAHFH,EAGEG;OAEKF,C,EAAAA;cACgBC,CAAAA,IAAW,oBAAoBC,CAApB,GAA2B,I,EAC5B,iBAAzBC,OAAAA,CAAAA,GAAAA,CAAAA,QAAyB,KAC3BC,CAAAA,IAAgBC,EAAAA,EADW,C,GAIvBC,CAAAA,GAAYC,KAAAA,CAAMH,CAAAA,GAvC1BZ,wFAuC0BY,GAAyBF,CAA/BK,C,EAA+BL,I,GACpC,kB,EACPI,C;;;;WAIWL,C,EAAiBC,C,EAAAA;AAC/BR,EAAAA,EAAAA,CAAAA,GAAAA,CAAUO,CAAVP,MACHc,OAAAA,CAAAA,IAAAA,CAAaP,CAAAA,GAAUI,EAAAA,EAAVJ,GA/CfT,wFA+CeS,GAAuCC,CAApDM,GACAd,EAAAA,CAAAA,GAAAA,CAAUO,CAAVP,CAFGA;;;WCtDoBe,C,EAAmBC,C,EAAAA;aAClCD,CAAAA,GAAAA,GAAAA,GAAaE,kBAAAA,CAAmBD,CAAnBC,CAAbF,GAAgCC,G,GAAWD,C;;;YAExBG,C,EAAAA;MACvBC,CAAAA,GAAaD,CAAAA,CAAAA,OAAAA,CAAiB,GAAjBA,C;cACfC,C,GACK;cACLD,CADK;AAELH,IAAAA,SAAAA,EAAWG,CAAAA,CAAAA,KAAAA,CAAe,CAAfA,EAAkBC,CAAlBD,CAFN;AAGLE,IAAAA,SAAAA,EAAWC,IAAAA,CAAAA,KAAAA,CAAWH,CAAAA,CAAAA,KAAAA,CAAeC,CAAAA,GAAa,CAA5BD,EAA4B,CAAA,CAA5BA,CAAXG;AAHN,G,GAMA;cACLH,CADK;AAELH,IAAAA,SAAAA,EAAWG,CAFN;AAGLE,IAAAA,SAAAA,EAAW;AAHN,G;;;ACfJrB,IAAMyB,EAAAA,GACc,iBAAzBf,OAAAA,CAAAA,GAAAA,CAAAA,QAAyB,IAAmC,eAAA,OAAA,OAAnC,GACrBgB,OAAAA,CAAAA,SAAAA,CAAAA,IAAAA,CAAAA,IAAAA,CAA4BA,OAAAA,CAAAA,OAAAA,EAA5BA,CADqB,GACOA,UAC5BC,CAD4BD,EAC5BC;oBAAiBA,C,EAAI,C;CAHpB3B;;;uBCkC0C,I;;;AAEjD4B,IAAIC,CAAAA,GAAmC,IAAvCD;AAAAA,IACIE,CAAAA,GAA0C,IAD9CF;AAAAA,IAEIG,CAAAA,GAAsC,IAF1CH;;;SAI0C;AACxCI,IAAAA,UAAAA,EAAYC,CAAAA,EAD4B;AAExCC,IAAAA,IAAAA,EAAM,IAAIC,GAAJ,EAFkC;AAGxCC,IAAAA,IAAAA,EAAM;AAHkC,G;;;WAQxCC,C,EACAC,C,EAAAA;AAEAT,EAAAA,CAAAA,GAAcQ,CAAdR;MACsB,IAAI3B,GAAJ,E;MACCoC,C;mBACnB5B,OAAAA,CAAAA,GAAAA,CAAAA,Q,KACFP,CAAAA,CAAAA,MAAAA,GAA2B,C;;;;MAMvBkC,CAAAA,GAAOR,C;GAERQ,CAAAA,CAAAA,W,IAAwC,IAApBA,CAAAA,CAAAA,OAAAA,CAAAA,I,KACvBA,CAAAA,CAAAA,WAAAA,GAAAA,CAAmB,CAAnBA,EACAZ,EAAAA,CAAAA,SAAAA,CAAAA,GAAAA;AACEc,IAAAA,EAAAA,CAAGF,CAAHE,CAAAA;GADFd,C;gBAKmBY,CAAAA,CAAAA,oB,KACnBA,CAAAA,CAAAA,oBAAAA,GAAAA,CAA4B,CAA5BA,EACAZ,EAAAA,CAAAA,SAAAA,CAAAA,GAAAA;AACEY,IAAAA,CAAAA,CAAAA,OAAAA,CAAAA,KAAAA,CAAoBA,CAAAA,CAAAA,gBAApBA;8BAC4B,C;yBACJJ,CAAAA,E;GAH1BR,C;MAQFK,CAAAA,GADAD,CAAAA,GAAc,I;mBAGVnB,OAAAA,CAAAA,GAAAA,CAAAA,Q,KACFP,CAAAA,CAAAA,MAAAA,GAA2B,C;;;;AAM7BG,EAAAA,CAAAA,CAC0B,SAAxBwB,CADFxB,EACEwB,iBAAAA,OAAAA,CAAAA,GAAAA,CAAAA,QAAAA,GACA,mKADAA,GACA,EAFFxB,EAKE,CALFA,CAAAA;;;;YA0BA6C,C,EACAC,C,EACAjC,C,EACAkC,C,EAAAA;AAKItB,EAAAA,CAAAA,IAAAA,KAG2CuB,CAH3CvB,KAGEoB,CAAAA,CAAAA,UAAAA,CAAepB,CAAfoB,CAHFpB,KAIAoB,CAAAA,CAAAA,UAAAA,CAAepB,CAAfoB,IAAuC,IAAIhB,GAAJ,EAAvCgB,EACAA,CAAAA,CAAAA,IAAAA,CAAAA,OAAAA,CAAiBpB,CAAjBoB,CALApB,GAQFwB,CAAAA,GAASJ,CAAAA,CAAAA,UAAAA,CAAepB,CAAfoB,CARPpB,IAUFwB,CAAAA,GAASJ,CAAAA,CAAAA,IAVPpB;MAcAyB,CAAAA,GAASD,CAAAA,CAAAA,GAAAA,CAAWH,CAAXG,C;aACTC,C,IACFD,CAAAA,CAAAA,GAAAA,CAAWH,CAAXG,EAAuBC,CAAAA,GAASvB,CAAAA,EAAhCsB,C;aAMEF,C,IAAwBtB,C,GAG1ByB,CAAAA,CAAOrC,CAAPqC,CAAAA,GAAmBH,C,GAAAA,OAFZG,CAAAA,CAAOrC,CAAPqC,C;;;YAQTL,C,EACAC,C,EACAjC,C,EAAAA;OACe,IAENsC,CAAAA,GAAI,CAFE,EAECC,CAAAA,GAAIP,CAAAA,CAAAA,IAAAA,CAAAA,M,EAAiBM,CAAAA,GAAIC,C,EAAGD,CAAAA,E,EAAK;QAEzC9D,CAAAA,GADawD,CAAAA,CAAAA,UAAAA,CAAeA,CAAAA,CAAAA,IAAAA,CAASM,CAATN,CAAfA,EAAwBM,GAAxBN,CACSC,CADTD,C;;aAGNG,C,KAAT3D,C,IAAsBwB,CAAAA,IAAAA,C,EAAAA;eACZA,C;;;;qBAKVxB,CAAAA,GAAOwD,CAAAA,CAAAA,IAAAA,CAAAA,GAAAA,CAAaC,CAAbD,C,IACexD,CAAAA,CAAKwB,CAALxB,C,GAAKwB,KAAYmC,C;;;YAIdH,C,EAAiBb,C,EAAAA;MAE1CqB,CAAAA,GAAQR,CAAAA,CAAAA,IAAAA,CAAAA,OAAAA,CAAiBb,CAAjBa,C;OACVQ,C,KAAAA,OAEKR,CAAAA,CAAAA,UAAAA,CAAeb,CAAfa,CAFLQ,EAGFR,CAAAA,CAAAA,IAAAA,CAAAA,MAAAA,CAAgBQ,CAAhBR,EAAuB,CAAvBA,C;;;YAMFP,C,EACAC,C,EACAO,C,EACAQ,C,EAAAA;MAGMC,CAAAA,GAAAA,KAAgCP,CAAhCO,KAAQhB,CAAAA,CAASO,CAATP,CAARgB,GAA4ChB,CAAAA,CAASO,CAATP,CAA5CgB,GAAkE,C;MAEtDhB,CAAAA,CAASO,CAATP,CAAAA,GAAuBgB,CAAAA,GAAQD,CAARC,GAAc,C;aAGnDjB,C,KACc,KAAZkB,CAAY,GAAGlB,CAAAA,CAAAA,GAAAA,CAAYQ,CAAZR,CAAH,GACE,KAATiB,CAAS,IAAgB,IAAXC,CAAL,IAAmBlB,CAAAA,CAAAA,MAAAA,CAAeQ,CAAfR,C;;;YAMvCA,C,EACAC,C,EACAkB,C,EACAH,C,EAAAA;MAEoB,YAAA,OAAA,C,EAAA;AAClBI,IAAAA,EAAAA,CAAkBpB,CAAlBoB,EAA2BnB,CAA3BmB,EAAqCD,CAArCC,EAA2CJ,CAA3CI,CAAAA;aACSC,KAAAA,CAAAA,OAAAA,CAAcF,CAAdE,C,EAAcF;SAAO,IACrBN,CAAAA,GAAI,CADiB,EACdC,CAAAA,GAAIK,CAAAA,CAAAA,M,EAAaN,CAAAA,GAAIC,C,EAAGD,CAAAA,E,EAAK;UACrCL,CAAAA,GAAYW,CAAAA,CAAKN,CAALM,C;WAEhBC,EAAAA,CAAkBpB,CAAlBoB,EAA2BnB,CAA3BmB,EAAqCZ,CAArCY,EAAgDJ,CAAhDI,C;;;;;YAQNE,C,EACAC,C,EACAxE,C,EAAAA;WAEa2D,C,KAAT3D,C,EAAAA;SACGK,IAAMmB,C,IAAAA,C,EAAAA;AACJgD,MAAAA,CAAAA,CAAAA,GAAAA,CAAkBhD,CAAlBgD,MAGHD,CAAAA,CAAAA,IAAAA,CAAgBE,EAAAA,CAAejD,CAAfiD,CAAhBF,GACAC,CAAAA,CAAAA,GAAAA,CAAkBhD,CAAlBgD,CAJGA;;;;;YAYTD,C,EACAC,C,EACAf,C,EACAD,C,EAAAA;AAGAkB,EAAAA,EAAAA,CAAkBH,CAAlBG,EAA8BF,CAA9BE,EAA6ClB,CAAAA,CAAAA,IAAAA,CAAAA,GAAAA,CAAaC,CAAbD,CAA7CkB,CAAAA;;OAFA,IAKSZ,CAAAA,GAAI,CALb,EAKgBC,CAAAA,GAAIP,CAAAA,CAAAA,IAAAA,CAAAA,M,EAAiBM,CAAAA,GAAIC,C,EAAGD,CAAAA,E,EAAAA;AAE1CY,IAAAA,EAAAA,CAAkBH,CAAlBG,EAA8BF,CAA9BE,EADmBlB,CAAAA,CAAAA,UAAAA,CAAeA,CAAAA,CAAAA,IAAAA,CAASM,CAATN,CAAfA,EAAwBM,GAAxBN,CACyCC,CADzCD,CACnBkB,CAAAA;;;;YAKehC,C,EAAAA;AAEjBA,EAAAA,CAAAA,CAAAA,WAAAA,GAAAA,CAAmB,CAAnBA;8BAIqBe,C,EAAAA;QAGT,MADCf,CAAAA,CAAAA,QAAAA,CAAce,CAAdf,KAA4B,CAC7B,C,EAAG;WAENrC,IAAMsC,C,IAAAA,CAAAA,CAAAA,O,EAA+B;YAClCO,CAAAA,GAAWR,CAAAA,CAAAA,OAAAA,CAAaC,CAAbD,C;;YAIL,KAHEQ,CAAAA,CAASO,CAATP,CAAAA,IAAuB,CAGzB,C,EAHyB;;;;eAI9BA,CAAAA,CAASO,CAATP,C;;;aAMFR,CAAAA,CAAAA,QAAAA,CAAce,CAAdf,C;uBACae,C;;eAOAE,C,MAAAA,CAAAA,GADAjB,CAAAA,CAAAA,OAAAA,CAAAA,IAAAA,CAAAA,GAAAA,CAAsBe,CAAtBf,C,MAElBA,CAAAA,CAAAA,OAAAA,CAAAA,IAAAA,CAAAA,MAAAA,CAAyBe,CAAzBf,GACIA,CAAAA,CAAAA,O,GAAAA;aACGrC,IAAMmB,C,IAAAA,C,EAAAA;AAETkB,UAAAA,CAAAA,CAAAA,gBAAAA,CF3QmDb,OE0Qf4B,CF1Qe5B,GE0Qf4B,GF1Qe5B,GE0QJL,CAC/CkB,IAD+ClB,KAClBmC,CAA7BjB;;;;eAQWiB,C,MAAAA,CAAAA,GADAjB,CAAAA,CAAAA,KAAAA,CAAAA,IAAAA,CAAAA,GAAAA,CAAoBe,CAApBf,C,GACW;AAC1BA,QAAAA,CAAAA,CAAAA,KAAAA,CAAAA,IAAAA,CAAAA,MAAAA,CAAuBe,CAAvBf;;aACKrC,IAAMmB,C,IAAAA,C,EAAAA;AAELkB,UAAAA,CAAAA,CAAAA,OAAAA,KAEFA,CAAAA,CAAAA,gBAAAA,CFzRmDb,OEwRf4B,CFxRe5B,GEwRf4B,GFxRe5B,GEwRJL,CAC/CkB,IAD+ClB,KAClBmC,CAF3BjB,GAKJiC,EAAAA,CAAgBjC,CAAAA,CAAAA,OAAhBiC,EAA8BjC,CAAAA,CAAAA,QAA9BiC,EAA6CC,CAAAA,CAASpD,CAAToD,CAA7CD,EAAsDnD,CAAAA,CAAtDmD,CALIjC;;;;uBASYe,C;;;;;WAKEA,C,EAAmBjC,C,EAAAA;AAC5B,mBAAbA,CAAa,KACXiC,CAAAA,KAAcvB,CAAAA,CAAAA,YAAduB,GACFtB,CAAAA,CAAAA,GAAAA,CAAyBsB,CAAzBtB,CADEsB,GACuBA,KACHE,CADGF,KAChBjC,CADgBiC,IAEzBtB,CAAAA,CAAAA,GAAAA,CAAkCsB,CAAAA,GAAAA,GAAAA,GAAWjC,CAA7CW,CAJa;;;WAWjBsB,C,EACAjC,C,EAAAA;AAEAqD,EAAAA,CAAAA,CAAmBpB,CAAnBoB,EAA8BrD,CAA9BqD,CAAAA;YACe3C,CAAAA,CAAAA,O,EAAsBuB,C,EAAWjC,C;;;WAKhDiC,C,EACAjC,C,EAAAA;AAEAqD,EAAAA,CAAAA,CAAmBpB,CAAnBoB,EAA8BrD,CAA9BqD,CAAAA;YACe3C,CAAAA,CAAAA,K,EAAoBuB,C,EAAWjC,C;;;WAK9CiC,C,EACAjC,C,EACAkC,C,EAAAA;AAEAmB,EAAAA,CAAAA,CAAmBpB,CAAnBoB,EAA8BrD,CAA9BqD,CAAAA;KACQ3C,CAAAA,CAAAA,O,EAAsBuB,C,EAAWjC,C,EAAUkC,C;gBACtBtB,C,KAE3BF,CAAAA,CAAAA,gBAAAA,CF3U2DL,OE0UvB4B,CF1UuB5B,GE0UvB4B,GF1UuB5B,GE0UZL,CAC/CU,IAAqCwB,C;;;YAUvCD,C,EACAjC,C,EACA4C,C,EAAAA;MAEM1B,CAAAA,GAAOR,C;;MAOTE,C,EAAsB;AAGxBc,QAAAA,CAAAA,GACER,CAAAA,CAAAA,OAAAA,CAAaN,CAAbM,MACCA,CAAAA,CAAAA,OAAAA,CAAaN,CAAbM,IAAqCJ,CAAAA,EADtCI,CADFQ;QAGAE,CAAAA,GAAQV,CAAAA,CAAAA,KAAAA,CAAAA,UAAAA,CAAsBN,CAAtBM,C;SACH;AACDA,IAAAA,CAAAA,CAAAA,OAAAA,KAEFA,CAAAA,CAAAA,gBAAAA,CF1WyDb,OEyWrB4B,CFzWqB5B,GEyWrB4B,GFzWqB5B,GEyWVL,CAC/CkB,IAA6B0B,CAF3B1B;QAIOA,CAAAA,CAAAA,Q;QACHA,CAAAA,CAAAA,KAAAA,CAAAA,I;QACRO,CAAAA,GAAUP,CAAAA,CAAAA,O;;;WAKsBiB,C,MAD5BqB,CAAAA,GAAAA,KAAyBrB,CAAzBqB,KAAe5B,CAAf4B,GAAqC5B,CAAAA,CAAAA,GAAAA,CAAUK,CAAVL,CAArC4B,GAA+CvB,KAAaE,C,IACpBqB,CAAAA,CAAaxD,CAAbwD,C,GAAyB,I;IAGpDvB,C,EAAWjC,C;KAEtBkB,CAAAA,CAAAA,K,EAAYe,C,EAAWjC,C,EAAU4C,C;KAEzBnB,C,EAASC,C,EAAU+B,C,EAAAA,CAAAA,C;KAEnBhC,C,EAASC,C,EAAUkB,C,EAAM,C;;;YCrXzCpE,C,EACAS,C,EACAgD,C,EACA8B,C,EAAAA;OAEK9E,C,EAAAA;YAAiB,C;;;MAChB+E,CAAAA,GAAgBC,EAAAA,CAAiBzF,CAAjByF,C;;MAClBhF,CAAAA,KAAa+E,C,EAAAA;YAAsB,C;;;2CAEvCE,CAAAA,CACE,6EACEjF,CADF,GAEE,qCAFF,GAIE+E,CAJF,GAKE,0CALF,GAMEA,CANF,GAOE,+IARJE,EAWE,EAXFA,C;UAcQC,CAAAA,CAAgB3F,CAAhB2F,CAAAA,CAAgB3F,IAAhB2F,CAAgB3F,UAAWA,CAAXA,EAAWA;QAChBA,CAAAA,CAAAA,IAAAA,KLnBLC,IAAAA,CAAAA,K,EAAAA;cKmBmB,C;;;QACd2F,CAAAA,CACfC,CAAAA,CAAQ7F,CAAR6F,CADeD,EAEfE,CAAAA,CAAkB9F,CAAlB8F,EAAwBP,CAAAA,CAAAA,SAAxBO,CAFeF,C;kBDgTiBjC,C,KAApCmB,CAAAA,CC5SmBrB,CD4SnBqB,EC5S8BtD,CD4S9BsD,C,IC5S8BtD,KD6SImC,CC7SJnC,KD6S9BuD,CAAAA,CC7SmBtB,CD6SnBsB,EC7S8BvD,CD6S9BuD,C;GCnTQY,C;;;AAiBRI,SAAAA,CAAAA,CACEtF,CADFsF,EAEEtC,CAFFsC,EAGEC,CAHFD,EAIER,CAJFQ,EAIER;kBAEgB9E,C;mBACCgD,C;iBACF8B,C;oBACG,CAAC,CAAD,C;wBACI,CAACS,CAAD,C;;;;SAIY,MAA3BC,KAAAA,UAAAA,CAAAA,M,GAA8B;QAC7BjC,CAAAA,GAAQiC,KAAAA,UAAAA,CAAgBA,KAAAA,UAAAA,CAAAA,MAAAA,GAAyB,CAAzCA,G;QACRD,CAAAA,GAASC,KAAAA,cAAAA,CAAoBA,KAAAA,cAAAA,CAAAA,MAAAA,GAA6B,CAAjDA,C;;QACXjC,CAAAA,IAASgC,CAAAA,CAAAA,M,EAAAA;;WAIN;AACChG,MAAAA,CAAAA,GAAOgG,CAAAA,CAAOhC,CAAPgC,CAAPhG;;SCnDH;ADoDsBmG,QAAAA,CAAAA,GAAAA,KAAAA,OAAAA,CAAAA,SAAAA;gBAANnG,CAAAA,CAAAA,U;;iBClDN2D,C,KAAf+C,C,EAAAA;eAFK,IAOA5C,CAAAA,GAAI,CAPJ,EAOOC,CAAAA,GAAI2C,CAAAA,CAAAA,M,EAAmB5C,CAAAA,GAAIC,C,EAAGD,CAAAA,E,EAAK;gBAC3C6C,CAAAA,GAAYD,CAAAA,CAAW5C,CAAX4C,C;gBACZE,CAAAA,GAAOf,CAAAA,CAAQc,CAARd,C;gBAGPgB,CAAAA,GAAqB,cAATD,C;;iBACbC,CAAAA,IAAsB,WAATD,C,MAGZE,CAAAA,GAAMH,CAAAA,CAAAA,SAAAA,GAAsBA,CAAAA,CAAAA,SAAAA,CAAoB,CAApBA,CAAtBA,GAA+C,I,KAC9B,SAAjBd,CAAAA,CAAQiB,CAARjB,C,KAGS,aAAA,QADfnC,CAAAA,GAAQqD,mBAAAA,CAAoBD,CAAAA,CAAAA,KAApBC,EAA+BC,CAA/BD,CACO,CAAA,IAAuB,SAAVrD,C,GAAAA;kBAI3BmD,CAAAA,GAAAA,CAAAA,CAAcnD,CAAdmD,GAAcnD,CAASA,C;;;;;;aArBvB,C;;;UDiDEwC,C,EAAAA;AAEE,YAAiBlG,CAAAA,CAAAA,IAAAA,KL5DhBC,IAAAA,CAAAA,KK4DD,EL5DCA;mBKkEe0D,C,MAJfyC,CAAAA,GAAiCpG,CAAAA,CAAAA,IAAAA,KL1DFC,IAAAA,CAAAA,eK0DED,GACnCiG,KAAAA,OAAAA,CAAAA,SAAAA,CAAuBJ,CAAAA,CAAQ7F,CAAR6F,CAAvBI,CADmCjG,GAEnCA,C,MAG2B,iBAAzBe,OAAAA,CAAAA,GAAAA,CAAAA,QAAyB,IAAzBA,CAAAA,CACYkF,KAAAA,QADZlF,EAC2BqF,CAD3BrF,CAAyB,E,KAKO4C,C,KAAlCsC,KAAAA,OAAAA,CAAAA,gB,GACIA,KAAAA,OAAAA,CAAAA,gBAAAA,CAAAA,iBAAAA,CACER,EAAAA,CAAiBW,CAAjBX,CADFQ,EAEEA,KAAAA,QAFFA,C,GAIAI,EAAAA,CACED,CADFC,EAEEJ,KAAAA,QAFFI,EAGEJ,KAAAA,SAHFI,EAIEJ,KAAAA,OAJFI,C,GAIEJ;iCAIe,C,GAAA,KAAA,cAAA,CAAA,IAAA,CACIN,CAAAA,CAAgBS,CAAhBT,CADJ,C;;SAzBpB,M,IA+BsB,iBAAlBE,CAAAA,CAAQ7F,CAAR6F,C,EAAQ7F;;;;;;;;WAYAsG,C,EAAAA;oBACzBA,C,GAAkB,I,GAAQA,C;;;YEtF1BW,C,EACAC,C,EACAxE,C,EAAAA;AAEAyE,EAAAA,CAAAA,CAAcF,CAAAA,CAAAA,IAAdE,EAA0B,CAA1BA,CAAAA;MACeC,EAAAA,CAAWH,CAAXG,EAAkBF,CAAlBE,EAA2B1E,CAA3B0E,C;;;;;YAMfH,C,EACAC,C,EACAxE,C,EAAAA;MAEM8D,CAAAA,GAAYa,CAAAA,CAAiBH,CAAAA,CAAAA,KAAjBG,C;MACZC,CAAAA,GAAsB;AAAEC,IAAAA,YAAAA,EAAcC,CAAAA;AAAhB,G;MAEtBxB,CAAAA,GAASL,CAAAA,CAAgBa,CAAhBb,C;MACT8B,CAAAA,GAAgBR,CAAAA,CAAAA,UAAAA,CAAiBT,CAAAA,CAAAA,SAAjBS,C;MAED;AACnBS,IAAAA,cAAAA,EAAgBD,CADG;AAEnBE,IAAAA,SAAAA,EAAWF,CAFQ;AAGnBG,IAAAA,cAAAA,EAAgB,EAHG;AAInBvG,IAAAA,SAAAA,EAAW,EAJQ;AAKnB8E,IAAAA,SAAAA,EAAW0B,CAAAA,CAAmBrB,CAAnBqB,EAA8BX,CAAAA,CAAAA,SAA9BW,CALQ;AAMnBC,IAAAA,SAAAA,EAAWC,CAAAA,CAAab,CAAAA,CAAAA,KAAba,CANQ;YAOnBT,CAPmB;WAQnBL,CARmB;AASnBe,IAAAA,gBAAAA,EAAkBf,CAAAA,CAAAA;AATC,G;mBAYjBlG,OAAAA,CAAAA,GAAAA,CAAAA,Q,IACFkH,CAAAA,CAAcR,CAAdQ,EAA6BzB,CAA7ByB,C;QAGoB1C,CAAAA,CAAAA,KAAAA,CAAAA,UAAAA,CAAqB,OAArBA,C,GACpB2C,EAAAA,CAAe3C,CAAf2C,EAAoBT,CAApBS,EAAmClC,CAAnCkC,EAA2CxF,CAA3CwF,C,GAEAC,EAAAA,CAAU5C,CAAV4C,EAAeV,CAAfU,EAA8BnC,CAA9BmC,EAAsCzF,CAAtCyF,C;;;;YAOFlB,C,EACAC,C,EACAvE,C,EAAAA;AAEAwE,EAAAA,CAAAA,CAAcF,CAAAA,CAAAA,IAAdE,EAA0BxE,CAA1BwE,CAAAA;MAEMX,CAAAA,GAAYa,CAAAA,CAAiBH,CAAAA,CAAAA,KAAjBG,C;MACU;AAAEE,IAAAA,YAAAA,EAAcC,CAAAA;AAAhB,G;MAEtBY,CAAAA,GAAkBnB,CAAAA,CAAAA,UAAAA,CAAiB,UAAjBA,C;MAClBQ,CAAAA,GAAgBR,CAAAA,CAAAA,UAAAA,CAAiBT,CAAAA,CAAAA,SAAjBS,C;IAEpBQ,CAAAA,KAAkBW,C,EAAAA,iBAAAA,OAAAA,CAAAA,GAAAA,CAAAA,QAAAA,GAClB,6HADkBA,GAClB,E,EAEA,E;mBAGErH,OAAAA,CAAAA,GAAAA,CAAAA,Q,IACFkH,CAAAA,CAAcR,CAAdQ,EAA6BzB,CAA7ByB,C;MAGmB;AACnBP,IAAAA,cAAAA,EAAgBU,CADG;AAEnBT,IAAAA,SAAAA,EAAWS,CAFQ;AAGnBR,IAAAA,cAAAA,EAAgB,EAHG;AAInBvG,IAAAA,SAAAA,EAAW,EAJQ;AAKnB8E,IAAAA,SAAAA,EAAW0B,CAAAA,CAAmBrB,CAAnBqB,EAA8BX,CAAAA,CAAAA,SAA9BW,CALQ;AAMnBC,IAAAA,SAAAA,EAAWC,CAAAA,CAAab,CAAAA,CAAAA,KAAba,CANQ;YAOnBT,CAPmB;WAQnBL,CARmB;AASnBe,IAAAA,gBAAAA,EAAkBf,CAAAA,CAAAA,gBATC;AAUnB5E,IAAAA,UAAAA,EAAAA,CAAY;AAVO,G;MAaRC,CAAAA,E;MACA,IAAIyD,CAAJ,CACX0B,CADW,EAEXA,CAFW,EAGX9B,CAAAA,CAAgBa,CAAhBb,CAHW,EAIXJ,CAJW,C;;WAOTvF,C,EAAAA,KAC4B2D,CAD5B3D,MACIA,CAAAA,GAAOqI,CAAAA,CAAAA,IAAAA,EADXrI,C,GACWqI;aACa1E,C,KAAtB3D,CAAAA,CAAAA,Y,EAAiC;UAC7BqB,CAAAA,GAAYwE,CAAAA,CAAQ7F,CAAR6F,C;UACZyC,CAAAA,GAAW/C,CAAAA,CAAAA,KAAAA,CAAAA,mBAAAA,CAA8BlE,CAA9BkE,C;;eAEA5B,C,KAAb2E,C,EAAwB;AAE1B/C,QAAAA,CAAAA,CAAAA,SAAAA,GAAgBlE,CAAhBkE;WAKeA,C,EADMgD,CAAAA,CAAAA,CAAAA,GADCD,CAAAA,CAAAA,CAAAA,CAAAA,GADJxC,CAAAA,CAAkB9F,CAAlB8F,EAAwBP,CAAAA,CAAAA,SAAxBO,CACIwC,KAAsBhG,CAAAA,EAAtBgG,EAAkC/C,CAAAA,CAAAA,KAAlC+C,EAA6C/C,CAA7C+C,CACDC,C,EACa5C,CAAAA,CAAgB3F,CAAhB2F,C;UAC7BtE,C,IAAamH,C;wBACFjD,CAAAA,CAAAA,KAAAA,CAAAA,OAAAA,CAAkB6C,CAAlB7C,EAAmClE,CAAnCkE,C,KAEdkD,CAAAA,CAAQ/F,CAAR+F,EAAcC,CAAAA,IAAapG,CAAAA,EAA3BmG,EAAuClD,CAAAA,CAAAA,KAAvCkD,EAAkDlD,CAAlDkD,C;;;;;AAMRnD,EAAAA,CAAAA;;;;YAKA2B,C,EACA0B,C,EACAjG,C,EACAyD,C,EAAAA;AAEM2B,EAAAA,CAAAA,GAAYC,CAAAA,CAAaY,CAAbZ,CAAZD;MACAc,CAAAA,GAAQC,MAAAA,CAAAA,IAAAA,CAAYf,CAAZe,C;;WAEGlF,C,MAAAA,CAAAA,GADAmE,CAAAA,CAAUc,CAAAA,CAAM,CAANA,CAAVd,C,GAAgB;mDAExBpC,CAAAA,CACL,iIADKA,EAGL,EAHKA,C,GAGL,KAAA,C;;;MAIEjF,CAAAA,GAA+BqI,CAAAA,CAAAA,aAAAA,CAAAA,IAAAA,CAAAA,K;MACnBC,CAAAA,CAAAA;AAAEC,IAAAA,UAAAA,EAAYvI;AAAdsI,GAAAA,EAA2BrG,CAA3BqG,C;MACZtF,CAAAA,GAAYwD,CAAAA,CAAAA,WAAAA,CAAkBgC,CAAlBhC,C;;OACbxD,C,EAAAA;mDACIiC,CAAAA,CACL,sIAEEjF,CAFF,GAGE,IAJGiF,EAKL,EALKA,C,GAKL,KAAA,C;;;mBAIA3E,OAAAA,CAAAA,GAAAA,CAAAA,Q,IACFkH,CAAAA,CAAcxH,CAAdwH,EAAwBa,CAAxBb,C;SAGmB;AACnBP,IAAAA,cAAAA,EAAgBjH,CADG;AAEnBkH,IAAAA,SAAAA,EAAWlE,CAFQ;AAGnBmE,IAAAA,cAAAA,EAAgB,EAHG;AAInBvG,IAAAA,SAAAA,EAAW,EAJQ;AAKnB8E,IAAAA,SAAAA,EAAWA,CAAAA,IAAa,EALL;eAMnB2B,CANmB;AAOnBR,IAAAA,MAAAA,EAAQ;AAAEC,MAAAA,YAAAA,EAAcC,CAAAA;AAAhB,KAPW;WAQnBP,CARmB;AASnBe,IAAAA,gBAAAA,EAAkBf,CAAAA,CAAAA;AATC,G,EAYDxD,C,EAAWkC,CAAAA,CAAgBmD,CAAhBnD,C,EAA2BsD,C;;;YAI1D1D,C,EACA9B,C,EACAuC,C,EACAtD,C,EAAAA;MAGMjC,CAAAA,GADUgD,CAAAA,KAAc8B,CAAAA,CAAAA,KAAAA,CAAAA,UAAAA,CAAqB,OAArBA,CAAd9B,GACWA,CADXA,GACuBf,CAAAA,CAAAA,U;;MACf,YAAA,OAAA,C,EAAA;AAExBwG,IAAAA,CAAAA,CAAyBzF,CAAzByF,EAAoC,YAApCA,EAAkDzI,CAAlDyI,CAAAA;QAEa,IAAInD,CAAJ,CAAsBtF,CAAtB,EAAgCgD,CAAhC,EAA2CuC,CAA3C,EAAmDT,CAAnD,C;;aAETvF,C,EAAAA,KAC4B2D,CAD5B3D,MACIA,CAAAA,GAAOqI,CAAAA,CAAAA,IAAAA,EADXrI,C,GACuC;UACnCqB,CAAAA,GAAYwE,CAAAA,CAAQ7F,CAAR6F,C;UACZ6C,CAAAA,GAAY5C,CAAAA,CAAkB9F,CAAlB8F,EAAwBP,CAAAA,CAAAA,SAAxBO,C;UACDF,CAAAA,CAAWvE,CAAXuE,EAAsB8C,CAAtB9C,C;UACXuD,CAAAA,GAAazG,CAAAA,CAAK0G,CAAAA,CAAcpJ,CAAdoJ,CAAL1G,C;UACbd,CAAAA,GAAe6B,CAAAA,GAAAA,GAAAA,GAAWjC,C;;UAEH,iBAAzBT,OAAAA,CAAAA,GAAAA,CAAAA,Q,EAAAA;iBACiB4C,C,KAAfwF,C,EAA0B;AACtBE,UAAAA,CAAAA,GAAS9D,CAAAA,CAAAA,UAAAA,GACX,kDADWA,GAEX,EAFE8D;mBAKkB1F,C,KAAtB3D,CAAAA,CAAAA,Y,GACI,+B,GACA,e;mDAEN0F,CAAAA,CACE,sCACElE,CADF,GAEE,oDAFF,GAGE8H,CAHF,GAIE,kBAJF,GAKED,CANJ3D,EAOE,EAPFA,C;;;gCAWiCjF,C,IACjC8E,CAAAA,CAAAA,gBAAAA,CAAAA,sBAAAA,CAA4C9E,CAA5C8E,EAAsDlE,CAAtDkE,C;;;;iBAIAvF,CAAAA,CAAAA,Y,GAEFkJ,CAAAA,CAAyBzF,CAAzByF,EAAoC1H,CAApC0H,EAA8CC,CAA9CD,C,IAGMK,CAAAA,GAAYhB,CAAAA,CAAWY,CAAXZ,CAAZgB,EAENL,EAAAA,CAAuBzF,CAAvByF,EAAkC1H,CAAlC0H,EADM9E,CAAAA,GAAOoF,EAAAA,CAAWjE,CAAXiE,EAAgB5H,CAAhB4H,EAAqB7D,CAAAA,CAAgB3F,CAAhB2F,CAArB6D,EAA4CD,CAA5CC,CACbN,C;;;;;YAMJ3D,C,EACAqC,C,EACA5B,C,EACAtD,C,EAAAA;MAEI4B,KAAAA,CAAAA,OAAAA,CAAc5B,CAAd4B,C,EAAqB;aACjBmF,CAAAA,GAAcnF,KAAAA,CAAM5B,CAAAA,CAAAA,MAAN4B,C,EACXR,CAAAA,GAAI,C,EAAGC,CAAAA,GAAIrB,CAAAA,CAAAA,M,EAAaoB,CAAAA,GAAIC,C,EAAGD,CAAAA,E,EAAK;UAKrCV,CAAAA,GAAQoG,EAAAA,CAAWjE,CAAXiE,EAFY5B,CAAAA,GAAAA,GAAAA,GAAmB9D,CAE/B0F,EAA0BxD,CAA1BwD,EAJD9G,CAAAA,CAAKoB,CAALpB,CAIC8G,C;QAEN1F,C,IAAKV,C;;;;;;AAIV,MAAa,SAATV,CAAJ,EAAIA;;;;MAKe,UAAA,CAAA,GADR6C,CAAAA,CAAAA,KAAAA,CAAAA,WAAAA,CAAsB7C,CAAtB6C,CACQ,IAAO9B,CAAP,GAAmBmE,C;MAC5BlF,CAAAA,CAAAA,U;aAGf6C,CAAAA,CAAAA,KAAAA,CAAAA,IAAAA,CAAe7C,CAAAA,CAAAA,UAAf6C,C,IACc,SAAd9B,C,IACoB,YAAA,OAAA,C,IACnBhD,CAAAA,CAAAA,QAAAA,CAAkB,YAAlBA,C,IACAA,CAAAA,CAAAA,QAAAA,CAAkB,MAAlBA,C,IACY,eAAbA,C,IAAAA,iBAAAA,OAAAA,CAAAA,GAAAA,CAAAA,QAAAA,IAEAiF,CAAAA,CACE,qDACEkC,CADF,GAEE,0LAFF,GAMEnH,CANF,GAOE,gIAPF,GAUEA,CAVF,GAWE,6BAZJiF,EAaE,EAbFA,C;KAiBaH,C,EAAK3D,C,EAAKoE,C,EAAQtD,C;;;;YAMjC6C,C,EACA9E,C,EACAuF,C,EACAtD,C,EAAAA;MAEMgH,CAAAA,GACJjJ,CAAAA,KAAa8E,CAAAA,CAAAA,KAAAA,CAAAA,UAAAA,CAAqB,UAArBA,CAAb9E,IACAA,CAAAA,KAAa8E,CAAAA,CAAAA,KAAAA,CAAAA,UAAAA,CAAqB,cAArBA,C;MAEF,IAAIQ,CAAJ,CAAsBtF,CAAtB,EAAgCA,CAAhC,EAA0CuF,CAA1C,EAAkDT,CAAlD,C;;WAETvF,C,EAAAA,KAC4B2D,CAD5B3D,MACIA,CAAAA,GAAOqI,CAAAA,CAAAA,IAAAA,EADXrI,C,GACuC;QACnCqB,CAAAA,GAAYwE,CAAAA,CAAQ7F,CAAR6F,C;QACZ6C,CAAAA,GAAY5C,CAAAA,CAAkB9F,CAAlB8F,EAAwBP,CAAAA,CAAAA,SAAxBO,C;QACkBF,CAAAA,GAAAA,CAAAA,CAAWvE,CAAXuE,EAAsB8C,CAAtB9C,C;QAAVnF,CAAAA,GAAAA,GAAAA,GL7UZmB,C;;aK8UY+B,C,KAAtB3D,CAAAA,CAAAA,Y,EAAiC;SAEpBuF,C,EADIgD,CAAAA,CAAW7F,CAAAA,CAAK0G,CAAAA,CAAcpJ,CAAdoJ,CAAL1G,CAAX6F,C,EACa5C,CAAAA,CAAgB3F,CAAhB2F,C;;;AAG9B+D,IAAAA,CAAAA,KAEFnE,CAAAA,CAAAA,cAAAA,GAAqB9E,CAArB8E,EACAA,CAAAA,CAAAA,SAAAA,GAAgB9E,CADhB8E,EAEAA,CAAAA,CAAAA,cAAAA,GAAqB/D,CAFrB+D,EAGAA,CAAAA,CAAAA,SAAAA,GAAgBlE,CAHhBkE,E,KAQgB5B,C,MADV8E,CAAAA,GAAUlD,CAAAA,CAAAA,KAAAA,CAAAA,OAAAA,CAAkB9E,CAAlB8E,EAA4BlE,CAA5BkE,C,KAEdkD,CAAAA,CAAQ/F,CAAR+F,EAAcC,CAAAA,IAAapG,CAAAA,EAA3BmG,EAAuClD,CAAAA,CAAAA,KAAvCkD,EAAkDlD,CAAlDkD,CAXAiB,CAAAA;;;;YAmBNnE,C,EACA7C,C,EACAsD,C,EAAAA;MAEI1B,KAAAA,CAAAA,OAAAA,CAAc5B,CAAd4B,C,EAAqB;aACjBmF,CAAAA,GAAcnF,KAAAA,CAAM5B,CAAAA,CAAAA,MAAN4B,C,EACXR,CAAAA,GAAI,C,EAAGC,CAAAA,GAAIrB,CAAAA,CAAAA,M,EAAaoB,CAAAA,GAAIC,C,EAAGD,CAAAA,E,EAAAA;AACtC2F,MAAAA,CAAAA,CAAQ3F,CAAR2F,CAAAA,GAAaE,EAAAA,CAAepE,CAAfoE,EAAoBjH,CAAAA,CAAKoB,CAALpB,CAApBiH,EAA6B3D,CAA7B2D,CAAbF;;;;;;AAEgB,WAAT/G,CAAS,KAMF,UADZe,CAAAA,GAAY8B,CAAAA,CAAAA,KAAAA,CAAAA,WAAAA,CAAsB7C,CAAtB6C,CACA,IAChB2C,EAAAA,CAAe3C,CAAf2C,EAAoBzE,CAApByE,EAA+BlC,CAA/BkC,EAAuCxF,CAAvCwF,CADgB,GAIhBC,EAAAA,CAAU5C,CAAV4C,EADiBzF,CAAAA,CAAAA,UACjByF,EAAyBnC,CAAzBmC,EAAiCzF,CAAjCyF,CAVkB;;;AClWpByB,SAAAA,CAAAA,CACE5B,CADF4B,EAEEC,CAFFD,EAGEE,CAHFF,EAIEG,CAJFH,EAKEnH,CALFmH,EAKEnH;;;sBAoDY,C;;;OAEIwD,CAAAA,CAAAA,I;qBACG,C;;;oBAGRL,C;mBAxDMiE,CAAAA,IAAa,E;6BACHE,CAAAA,IAAuB,E;cACtCtH,CAAAA,IAAQ,E;0BACIuF,C;iBAET;cACF8B,CAAAA,IAAWA,CAAAA,CAAAA,QAAXA,IAAgC,EAD9B;kBAEEA,CAAAA,IAAWA,CAAAA,CAAAA,YAAXA,IAAoC;AAFtC,G;OAOPE,CAAAA,GAAAA,CAAAA,CAAAA,GAAAA,CAAAA,CAAAA,MAAAA,EAAAA,YAAAA,EAAAA,EACAC,CAAAA,GAAeC,CAAAA,CAAAA,eAAAA,EADfF,EAEAG,CAAAA,GAAmBD,CAAAA,CAAAA,mBAAAA,EAFnBF,E,kBAUY;WANZI,CAAAA,GAAYJ,CAAAA,GAAYA,CAAAA,CAAAA,IAAZA,GAA6B,OAM7B;cALZK,CAAAA,GAAeJ,CAAAA,GAAeA,CAAAA,CAAAA,IAAfA,GAAmC,UAKtC;kBAJZK,CAAAA,GAAmBH,CAAAA,GACrBA,CAAAA,CAAAA,IADqBA,GAErB;AAEc,GAVZH,E,uBAgBW,E,EACdI,C,IAAY,O,EAAA,CAAA,CACZC,CADY,CAAA,GACG,U,EAAA,CAAA,CACfC,CADe,CAAA,GACI,c,2BAGJ;WACT,OADS;cAEN,UAFM;kBAGF;AAHE,G,mBAMD;WACR,OADQ;cAEL,UAFK;kBAGD;AAHC,G;;0BJgBFzH,C,EAAAA;WAAwC;AAC3DC,MAAAA,oBAAAA,EAAAA,CAAsB,CADqC;AAE3DC,MAAAA,gBAAAA,EAAkBT,CAAAA,EAFyC;AAG3DU,MAAAA,WAAAA,EAAAA,CAAa,CAH8C;oBAI3DH,CAJ2D;AAK3DI,MAAAA,OAAAA,EAAS,IAAI1C,GAAJ,EALkD;AAM3D2C,MAAAA,QAAAA,EAAUZ,CAAAA,EANiD;AAO3Da,MAAAA,OAAAA,EAASb,CAAAA,EAPkD;AAQ3Dc,MAAAA,KAAAA,EAAOC,EAAAA,EARoD;AAS3DC,MAAAA,OAAAA,EAASD,EAAAA,EATkD;AAU3DE,MAAAA,OAAAA,EAAS;AAVkD,K;AIT7C2F,G,CAAkBjD,KAAAA,UAAAA,CAAgB,OAAhBA,C;;;mCAWrBW,C,EAAAA;yBACcA,C;;;oCAGblE,C,EAAAA;;;;;OAELjC,C,EAAAA;;;;WAEmCkD,C,KAA7BsC,KAAAA,SAAAA,CAAexF,CAAfwF,C,EAAexF;;;;MAItBmB,C;YACUnB,C,IAAAA,CAAAA,GACNwF,KAAAA,IAAAA,CAAUxF,CAAVwF,EAAoBvD,CAApBuD,C,GACUtC,QAAP4G,CAAO5G,GAChB/B,CAAAA,GAAM,KAAG2I,CADO5G,GAECA,QAAR6G,CAAQ7G,KACjB/B,CAAAA,GAAM,KAAG4I,CADQ7G,C;aAIHlD,CAAAA,GAAAA,GAAAA,GAAYmB,C,GAAQ,I;;;0CAGpBiC,C,EAA8BrC,C,EAAAA;MAK5B,UAJZiC,CAAAA,GACO,SAAXI,CAAW,IAA0B,YAAA,OAAA,CAA1B,GACPoC,KAAAA,WAAAA,CAAiBpC,CAAjBoC,CADO,GAEPpC,CACY,C,EADZA;;;;MAEAsF,CAAAA,GAAaD,CAAAA,CAAwBzF,CAAxByF,EAAmC1H,CAAnC0H,C;oBACfC,C,GAAiCA,C,GAAAA,CAC/B/E,CAAAA,GAAO8E,CAAAA,CAAsBzF,CAAtByF,EAAiC1H,CAAjC0H,CADwBC,IAEvB/E,CAFuB+E,GAEhB,I;;;gCAIrBtF,C,EACA4G,C,EACAnJ,C,EAAAA;gCAE8BuC,C,EAAQ+B,CAAAA,CAAW6E,CAAX7E,EAAkBtE,CAAlBsE,C;;;wCAGxB+C,C,EAA8BxC,C,EAAAA;eCjG9CZ,C,EACA9B,C,EACAuC,C,EAAAA;QAE8B,YAAdvC,C,EAGF;AACZhD,UAAAA,CAAAA,GAAWyI,CAAAA,CAAwBzF,CAAxByF,EAAmC,YAAnCA,CAAXzI;;UACwB,YAAA,OAAA,C,EAAA;;;;QAGGgD,C,EAAW,Y,EAAA,KAAcE,C;;UAGzCF,C;;;QAGA,IAAIsC,CAAJ,CAAsBtF,CAAtB,EAAgCgD,CAAhC,EAA2CuC,CAA3C,EAAmDT,CAAnD,C;;aAETvF,C,EAAAA,KAC4B2D,CAD5B3D,MACIA,CAAAA,GAAOqI,CAAAA,CAAAA,IAAAA,EADXrI,C,GACuC;UACnCqB,CAAAA,GAAYwE,CAAAA,CAAQ7F,CAAR6F,C;UACZrE,CAAAA,GAAWoE,CAAAA,CACfvE,CADeuE,EAEfE,CAAAA,CAAkB9F,CAAlB8F,EAAwBP,CAAAA,CAAAA,SAAxBO,CAFeF,C;uBAMf7E,OAAAA,CAAAA,GAAAA,CAAAA,Q,IACAwE,CAAAA,CAAAA,gB,IACA9E,C,IAEA8E,CAAAA,CAAAA,gBAAAA,CAAAA,sBAAAA,CAA4C9E,CAA5C8E,EAAsDlE,CAAtDkE,C;;eAGwB5B,C,KAAtB3D,CAAAA,CAAAA,Y,EAAAA;AACFkJ,QAAAA,CAAAA,CAAyBzF,CAAzByF,EAAoC1H,CAApC0H,EAAoC1H,KAAUmC,CAA9CuF,CAAAA;iBAEM4B,CAAAA,GAAcnF,CAAAA,CAAgB3F,CAAhB2F,CAAdmF,EACA1G,CAAAA,GAAO8E,CAAAA,CAAsBzF,CAAtByF,EAAiC1H,CAAjC0H,CADP4B,EAGN5B,EAAAA,CAAuBzF,CAAvByF,EAAkC1H,CAAlC0H,EAAkC1H,KAAUmC,CAA5CuF,CAHM4B,EAIN5B,CAAAA,CAAyBzF,CAAzByF,EAAoC1H,CAApC0H,EAAoC1H,KAAUmC,CAA9CuF,CAJM4B,EAMFxG,KAAAA,CAAAA,OAAAA,CAAcF,CAAdE,C,EAAqB;AACdR,QAAAA,CAAAA,GAAI,CAAJA;;aAAJ7B,IAAW8B,CAAAA,GAAIK,CAAAA,CAAAA,M,EAAaN,CAAAA,GAAIC,C,EAAGD,CAAAA,E,EAAK;cACrCiH,CAAAA,GAAY3G,CAAAA,CAAKN,CAALM,C;mBACd2G,C,IACFC,EAAAA,CAAoBzF,CAApByF,EAAyBD,CAAzBC,EAAoCF,CAApCE,C;;;aAIJA,EAAAA,CAAoBzF,CAApByF,EAAyB5G,CAAzB4G,EAA+BF,CAA/BE,C;;;QApEe;AACnB7E,IAAAA,SAAAA,EAAW0B,CAAAA,CAAAA,CAAAA,GAHKR,CAAAA,CAAAA,CDmHCqD,CAAAA,GAAAA,aAAAA,CAAc/B,CAAd+B,EAAqBvE,CAArBuE,CCnHDrD,EDmHsBlB,KCnHtBkB,CAGLQ,EAA8BX,CAAAA,CAAAA,SAA9BW,CADQ;AAEnBC,IAAAA,SAAAA,EAAWC,CAAAA,CAAab,CAAAA,CAAAA,KAAba,CAFQ;WDiHRd,ICjHQ;AAInBe,IAAAA,gBAAAA,ED6GWf,KAAAA;ACjHQ,G,EASnB1B,CAAAA,CAAAA,KAAAA,CAAAA,UAAAA,CAAqB,OAArBA,C,EACAI,CAAAA,CAAgBa,CAAhBb,C;;;sCD0GY9B,C,EAAAA;MAKS,UAJfJ,CAAAA,GACO,SAAXI,CAAW,IAA0B,YAAA,OAAA,CAA1B,GACPoC,KAAAA,WAAAA,CAAiBpC,CAAjBoC,CADO,GAEPpC,CACe,C,EAAdJ;;;QJ0QHc,CAAAA,GAA0B,E;QAC1BC,CAAAA,GAA6B,IAAIjE,GAAJ,E;MI3QL2I,C;OJgRT3E,C,EAAYC,C,EIhRH0E,C,EJgR6B9F,C;OACtCmB,C,EAAYC,C,EIjRH0E,C,EJiR6B5F,C;QACpDiB,C;;QIlR+D,E;;;;;;oCAIpEoG,C,EACAlC,C,EAAAA;AAEMvB,EAAAA,CAAAA,GAAUwD,aAAAA,CAAcC,CAAAA,CAAAA,KAAdD,EAA2BC,CAAAA,CAAAA,SAA3BD,CAAVxD;gBACSuB,CAAAA,CAAQxC,KAAAA,SAAAA,CAAeiB,CAAfjB,CAARwC,C,KAAuBvB,EAAAA,CAEzBjB,IAFyBiB,EAEnBA,CAFmBA,EAEV0D,CAFU1D,C;;;kCAM9ByD,C,EAAAA;YACI1E,I,EAAMyE,aAAAA,CAAcC,CAAAA,CAAAA,KAAdD,EAA2BC,CAAAA,CAAAA,SAA3BD,C,EAA2BC,I;;;qCAI7CE,C,EACAhH,C,EACAsC,C,EAAAA;AETI2B,EAAAA,CAAAA,GAAYC,CAAAA,CFWU8C,CEXV9C,CAAZD;MACAc,CAAAA,GAAQC,MAAAA,CAAAA,IAAAA,CAAYf,CAAZe,C;;WAEGlF,C,MAAAA,CAAAA,GADAmE,CAAAA,CAAUc,CAAAA,CAAM,CAANA,CAAVd,C,GAAgB;6CAE/BpC,CAAAA,CACE,gIADFA,EAGE,CAHFA,C,MAMO,I;;QAGHjF,CAAAA,GAA+BqI,CAAAA,CAAAA,aAAAA,CAAAA,IAAAA,CAAAA,K;4BFFKjF,CAAAA,CAAAA,U,KAAAA,CAAAA,CAAAA,UAAAA,GEIpBpD,C;KAGhBgD,CAAAA,GACc,YAAA,OAAA,CAAA,GFREwD,KAAAA,WAAAA,CESE8B,CAAAA,CAAAA;AAAEC,MAAAA,UAAAA,EAAYvI;AAAdsI,KAAAA,EFTkBlF,CESlBkF,CFTF9B,CEQF,GFRsBpD,C,KEwBb,iBAAzB9C,OAAAA,CAAAA,GAAAA,CAAAA,QAAyB,IAC3BkH,CAAAA,CAAcxH,CAAdwH,EAAwBa,CAAxBb,CAD2B,EACHa,CAAAA,GAgBxBwC,CAAAA,CAbmB/F;AACnBmC,MAAAA,cAAAA,EAAgBjH,CADG8E;AAEnBoC,MAAAA,SAAAA,EAAWlE,CAFQ8B;AAGnBqC,MAAAA,cAAAA,EAAgB,EAHGrC;AAInBlE,MAAAA,SAAAA,EAAW,EAJQkE;AAKnBY,MAAAA,SAAAA,EFjCgDA,CAAAA,IEiCxB,EALLZ;iBAMnBuC,CANmBvC;AAOnB6F,MAAAA,OAAAA,EAAAA,CAAS,CAPU7F;aF5BC0B,IE4BD1B;AASnByC,MAAAA,gBAAAA,EFrCoBf,KAAAA;AE4BD1B,KAanB+F,EAAmB7H,CAAnB6H,EAA8B3F,CAAAA,CAAgBmD,CAAhBnD,CAA9B2F,EAAyDhJ,CAAAA,EAAzDgJ,CAAAA,IAAwE,I,KAAA,iBAAA,OAAA,CAAA,GAAA,CAAA,QAAA,IA5BxE5F,CAAAA,CACE,gIAEEjF,CAFF,GAGE,IAJJiF,EAKE,CALFA,CA4BwE,E,IApBjE,I;;;;;;sCFjBPmF,C,EACAnI,C,EACAyD,C,EAAAA;KAEcF,I,EAAM4E,C,EAAcnI,C,EAAMyD,C;;;WG9K1CnG,C,EACAgH,C,EAAAA;WAEuBrD,C,KAAnB3D,CAAAA,CAAAA,S,IAA0D,MAA1BA,CAAAA,CAAAA,SAAAA,CAAAA,M,EAAAA;;;;WAI9BsB,CAAAA,GAAOgB,CAAAA,E,EACTiK,CAAAA,GAAW,C,EAENzI,CAAAA,GAAI,C,EAAGC,CAAAA,GAAI/D,CAAAA,CAAAA,SAAAA,CAAAA,M,EAAuB8D,CAAAA,GAAIC,C,EAAGD,CAAAA,E,EAAK;QAC/CgD,CAAAA,GAAM9G,CAAAA,CAAAA,SAAAA,CAAe8D,CAAf9D,C;QACN0D,CAAAA,GAAQqD,mBAAAA,CAAoBD,CAAAA,CAAAA,KAApBC,EAA+BC,CAA/BD,C;YACVrD,C,KACFpC,CAAAA,CAAKuE,CAAAA,CAAQiB,CAARjB,CAALvE,CAAAA,GAAqBoC,CAArBpC,EACAiL,CAAAA,E;;;aAIGA,C,GAAejL,C,GAAO,I;;;WAK7BtB,C,EACA2K,C,EAAAA;WAEiChH,C,KAA7B3D,CAAAA,CAAAA,mB,EAAAA;WACK,E;;;MAGHsB,CAAAA,GAAmBqJ,CAAAA,IAAuB,E;gDAER3D,C,EAAMwF,C,EAAAA;QACtC5F,CAAAA,GAAOf,CAAAA,CAAQ2G,CAAAA,CAAAA,QAAR3G,C;QACTnC,CAAAA,GAAQpC,CAAAA,CAAKsF,CAALtF,C;;aACEqC,C,KAAVD,C,EAAAA;eACuBC,C,KAArB6I,CAAAA,CAAAA,Y,EAAAA;AACF9I,QAAAA,CAAAA,GAAQqD,mBAAAA,CAAoByF,CAAAA,CAAAA,YAApBzF,EAAsCzF,CAAtCyF,CAARrD;;;;;;MAMCkD,C,IAAQlD,C;;KAEZpB,CAAAA,E;;;ACzCHmK,SAAAA,CAAAA,CAAYvC,CAAZuC,EAAYvC;gBACIwC,iBAAAA,CAAkBxC,CAAlBwC,C;;;wCAGAjM,C,EAAkBY,C,EAAAA;qBAC1BoJ,CAAAA,GAAQkC,EAAAA,CAAS1G,KAAAA,MAAT0G,EAAsBlM,CAAtBkM,EAAgCtL,CAAhCsL,C,IAAgCtL,CACd,C,GACzBuL,cAAAA,CAAenC,CAAAA,CAAAA,IAAfmC,C;;;uCAGMnM,C,EAAkBY,C,EAAAA;WAEjBsC,C,MADR8G,CAAAA,GAAQkC,EAAAA,CAAS1G,KAAAA,MAAT0G,EAAsBlM,CAAtBkM,EAAgCtL,CAAhCsL,C,GAAgCtL;YACd,C;;;MACjBwL,aAAAA,CAAcpC,CAAAA,CAAAA,IAAdoC,CAAAA,GAA4BpC,CAAAA,CAAAA,IAAAA,CAAAA,MAA5BoC,GAAgDpC,CAAAA,CAAAA,I;oBAC7CqC,C,KAAWF,cAAAA,CAAeE,CAAAA,CAAAA,MAAfF,C;;;+CAGRnM,C,EAAkBsM,C,EAAAA;WAC9BJ,EAAAA,CAAS1G,KAAAA,MAAT0G,EAAsBlM,CAAtBkM,EAAgCI,CAAhCJ,C;;;0CAITnH,C,EACA/E,C,EAAAA;OAEKA,C,IAAAA,CAAa+E,C,EAAAA;YAAsB,C;;;MACpC/E,CAAAA,KAAa+E,C,EAAAA;YAAsB,C;;;MAEjCwH,CAAAA,GAAe/G,KAAAA,MAAAA,CAAAA,OAAAA,CAAoBT,CAApBS,C;MACfgH,CAAAA,GAAahH,KAAAA,MAAAA,CAAAA,OAAAA,CAAoBxF,CAApBwF,C;;MAEf+G,CAAAA,YAAAA,iB,EAAAA;iBACsBC,C;;;IAGPD,CAAAA,YAAAA,oBAAAA,IAAAA,CAAAA,YAAAA,gB,EAAAA,iBAAAA,OAAAA,CAAAA,GAAAA,CAAAA,QAAAA,GA+CnB,sCA/CiCxH,CA+CjC,GAEE,oIAjDiBwH,GAiDjB,E,EAEF,C;KAlDiBC,C,EAAYxM,C;oCACKuM,C,EAAcC,C;;;YAKlD/C,C,EACAzJ,C,EACAY,C,EAAAA;KAEM6L,CAAAA,GAAShD,CAAAA,CAAAA,OAAAA,CAAezJ,CAAfyJ,C,EACUzJ,C;;WAGXkD,C,MAAAA,CAAAA,GADAuJ,CAAAA,CAAAA,SAAAA,GAAmB7L,CAAnB6L,C,GAAmB7L;6CAE/BqE,CAAAA,CACE,+BACErE,CADF,GAEE,uBAFF,GAGEZ,CAHF,GAIE,yHALJiF,EAQE,CARFA,C;;;;;;AAiBJyH,SAAAA,EAAAA,CAA0B7G,CAA1B6G,EAAkC1M,CAAlC0M,EAAkC1M;AAChCE,EAAAA,CAAAA,CACE2F,CAAAA,YAAAA,iBADF3F,EACE2F,iBAAAA,OAAAA,CAAAA,GAAAA,CAAAA,QAAAA,GACA,oCACE7F,CADF,GAEE,sFAHF6F,GAGE,EAJJ3F,EAME,CANFA,CAAAA;;;YNxEsBX,C,EAAAA;oBACRC,IAAAA,CAAAA,mB;;;YAOZD,C,EAAAA;oBAAsBC,IAAAA,CAAAA,oB;;;WAHxBsG,C,EAAAA;OAEMC,CAAAA,GAAYD,CAAAA,CAAAA,WAAAA,CAAAA,IAAAA,CAAAA,EAAAA,C,GAAAA,iBAAAA,OAAAA,CAAAA,GAAAA,CAAAA,QAAAA,GAMhB,iIANgBA,GAMhB,E,EAEA,C;;;;YAQ6C/C,C,EAAgBxD,C,EAAAA;AAC7DwD,EAAAA,CAAAA,CAAIqC,CAAAA,CAAQ7F,CAAR6F,CAAJrC,CAAAA,GAAqBxD,CAArBwD;;;;WAFyB+C,C,EAAAA;8BACJE,E,EAAAA,M,CAAAA,E,EAGpB,E;;;YIkBHQ,C,EACAC,C,EACAxE,C,EAAAA;AAEAyE,EAAAA,CAAAA,CAAcF,CAAAA,CAAAA,IAAdE,EAA0B,CAA1BA,CAAAA;MACe8D,EAAAA,CAAKhE,CAALgE,EAAY/D,CAAZ+D,EAAqBvI,CAArBuI,C;;;;;YAMfhE,C,EACAC,C,EACAyD,C,EAAAA;MAEMnE,CAAAA,GAAYa,CAAAA,CAAiBH,CAAAA,CAAAA,KAAjBG,C;MACZ6D,CAAAA,GAAUjE,CAAAA,CAAAA,UAAAA,CAAiBT,CAAAA,CAAAA,SAAjBS,C;MACVkE,CAAAA,GAAaxF,CAAAA,CAAgBa,CAAhBb,C;MAEE;AACnB+B,IAAAA,cAAAA,EAAgBwD,CADG;AAEnBvD,IAAAA,SAAAA,EAAWuD,CAFQ;AAGnBtD,IAAAA,cAAAA,EAAgB,EAHG;AAInBvG,IAAAA,SAAAA,EAAW,EAJQ;AAKnB8E,IAAAA,SAAAA,EAAW0B,CAAAA,CAAmBrB,CAAnBqB,EAA8BX,CAAAA,CAAAA,SAA9BW,CALQ;AAMnBC,IAAAA,SAAAA,EAAWC,CAAAA,CAAab,CAAAA,CAAAA,KAAba,CANQ;AAOnBqD,IAAAA,OAAAA,EAAAA,CAAS,CAPU;WAQnBnE,CARmB;AASnBe,IAAAA,gBAAAA,EAAkBf,CAAAA,CAAAA;AATC,G;mBAYjBlG,OAAAA,CAAAA,GAAAA,CAAAA,Q,IACFkH,CAAAA,CAAciD,CAAdjD,EAAuBzB,CAAvByB,C;MAGS0C,CAAAA,IAASrI,CAAAA,E;MAElB4I,CAAAA,KAAY3F,CAAAA,CAAAA,KAAAA,CAAAA,UAAAA,CAAqB,OAArBA,CAAZ2F,GACIG,EAAAA,CAAS9F,CAAT8F,EAAcH,CAAdG,EAAuBF,CAAvBE,EAAmC3I,CAAnC2I,CADJH,GAEII,CAAAA,CAAc/F,CAAd+F,EAAmBJ,CAAnBI,EAA4BH,CAA5BG,EAAwC5I,CAAxC4I,C;SAEC;AACL/D,IAAAA,YAAAA,EAAcC,CAAAA,EADT;AAEL4D,IAAAA,OAAAA,EAAAA,KAAkBzH,CAAlByH,KAAS1I,CAAT0I,GAAS1I,CAAqB,CAA9B0I,GAAsC7F,CAAAA,CAAAA,OAFjC;AAGL7C,IAAAA,IAAAA,EAAAA,KAAeiB,CAAfjB,KAAMA,CAANA,GAA2B,IAA3BA,GAAkCA;AAH7B,G;;;YAQP6C,C,EACA9B,C,EACAuC,C,EACAuF,C,EAAAA;MAEuC,YAAA,OAAA,CAAA,CAAA,U,EAAA;;;;MAI1B,IAAIxF,CAAJ,CAAsBtC,CAAtB,EAAiCA,CAAjC,EAA4CuC,CAA5C,EAAoDT,CAApD,C;OACAjD,CAAAA,E,EAAAA,U,GACKiJ,CAAAA,CAAAA,U;;WAEdvL,C,EAAAA,KAC4B2D,CAD5B3D,MACIA,CAAAA,GAAOqI,CAAAA,CAAAA,IAAAA,EADXrI,C,GACuC;QACnCwL,CAAAA,GAAapC,CAAAA,CAAcpJ,CAAdoJ,C;QACbD,CAAAA,GAAaoC,CAAAA,CAAaC,CAAbD,C;eACfvL,CAAAA,CAAAA,Y,IAAkD,SAAfmJ,C,IAC/BI,CAAAA,GAAYhB,CAAAA,CAAWY,CAAXZ,CAAZgB,EACN7G,CAAAA,CAAK8I,CAAL9I,CAAAA,GAAmB+I,EAAAA,CAAclG,CAAdkG,EAAmB9F,CAAAA,CAAgB3F,CAAhB2F,CAAnB8F,EAA0ClC,CAA1CkC,C,IAEnB/I,CAAAA,CAAK8I,CAAL9I,CAAAA,GAAmByG,C;;;;;;YAQvB5D,C,EACAS,C,EACAuF,C,EAAAA;MAEIjH,KAAAA,CAAAA,OAAAA,CAAciH,CAAdjH,C,EAA6B;aACzBmF,CAAAA,GAAcnF,KAAAA,CAAMiH,CAAAA,CAAAA,MAANjH,C,EACXR,CAAAA,GAAI,C,EAAGC,CAAAA,GAAIwH,CAAAA,CAAAA,M,EAAqBzH,CAAAA,GAAIC,C,EAAGD,CAAAA,E,EAAAA;AAC9C2F,MAAAA,CAAAA,CAAQ3F,CAAR2F,CAAAA,GAAagC,EAAAA,CAAclG,CAAdkG,EAAmBzF,CAAnByF,EAA2BF,CAAAA,CAAazH,CAAbyH,CAA3BE,CAAbhC;;;;;;AAEG,MAAqB,SAAjB8B,CAAJ,EAAIA;;;;uBAKOhG,CAAAA,CAAAA,KAAAA,CAAAA,WAAAA,CAAsBgG,CAAtBhG,C,IAAsBgG,KAKhB5H,CALgB4H,MAIhCpC,CAAAA,GAAamC,CAAAA,CAAc/F,CAAd+F,EAAmB7H,CAAnB6H,EAA8BtF,CAA9BsF,EAAsChJ,CAAAA,EAAtCgJ,CAJmBC,IAKJ,IALIA,GAKGpC,C,GAElCkC,EAAAA,CAAS9F,CAAT8F,EAAcE,CAAAA,CAAAA,UAAdF,EAAuCrF,CAAvCqF,EAA+CE,CAA/CF,C;;;WAmET9F,C,EACA9B,C,EACAuC,C,EACAtD,C,EAAAA;;;MAGMgJ,CAAAA,GAAUjI,CAAAA,KAAcwD,CAAAA,CAAAA,UAAAA,CAAiB,OAAjBA,C;MAGxBxG,CAAAA,GAAYiL,CAAAA,GAEdjI,CAFciI,GACdxC,CAAAA,CAAwBzF,CAAxByF,EAAmC,YAAnCA,C;;MAEoB,YAAA,OAAA,C,EAAA;AAIxBxG,IAAAA,CAAAA,CAAAA,UAAAA,GAAkBjC,CAAlBiC;QACa,IAAIqD,CAAJ,CAAsBtF,CAAtB,EAAgCgD,CAAhC,EAA2CuC,CAA3C,EAAmDT,CAAnD,C;;aAETvF,C,EACA2L,CAAAA,GAAAA,CAAY,C,EACZC,CAAAA,GAAAA,CAAc,C,EAAA,KACcjI,CADd,MACV3D,CAAAA,GAAOqI,CAAAA,CAAAA,IAAAA,EADG,C,GACyB;UAEnChH,CAAAA,GAAYwE,CAAAA,CAAQ7F,CAAR6F,C;UACZ6C,CAAAA,GAAY5C,CAAAA,CAAkB9F,CAAlB8F,EAAwBP,CAAAA,CAAAA,SAAxBO,C;UACZ0F,CAAAA,GAAapC,CAAAA,CAAcpJ,CAAdoJ,C;UACb5H,CAAAA,GAAWoE,CAAAA,CAAWvE,CAAXuE,EAAsB8C,CAAtB9C,C;UACXuD,CAAAA,GAAaD,CAAAA,CAAwBzF,CAAxByF,EAAmC1H,CAAnC0H,C;UACbtH,CAAAA,GAAe6B,CAAAA,GAAAA,GAAAA,GAAWjC,C;uBAE5BT,OAAAA,CAAAA,GAAAA,CAAAA,Q,IAAyCiH,C,IAAoBvH,C,IAC/DuH,CAAAA,CAAAA,sBAAAA,CAAwCvH,CAAxCuH,EAAkD3G,CAAlD2G,C;UAKE6D,CAAAA,GAAAA,KAAAA,C;UAEEhC,CAAAA,GAAY5C,CAAAA,CAAAA,SAAAA,CAAgBxG,CAAhBwG,C;;eACAtD,C,KAAdkG,C,IAA2D,cAAA,OAAA,CAAA,CAAfxI,CAAe,C,EAAfA;YAG9CkE,CAAAA,CAAAA,cAAAA,GAAqB9E,CAArB8E,EACAA,CAAAA,CAAAA,SAAAA,GAAgB9B,CADhB8B,EAEAA,CAAAA,CAAAA,cAAAA,GAAqB3D,CAFrB2D,EAGAA,CAAAA,CAAAA,SAAAA,GAAgBlE,CAHhBkE,E,KAOmB5B,C,KAAfwF,C,KACFzG,CAAAA,CAAK8I,CAAL9I,CAAAA,GAAmByG,C,CARrB5D,EAWAsG,CAAAA,GAAiBhC,CAAAA,CAAUxI,CAAVwI,CAAAA,CACfnH,CADemH,EAEfnB,CAAAA,IAAapG,CAAAA,EAFEuH,EAGf5C,CAHe4C,EAIftE,CAJesE,CAXjBtE,EAeEA,KAGwB5B,CAHxB4B,KAGEvF,CAAAA,CAAAA,YAHFuF,KAMAsG,CAAAA,GAAiBC,EAAAA,CACfvG,CADeuG,EAEfrL,CAFeqL,EAGfzK,CAHeyK,EAIflK,CAJekK,EAKfnG,CAAAA,CAAgB3F,CAAhB2F,CALemG,EAMdpJ,CAAAA,CAAK8I,CAAL9I,CAAAA,IAA6BJ,CAAAA,EANfwJ,EAOfD,CAPeC,CANjBvG,CAfFA,E,KAiCuB5B,C,KAArBqE,C,IACmB,SAAnB6D,C,IAAAA,CACC7D,CAAAA,CAAAA,eAAAA,CAAiCvH,CAAjCuH,EAA2C3G,CAA3C2G,C,EAA2C3G;;;;mBAMrCrB,CAAAA,CAAAA,Y,GAET6L,CAAAA,GAAiB1C,C,GAAAA,KAIJxF,CAJIwF,MAGX/E,CAAAA,GAAO8E,CAAAA,CAAsBzF,CAAtByF,EAAiC1H,CAAjC0H,CAHIC,IAKf0C,CAAAA,GAAiBE,EAAAA,CACfxG,CADewG,EAEf3H,CAFe2H,EAGftL,CAHesL,EAIf1K,CAJe0K,EAKfpG,CAAAA,CAAgB3F,CAAhB2F,CALeoG,EAMfrJ,CAAAA,CAAK8I,CAAL9I,CANeqJ,CALF5C,GAagB,YAAA,OAAA,CAAA,IAA2B,SAAfA,CAAZ,KAE/B0C,CAAAA,GAAiB1C,CAFc,C;;;eAUdxF,C,KAAnBkI,C,IAAAA,KACqBlI,CADrBkI,KACA7D,C,IACAA,CAAAA,CAAAA,eAAAA,CAAiCvH,CAAjCuH,EAA2C3G,CAA3C2G,C,EAA2C3G;AAI3CuK,QAAAA,CAAAA,GAAAA,CAAc,CAAdA,EACAlJ,CAAAA,CAAK8I,CAAL9I,CAAAA,GAAmB,IADnBkJ;aAEK;AAAA,YAAA,KAAuBjI,CAAvB,KAAIkI,CAAJ,EAAIA;;;;aAKG,C;UACPL,C,IAAcK,C;;;;AAInBD,IAAAA,CAAAA,KAAarG,CAAAA,CAAAA,OAAAA,GAAAA,CAAc,CAA3BqG,CAAAA;gBACcA,C,IAAAA,CAAgBD,C,GAAAA,KAAYhI,C,GAAYjB,C;;;;YA0H1D6C,C,EACA9E,C,EACAY,C,EACAO,C,EACAoE,C,EACAkG,C,EACA5E,C,EAAAA;MAEIhD,KAAAA,CAAAA,OAAAA,CAAcgD,CAAdhD,C,EAAuB;;aAKFX,C,KAArBqE,C,IACAA,CAAAA,CAAAA,cAAAA,CAAgCvH,CAAhCuH,EAA0C3G,CAA1C2G,C;;aACItF,CAAAA,GAAW4B,KAAAA,CAAMgD,CAAAA,CAAAA,MAANhD,C,EACRR,CAAAA,GAAI,C,EAAGC,CAAAA,GAAIuD,CAAAA,CAAAA,M,EAAexD,CAAAA,GAAIC,C,EAAGD,CAAAA,E,EAAK;UAEvCqI,CAAAA,GAAcL,EAAAA,CAClBvG,CADkBuG,EAElBrL,CAFkBqL,EAGlBzK,CAHkByK,EAITlK,CAAAA,GAAAA,GAAAA,GAAQkC,CAJCgI,EAKlB9F,CALkB8F,EAKlB9F,KAEarC,CAFbqC,KAEAkG,CAFAlG,GAEyBkG,CAAAA,CAASpI,CAAToI,CAFzBlG,GAEkClC,KAAKH,CAPrBmI,EAQlBxE,CAAAA,CAAOxD,CAAPwD,CARkBwE,C;;eAWAnI,C,KAAhBwI,C,IAA8BC,C,EAAAA;AAGhC1J,QAAAA,CAAAA,CAAKoB,CAALpB,CAAAA,GAAKoB,KAAqBH,CAArBG,KAAKqI,CAALrI,GAAiCqI,CAAjCrI,GAA+C,IAApDpB;;;;;;;;;AAKC,MAAe,QAAX4E,CAAJ,EAAIA;;;;MAgEE,YAAA,OAAA,CAAA,IACC,YAAA,OAAA,CAAA,IAA6C,YAAA,OAAA,CAAA,CAAA,U,EA/D3B;AACxB5E,IAAAA,CAAAA,GAAAA,KAAoBiB,CAApBjB,KAAOwJ,CAAPxJ,GAAgCJ,CAAAA,EAAhCI,GAA6CwJ,CAA7CxJ;;QACmB,YAAA,OAAA,C,EAAA;AACrB4I,MAAAA,CAAAA,GAAAA,CAAAA,CAAAA,CAAAA,EAAAA,CAAAA,EAAAA,CAAAA,EAAAA,CAAAA,CAAAA;;iBACAe,CAAAA,CAAAA,gB,EA1JA5I,CAAAA,GA0JA4I,CAAAA,CAAAA,KAAAA,CAAAA,WAAAA,CAAAA,CAAAA,KAAAA,C,EAzJAL,CAAAA,GAyJAK,CAAAA,CAAAA,U,EAxJA5L,CAAAA,GACJyI,CAAAA,CAAwBzF,CAAxByF,EAAmC,YAAnCA,CAAAA,IAAoD8C,C,EAGhC,YAAA,OAAA,CAAA,IACnBA,CAAAA,IAAoBvL,CAAAA,KAAauL,C,EAAAA;iDAGlCtG,CAAAA,CACE,6CACEjC,CADF,GAEE,6EAHJiC,EAKE,CALFA,C,WAQO/B,C;;AAwIH0I,QAAAA,CAAAA,CAAAA,UAAAA,GAnIY5L,CAmIZ4L;YAlIO,IAAItG,CAAJ,CAAsBtF,CAAtB,EAAgCgD,CAAhC,EAkIP4I,CAlIO,EAkIPA,CAlIO,C;;aAITT,CAAAA,GADAD,CAAAA,GAAAA,CAAY,C,EAAA,KAEgBhI,CAFhB,MAER3D,CAAAA,GAAOqI,CAAAA,CAAAA,IAAAA,EAFC,C,GAE2B;AAEnChH,UAAAA,CAAAA,GAAYwE,CAAAA,CAAQ7F,CAAR6F,CAAZxE;cACa+H,CAAAA,CAAcpJ,CAAdoJ,C;cACb5H,CAAAA,GAAWoE,CAAAA,CACfvE,CADeuE,EAEfE,CAAAA,CAAkB9F,CAAlB8F,EAuHEuG,CAAAA,CAAAA,SAvHFvG,CAFeF,C;cAIXhE,CAAAA,GAAe6B,CAAAA,GAAAA,GAAAA,GAAWjC,C;cAC1B2H,CAAAA,GAAaD,CAAAA,CAAwBzF,CAAxByF,EAAmC1H,CAAnC0H,C;cACb+C,CAAAA,GAmHFI,CAAAA,CAnHuBhL,CAmHvBgL,C;2BAjHAtL,OAAAA,CAAAA,GAAAA,CAAAA,Q,IAAyCiH,C,IAAoBvH,C,IAC/DuH,CAAAA,CAAAA,sBAAAA,CAAwCvH,CAAxCuH,EAAkD3G,CAAlD2G,C;cAKE6D,CAAAA,GAAAA,KAAAA,C;qBACAI,C,IAAAA,KAAmDtI,CAAnDsI,KAA6BjM,CAAAA,CAAAA,Y,GAE/B6L,CAAAA,GAAiBI,C,GAAAA,KACctI,CADdsI,KACRjM,CAAAA,CAAAA,YADQiM,GAGjBJ,CAAAA,GAAiB1C,CAHA8C,GAGA9C,KACQxF,CADRwF,KACR8C,CADQ9C,GAGjB0C,CAAAA,GAAiBC,EAAAA,CAkGfO,CAlGeP,EAEfrL,CAFeqL,EAGfzK,CAHeyK,EAIflK,CAJekK,EAKfnG,CAAAA,CAAgB3F,CAAhB2F,CALemG,EAkGfO,CAAAA,CA5FKb,CA4FLa,CAlGeP,EAOfG,CAPeH,CAHA3C,GAUf8C,KAMWtI,CANXsI,MAII7H,CAAAA,GAAO8E,CAAAA,CAAsBzF,CAAtByF,EAAiC1H,CAAjC0H,CAJX+C,IAOAJ,CAAAA,GAAiBE,EAAAA,CAoFjBM,CApFiBN,EAEf3H,CAFe2H,EAGftL,CAHesL,EAIf1K,CAJe0K,EAKfpG,CAAAA,CAAgB3F,CAAhB2F,CALeoG,EAoFjBM,CAAAA,CA9EOb,CA8EPa,CApFiBN,CAPjBE,GAe+B,YAAA,OAAA,CAAA,IAA2B,SAAf9C,CAAZ,KAE/B0C,CAAAA,GAAiB1C,CAFc,C;;mBAUdxF,C,KAAnBkI,C,IAAAA,KACqBlI,CADrBkI,KACA7D,C,IACAA,CAAAA,CAAAA,eAAAA,CAAiCvH,CAAjCuH,EAA2C3G,CAA3C2G,C,EAA2C3G;AAI3CuK,YAAAA,CAAAA,GAAAA,CAAc,CAAdA,EA4DES,CAAAA,CA3DGb,CA2DHa,CAAAA,GA3DiB,IADnBT;0BAE4BjI,C,KAAnBkI,C,EAA8B;qBAEhClI,C;;;iBAGK,C,EAqDV0I,CAAAA,CApDGb,CAoDHa,CAAAA,GApDiBR,C;;;;AAInBD,QAAAA,CAAAA,KAgDES,CAAAA,CAAAA,OAAAA,GAAAA,CAhDyB,CAA3BT,CAAAA;YACID,CAAAA,GA+CFU,CA/CEV,GA+CFU,KA/Cc1I,C;;;;;;;2CAiDlB+B,CAAAA,CACE,2CACE9D,CADF,GAEE,qGAHJ8D,EAKE,CALFA,C;;;YAaFH,C,EACAnB,C,EACA3D,C,EACAY,C,EACA2E,C,EACAkG,C,EAAAA;MAEI5H,KAAAA,CAAAA,OAAAA,CAAcF,CAAdE,C,EAAqB;;aAGAX,C,KAArBqE,C,IACAA,CAAAA,CAAAA,cAAAA,CAAgCvH,CAAhCuH,EAA0C3G,CAA1C2G,C;;aACIsE,CAAAA,GAAchI,KAAAA,CAAMF,CAAAA,CAAAA,MAANE,C,EACXR,CAAAA,GAAI,C,EAAGC,CAAAA,GAAIK,CAAAA,CAAAA,M,EAAaN,CAAAA,GAAIC,C,EAAGD,CAAAA,E,EAAK;UACrCiH,CAAAA,GAAYgB,EAAAA,CAChBxG,CADgBwG,EAEhB3H,CAAAA,CAAKN,CAALM,CAFgB2H,EAGhBtL,CAHgBsL,EAIhB1K,CAJgB0K,EAKhB/F,CALgB+F,EAKhB/F,KACarC,CADbqC,KACAkG,CADAlG,GACyBkG,CAAAA,CAASpI,CAAToI,CADzBlG,GACkClC,KAAKH,CANvBoI,C;;eAQApI,C,KAAdoH,C,IAA4BqB,C,EAAAA;AAG9BE,QAAAA,CAAAA,CAAQxI,CAARwI,CAAAA,GAAQxI,KAAmBH,CAAnBG,KAAKiH,CAALjH,GAA+BiH,CAA/BjH,GAA2C,IAAnDwI;;;;;;;;;AAKC,SAAA,SAAIlI,CAAJ,GACE,IADF,GAGEkH,CAAAA,CACL/F,CADK+F,EAELlH,CAFKkH,EAGLtF,CAHKsF,EAGLtF,KACarC,CADbqC,KACAkG,CADAlG,GACyB1D,CAAAA,EADzB0D,GACsCkG,CAJjCZ,CAHF;;;YG9fgB8B,C,EAAeC,C,EAAAA;iBACnCD,C,GAAAA;AACHE,IAAAA,OAAAA,EAAAA,CAAAA,CAAAA,CAAAA,CAAAA,EAAAA,EACKF,CAAAA,CAAAA,OADLE,CAAAA,EACKF;AACHG,MAAAA,IAAAA,EAAAA,CAAAA,CAAAA,CAAAA,CAAAA,EAAAA,EACKH,CAAAA,CAAAA,OAAAA,CAAAA,IADLG,CAAAA,EACKH;AACHI,QAAAA,YAAAA,EAAcH;AADXD,OADLG;AADGH,KADLE;AADGF,G;;;YAWiBA,C,EAAAA;iBACjBA,C,GAAAA;AACHzE,IAAAA,KAAAA,EAAO8E,cAAAA,CAAeL,CAAAA,CAAAA,KAAfK;AADJL,G;;;YAgBqBA,C,EAAAA;SAPH,YAQGA,CAAAA,CAAAA,aARH,IAQmC,mBAARA,CAAAA,CAAAA,OAAAA,CAAAA,a;;;YAUhD5G,C,EACAkH,C,EAAAA;iBAEGlH,C,GAAAA;AACH8G,IAAAA,OAAAA,EAAAA,CAAAA,CAAAA,CAAAA,CAAAA,EAAAA,EACK9G,CAAAA,CAAAA,OADL8G,CAAAA,EACK9G;qBACHkH;AADGlH,KADL8G;AADG9G,G;;;YAyMQ4G,C,EAAAA;YAAuBA,C;;;YAS1BuC,C,EAAAA;YAAuBA,CAAAA,CAAAA,S,EAAeA,CAAAA,CAAAA,O;;;YADnCA,C,EAAAA;SAAuB,WAAhBA,CAAAA,CAAAA,O;;;YAQPA,C,EAAAA;SAAuB,WAAhBA,CAAAA,CAAAA,O;;;YAkCDvC,C,EAAAA;UAAO6C,EAAAA,CAAiB7C,CAAjB6C,C;;;YCpJd6B,C,EAAAA;SAAoB,eAAfjM,CAAAA,CAAQiM,CAARjM,C;;;YA8DkB8M,C,EAAKC,C,EAAAA;AACJ,2BAApBA,CAAAA,CAAAA,IAAoB,IACtBD,CAAAA,CAAAA,GAAAA,CAAQC,CAAAA,CAAAA,IAAAA,CAAAA,KAARD,CADsB;;;;YA7FlCzI,C,EACAvB,C,EACA8H,C,EACAD,C,EAAAA;aAkCoDwB,C,EAAGC,C,EAAAA;UACvCC,CAAAA,GAAYzB,CAAAA,CAAoBwB,CAAAA,CAAAA,IAApBxB,C,GAAoBwB;;;;SADqB,IAMlDnO,CAAAA,GAAI,CAN8C,EAM3CC,CAAAA,GAAImO,CAAAA,CAAAA,M,EAAkBpO,CAAAA,GAAIC,C,EAAGD,CAAAA,E,EAAK;mBAC3BoO,CAAAA,CAAUpO,CAAVoO,CAAAA,CAAUpO,Q,EACzBqO,CAAAA,GAAetM,CAAAA,CAAQiD,CAARjD,C,EACfuM,CAAAA,GAAgBC,EAAAA,CAAiBvJ,CAAjBuJ,C,EAGbC,CAAAA,GAAI,C,EAAGvO,CAAAA,GAAIqO,CAAAA,CAAAA,M,EAAsBE,CAAAA,GAAIvO,C,EAAGuO,CAAAA,E,EAAK;YAC9C1L,CAAAA,GAAOwL,CAAAA,CAAcE,CAAdF,C;cACsBxL,C,MACjC8K,CAAAA,CAAsB9K,CAAtB8K,CAAAA,GAA8BlB,CAAAA,CAAc5J,CAAd4J,C;;;AAKlCmB,MAAAA,CAAAA,CAAoBQ,CAApBR,CAAAA,GAAoC7I,CAApC6I;aAEO;AACLL,QAAAA,IAAAA,EAAMrR,IAAAA,CAAAA,eADD;AAEL2G,QAAAA,IAAAA,EAAM2K,EAAAA,CAASY,CAATZ;AAFD,O;;;;;;MAtDbL,CAAAA,GAAW,IAAIC,QAAJ,CAAajH,CAAb,C;MAEXwH,CAAAA,GAGFpP,CAAAA,E;MAEEqP,CAAAA,GAGFrP,CAAAA,E;MAGEsP,CAAAA,GAAyC,IAAIrR,GAAJ,E;eAG7CoI,C,EACAyI,iBAAAA,CAAkBF,CAAlBE,EAA4B;AAC1BC,IAAAA,KAAAA,EAAO;AACLQ,MAAAA,KAAAA,EAAAA,UAAO7R,CAAP6R,EAAO7R;YACAA,CAAAA,CAAAA,U,EAAAA;cAIC0G,CAAAA,GAAa1G,CAAAA,CAAAA,UAAAA,CAAAA,MAAAA,CAAAA,EAAAA,C;;cAGf0G,CAAAA,CAAAA,MAAAA,KAAsB1G,CAAAA,CAAAA,UAAAA,CAAAA,M,EAAAA;AAuF5BE,gBAAAA,CAAAA,GAAOC,EAAAA,CAnFkC+Q,CAAAA,CAAAA,OAAAA,EAmFlC/Q,CAAPD;4BACeA,C,IAAAA,CAAAA,GAQd6S,cAAAA,CAAe7S,CAAf6S,CAAAA,GA5FgC7I,CAAAA,CAAAA,gBAAAA,CA4FehK,CA5FfgK,CA4FhC6I,GAAuD,CAAC7S,CAAD,C,IAACA,iBAAAA,OAAAA,CAAAA,GAAAA,CAAAA,QAAAA,IAP7DwF,CAAAA,CACE,gFADFA,EAEE,EAFFA,CAO6DxF,E,IAHtD,E;gBAxFqB6R,CAAAA,CAAAA,MAAAA,CAAAA,CAAAA,EA6BnB,EA7BmBA,C;gBA+BhBQ,CAAAA,GAAqB5M,CAAAA,CAAgB3F,CAAhB2F,C;gBAG4B,MAArD4M,CAAAA,CAAAA,MAAAA,GAA4BC,CAAAA,CAAAA,MAAyB,GACjDA,CAAAA,CAAAA,MAAAA,CAAsBD,CAAtBC,CADiD,GAEjD,CACE;AACElB,cAAAA,IAAAA,EAAMrR,IAAAA,CAAAA,KADR;AAEE2G,cAAAA,IAAAA,EAAM2K,EAAAA,CAAS,YAATA;AAFR,aADF,C;2BAQDvR,C,GAAAA;0BACH0G,CADG1G;AAEHwR,cAAAA,YAAAA,EAAc;AACZF,gBAAAA,IAAAA,EAAMrR,IAAAA,CAAAA,aADM;4BAEZwS;AAFY;AAFXzS,a;;;;AA1DF,KADmB;AAoE1B0S,IAAAA,QAAAA,EAAU;AACRb,MAAAA,KAAAA,EAAAA,UAAO7R,CAAP6R,EAAO7R;AACLA,QAAAA,CAAAA,CAAAA,WAAAA,CAAAA,MAAAA,CAAAA,EAAAA,EAKG4R,CALH5R;OAFM;AASR6S,MAAAA,KAAAA,EAAAA,UAAO7S,CAAP6S,EAAO7S;YAEM4B,C;YADLkR,CAAAA,GAAc,GAAA,MAAA,CAAI9S,CAAAA,CAAAA,WAAJ,C;;aACT4B,C,IAAAA,C,EAAAA;AACTkR,UAAAA,CAAAA,CAAAA,IAAAA,CAAiBnB,CAAAA,CAAoB/P,CAApB+P,CAAjBmB;;;aACGzS,IAAMuB,C,IAAAA,C,EAAAA;AACTkR,UAAAA,CAAAA,CAAAA,IAAAA,CAAiBpB,CAAAA,CAAsB9P,CAAtB8P,CAAjBoB;;;uBACU9S,C,GAAAA;uBAAM8S;AAAN9S,S;;AAfN;AApEgB,GAA5BoR,C;;;YA0Fc1N,C,EAAAA;SAA6B;AAC7C4N,IAAAA,IAAAA,EAAMrR,IAAAA,CAAAA,IADuC;WAE7CyD;AAF6C,G;;;YAgCrB1D,C,EAAAA;MAClB4I,CAAAA,GAAkB,E;QAElB5I,C,EAAM;AACVgT,IAAAA,cAAAA,EAAAA,UAAgBC,CAAhBD,EAAgBC;AACdrK,MAAAA,CAAAA,CAAAA,IAAAA,CAAW/C,CAAAA,CAAQoN,CAARpN,CAAX+C;;AAFQ,G;;;;;;;AD5MgB+E,SAAAA,UAAAA,CAAAA,EAAAA;AAAwCC,aAAAA,CAAAA,CAAAA,CAAAA,EAAAA;AAqHrCtG,UAAAA,CAAAA,GAAAA,CAAAA,CAAAA,SAAAA;AAAAA,UAAAA,CAAAA,GAAAA,CAAAA,CAAAA,KAAAA;AAAAA,UAAAA,CAAAA,GAAAA,CAAAA,CAAAA,UAAAA;AAAAA,UAAAA,CAAAA,GAAAA,YAEvBoE,CAAAA,CAAAA,aAFuBpE;AAAAA,UAEvBoE,CAAAA,GAAAA,CAAAA,CAAAA,IAFuBpE;AAAAA,UAEvBoE,CAAAA,GAAAA,CAAAA,CAAAA,GAFuBpE;;oBAON1F;AAAnBmM,QAAAA,CAAAA,CAAyBU,MAAzBV,CAAyBU,CAAzBV;AACoBnM,YAAAA,CAAAA,GAAAA,CAAAA,CAAAA,IAAAA;;AACMA,QAAAA,EAAAA,CAAAA,CAAAA,CTiLhCsD,OSjLgCtD,ETiLhCsD,CSjLgCtD,CAAAA;AAAAA,QAAAA,EAAAA,CAAAA,CAAAA,CTkLhCsD,KSlLgCtD,ETkLhCsD,CSlLgCtD,CAAAA;;;AAAAA,UAAAA,QAAAA,CAAAA,EAAAA;AAKTc,YAAAA,CAAAA,GAAAA,EAAAA,CACCgM,CADDhM,EACCgM,CADDhM,EACCgM,CADDhM,CAAAA,CACyBA,YADzBA;;;AAGfgJ,cAAAA,CAAAA,GAAAA,EAAAA,CACkB/C,CADlB+C,EACkB/C,CADlB+C,CAAAA;AAC+BlF,UAAAA,CAAAA,GACjC9D,CAAAA,CAAAA,IADiC8D;cAEjCmI,CAAAA,CAAAA,Y;;cAEAjM,EAAAA,CAAOiG,CAAPjG,EAAOiG,CAAPjG,EAAOiG,CAAPjG,CAAAA,CAA+BA,I;;;;YARM,IAAA,GAAA,E,EAczC6L,C;AAA4CK,MAAAA,CAAAA,IAAAA,CAAAA,CAAAA,CAAAA,EAE1CL,CAF0CK,CAAAA;AAEED,MAAAA,CAAAA,CAI9CH,CAAAA,CAAAA,SAJ8CG,EAI9CH,CAJ8CG,CAAAA;AAIHT,MAAAA,CAAAA,IAAAA,KAAAA,CAAAA,KAAAA,CAAAA,IAG5BS,CAAAA,CAAAA,CAAAA,CACb9J,SADa8J,EACb9J,CADa8J,CAH4BT;AAIJS,aAAAA;eAAAA;gBAAAA;qBAAAA;;AAAAA,OAAAA;;;AAGLnI,aAAAA,CAAAA,CAAAA,CAAAA,EAAAA;AAhElCA,UAAAA,CAAAA,GAEwCmC,EAAAA,CAAM1B,CAAN0B,EAAanC,CAAbmC,CAFxCnC;AAAAA,UAEqDA,CAAAA,GAAAA,CAAAA,CAAAA,IAFrDA;AAAAA,UAEqDA,CAAAA,GAAAA,CAAAA,CAAAA,YAFrDA;;eAKI9D,C,GACF8K,CAAAA,GAAe,M,IAEf3I,CAAAA,CAAmB2B,CAAnB3B,EAA8B0C,CAA9B1C,CAAAA,EACA2I,CAAAA,GACGpC,CAAAA,IAA2C,iBAAf5E,CAAAA,CAAAA,OAAAA,CAAAA,aAA5B4E,GAEG,SAFHA,GACG,K;aAID;AACLiC,QAAAA,OAAAA,EAASG,CADJ;mBAELhH,CAFK;cAGL9D;AAHK,O;;;eAlCmB0K,C,EAAe7F,C,EAAAA;AACzCA,MAAAA,CAAAA,CAAAA,OAAAA,CAAAA,UAAqB4G,CAArB5G,EAAqB4G;SACNF,CAAAA,CAAKE,CAALF,CAAAA,KAAcA,CAAAA,CAAKE,CAALF,CAAAA,GAAY,EAA1BA,C,EAA0B,I,CAC7Bb,CAAAA,CAAAA,G;cAEGA,CAAAA,CAAAA,G,KACXY,CAAAA,CAAAA,GAAAA,CACEZ,CAAAA,CAAAA,GADFY,EAE2B,mBAARZ,CAAAA,CAAAA,OAAAA,CAAAA,aAAQ,GACrBiB,EAAAA,CAAgBjB,CAAhBiB,EAAoB,mBAApBA,CADqB,GAErBjB,CAJNY,C;OALJzG;;;eAfwBf,C,EAAAA;UA9FL,eA+FMA,CAAAA,CAAAA,aA/FN,IASsC,mBAsFhCA,CAAAA,CAAAA,OAAAA,CAAAA,a,EAAY;;gBAEV8H,EAAAA,CAAgBrH,CAAhBqH,EAAuB9H,CAAvB8H,EAAkC1M,CAAlC0M,CAAAA,CAAkC1M,Y;cACvD2F,CAAAA,CAAAA,I,KACFwG,CAAAA,CAAAA,GAAAA,CAAmBnM,CAAnBmM,GAEAQ,CAAAA,CADML,CAAAA,GAAoB,IAAI3N,GAAJ,EAC1BgO,EAA4ChH,CAA5CgH,CAFAR,EAGAS,CAAAA,CAAyBhI,CAAzBgI,EAAoCN,CAApCM,C;;;;eAxBJhI,C,EACA0H,C,EAAAA;AAGAA,MAAAA,CAAAA,CAAAA,OAAAA,CAAAA,UAA0BtM,CAA1BsM,EAA0BtM;YACpBA,CAAAA,KAAQ4E,CAAAA,CAAAA,G,EAAe;cACnB4G,CAAAA,GAAKY,CAAAA,CAAAA,GAAAA,CAAQpM,CAARoM,C;qBACPZ,C,KACFY,CAAAA,CAAAA,MAAAA,CAAWpM,CAAXoM,GACAI,CAAAA,CAAAA,kBAAAA,CAA0BC,EAAAA,CAAgBjB,CAAhBiB,EAAoB,aAApBA,CAA1BD,C;;OALNF;;;eAtBAA,C,EACA3G,C,EAAAA;WAEqB5D,C,KAAjB4D,C,IAEFA,CAAAA,CAAAA,OAAAA,CAAAA,SAAAA,CAAAA,CAAqB4G,CAArB5G,EAAqB4G;YACb1L,CAAAA,GAAOwL,CAAAA,CAAKE,CAALF,C;;iBACAtK,C,KAATlB,C,EAAoB;AACtBwL,UAAAA,CAAAA,CAAKE,CAALF,CAAAA,GAAY,EAAZA;cACa,C;;eAARhM,IAAW8B,CAAAA,GAAItB,CAAAA,CAAAA,M,EAAaqB,CAAAA,GAAIC,C,EAAGD,CAAAA,E,EAAAA;AACtCoK,YAAAA,CAAAA,CAAAA,GAAAA,CAAsBzL,CAAAA,CAAKqB,CAALrB,CAAtByL;;;OALN3G,C;;;eA2KGoI,C,EAAAA;;;UAEOC,CAAAA,GAA0BpJ,CAAAA,CAAAA,OAAAA,CAAAA,a;UACA;AAC9BA,QAAAA,SAAAA,EAAWqJ,EAAAA,CAAgBrJ,CAAhBqJ,EAA2BxC,CAA3BwC,CADmB;AAE9BnN,QAAAA,IAAAA,EAAMiN,CAAAA,CAAAA,IAFwB;AAG9BzO,QAAAA,KAAAA,EAAOyO,CAAAA,CAAAA,KAHuB;AAI9BG,QAAAA,UAAAA,EAAYH,CAAAA,CAAAA;AAJkB,O;;UAQnB,wBAAXC,CAAW,IACC,kBAAXA,CAAW,IAA6B,cAAZvC,C,EAAAA;AAE7B/F,QAAAA,CAAAA,CAAAA,KAAAA,GAAAA,CAAe,CAAfA,EACA8G,CAAAA,CAAAA,kBAAAA,CACEC,EAAAA,CAAgB7H,CAAhB6H,EAA2B,cAA3BA,CADFD,CADA9G;;;;;;;;UArNCqG,CAAAA,GAAO,E;QAEZ1G,CAAAA,GAAQ,IAAI2C,CAAJ,CACZ+D,CAAAA,CAAAA,MAAAA,GAAc,IAAIlB,CAAJ,CAAqBkB,CAAAA,CAAAA,MAArB,CAAdA,GAAmCA,KAAehK,CADtC,EAEZgK,CAAAA,CAAAA,SAFY,EAGZA,CAAAA,CAAAA,OAHY,EAIZA,CAAAA,CAAAA,UAJY,EAKZA,CAAAA,CAAAA,IALY,C;;QASVA,CAAAA,CAAAA,O,EAAc;UACVpK,CAAAA,GAAUoK,CAAAA,CAAAA,O;UAChBE,CAAAA,GAAYtK,CAAAA,CAAAA,IAAAA,GAAAA,IAAAA,CAAAA,SAAAA,CAAAA,CAAoBuK,CAApBvK,EAAoBuK;AAClB7G,YAAAA,CAAAA,GAAAA,CAAAA,CAAAA,IAAAA;AAAAA,YAAY1D,CAAAA,GAAAA,CAAZ0D;UToTFvE,C,EAAM,C;;aACfrC,IAAMuB,C,IAAAA,C,EAAgB;cACnBuD,CAAAA,GAAWvD,CAAAA,CAAAA,OAAAA,CAAY,GAAZA,C;cACX6B,CAAAA,GAAY7B,CAAAA,CAAAA,KAAAA,CAAU,CAAVA,EAAauD,CAAbvD,C;cACDA,CAAAA,CAAAA,KAAAA,CAAUuD,CAAAA,GAAW,CAArBvD,C;;kBACTA,CAAAA,CAAAA,UAAAA,CAAe,CAAfA,C;iBACD,G;AACHwD,cAAAA,EAAAA,CAAU3B,CAAV2B,EAAqB5D,CAArB4D,ES3T+B0I,CAAAA,CT2TQlM,CS3TRkM,CT2T/B1I,CAAAA;;;iBAEG,G;AACHC,cAAAA,CAAAA,CAAY5B,CAAZ4B,EAAuB7D,CAAvB6D,ES9T+ByI,CAAAA,CT8TUlM,CS9TVkM,CT8T/BzI,CAAAA;;;;AAINC,QAAAA,CAAAA;oBACe/B,C;OSpUDA,C;;;QAKRwK,CAAAA,GAAiB,IAAIxN,GAAJ,E;QACjByN,CAAAA,GAAoB,IAAIxL,GAAJ,E;QACpByL,CAAAA,GAA4B3L,CAAAA,E;qBAyI3BuM,C,EAAAA;AACCC,MAAAA,CAAAA,GAAwBC,KAAAA,CAANF,CAAME,CAAxBD;UAIAE,CAAAA,GAAenB,CAAAA,GAKfuB,QAAAA,CAAAA,SAAAA,CAAAA,CADAD,IAAAA,CAAAA,CAAAA,CAAAA,CADAF,MAAAA,CAAOC,WAAAA,CAAPD,CAAOC,CAAPD,CAAAA,CADAH,CACAG,CACAE,CACAC,CALevB,GAOhBwB,K;UAMHN,KAAAA,CADAQ,GAAAA,CAAAA,CAAAA,CAAAA,CADA/L,GAAAA,CAAAA,EAAAA,CAAAA,CADA8L,MAAAA,CAAO,CAACN,CAAD,EAAeF,CAAf,CAAPQ,CACA9L,CACA+L,CACAR,C;UAIIS,CAAAA,GAIJT,KAAAA,CADAvL,GAAAA,CAAAA,CAAAA,CAAAA,CADAkM,MAAAA,CAAAA,EAAAA,CAAAA,CADAD,CACAC,CACAlM,CACAuL,C;UAOAvL,GAAAA,CAAAA,EAAAA,CAAAA,CADAkM,MAAAA,CAAAA,EAAAA,CAAAA,CADAF,CACAE,CACAlM,C;UAQAA,GAAAA,CAAAA,CAAAA,CAAAA,CADAkM,MAAAA,CAAAA,EAAAA,CAAAA,CADAF,CACAE,CACAlM,C;UAsCAA,GAAAA,CAAAA,CAAAA,CAAAA,CATAuM,CAAAA,CACEC,KAAAA,CAAM,CAGFN,MAAAA,CAAAA,EAAAA,CAAAA,CADAD,CACAC,CAHE,EAKJQ,CALI,CAANF,CADFD,CASAvM,C;mBAGW,CAAC2M,CAAD,EAAUC,CAAV,C;;GAnPazC;;;;;;;AClFGC,MAAAA,CAAAA,GAAAA,CAAAA,CAAAA,MAAAA;;AAEMA,aAAAA,CAAAA,CAAAA,CAAAA,EAAAA;;;;AAuEThM,aAAAA,CAAAA,CAAAA,CAAAA,EAAAA;AAnCCgM,UAAAA,CAAAA,GAAAA,CAAAA,CAAAA,GAAAA;AAAAA,UAAAA,CAAAA,GAAAA,CAAAA,CAAAA,KAAAA;;qDAK3B2C,CAAAA,CACID,GADJC,CACID,CADJC,C,GACID;;;AAIiB1O,QAAAA,CAAAA,GAAAA,SAAAA,EAAAA,CAwDvBsI,CAxDuBtI,EAyDvB+G,CAzDuB/G,EAyDvB+G;cAEMqI,CAAAA,GAA+C,E;cAC/CC,CAAAA,GAAyC,E;cACzCC,CAAAA,GAAW,IAAIC,QAAJ,CAAajH,CAAb,C;gBAGfvB,C,EACAyI,iBAAAA,CAAkBF,CAAlBE,EAA4B;AAC1BC,YAAAA,KAAAA,EAAAA,UAAOrR,CAAPqR,EAAOrR;kBACDA,CAAAA,CAAAA,Y,EAAmB;AA6JvBE,oBAAAA,CAAAA,GAAOC,EAAAA,CA5JoB+Q,CAAAA,CAAAA,OAAAA,EA4JpB/Q,CAAPD;kBAEJA,CAAAA,IAAAA,CAAS6S,cAAAA,CAAe7S,CAAf6S,C,EAAe7S,iBAAAA,OAAAA,CAAAA,GAAAA,CAAAA,QAAAA,GACxB,0EADwBA,GACxB,E,EACA,E;oBAGKA,CAAAA,CAAAA,QAAAA,E;uBAlKmB;AAChBoR,kBAAAA,IAAAA,EAAMrR,IAAAA,CAAAA,mBADU;AAEhBuF,kBAAAA,aAAAA,EAAe;AACb8L,oBAAAA,IAAAA,EAAMrR,IAAAA,CAAAA,UADO;AAEb2G,oBAAAA,IAAAA,EAAM2K,EAAAA,CAASrR,CAATqR;AAFO,mBAFC;AAMhB3K,kBAAAA,IAAAA,EAAM2K,EAAAA,CAAYrR,CAAAA,GAAAA,oBAAZqR,CANU;AAOhBC,kBAAAA,YAAAA,EAAcxR,CAAAA,CAAAA;AAPE,iB;;aAJI;AAe1ByR,YAAAA,kBAAAA,EAAAA,UAAoBzR,CAApByR,EAAoBzR;AAClBgR,cAAAA,CAAAA,CAAAA,IAAAA,CAAwBhR,CAAxBgR;;AAhBwB,WAA5BI,C;iBAqBK,CAACJ,CAAD,EAAqBC,CAArB,C;SAtFgBrP,CAEsBkP,CAFtBlP,EAEsBkP,CAFtBlP,CAAAA;;AAInB+G,QAAAA,CAAAA,GAAAA,CAAAA,CAAAA,CAAAA,CAAAA;;;4BAdmEkI,CAAAA,CAAAA,M,EAAAA,CAAAA,GAAAA,C,EAAAA,CAAAA,E,EAiBf/M;;AAChBA,UAAAA,CAAAA,CACpC0M,CAAAA,CAAAA,CAAAA,CADoC1M,CAAAA,GACtB+B,CADsB/B;;;AACpC0M,QAAAA,CAAAA,GAFyD,CAEzDA;;AAGO1M,aAAAA,CAAAA,GAAAA,CAAAA,CAAAA,MAAAA,EAAAA,CAAAA,GAAAA,CAAAA,EAAAA,CAAAA,EAAAA,EAAAA;AACuBA,UAAAA,CAAAA,GAM9BiN,CAAAA,CAAAA,CAP8CjN,CAAAA,GAAAA,CAAAA,CAO9CiN,CAP8CjN,CAO9CiN,EALalL,aAKbkL,CAN8BjN,EACjB+B,CAAAA,GAKbkL,CAAAA,CAAAA,CAAAA,CAAAA,KAAAA,CAAAA,CAAAA,CAAAA,CAAAA,GAHoD7Q,EAGpD6Q,CAN8BjN,EAGsB5D,CAAAA,CAAAA,IAAAA,CAAAA,KAAAA,IAAAA,CAAAA,CAAAA,MAHtB4D,E,EAM9BiN,I,CAAAA;kBAAAA;;AAAAA,W,CAN8BjN;;;;;AAM9BiN,aAAAA,CAAAA,CAAAA,CAAAA,EAAAA;AArD4B3D,UAAAA,eAAAA,CAAAA,CAAAA,aAAAA,EAAAA;;;;AAErBA,UAIExG,CAJFwG;AAAAA,UAIExG,CAAAA,GAAAA,CAAAA,EAJFwG;;WAIExG,C,IAAAA,C,EAAAA;AACT8J,QAAAA,CAAAA,CAAiB9J,CAAjB8J,CAAAA,GAAyBD,CAAAA,CAAoB7J,CAApB6J,CAAAA,CAAoB7J,MAApB6J,CAAoB7J,CAApB6J,CAAzBC;;;qBAMGtD,C,GAAAA;AACHzE,QAAAA,KAAAA,EAAOiI,EAAAA,CACL1G,CADK0G,EAELxD,CAAAA,CAAAA,KAFKwD,EAGLF,CAHKE,EAILJ,CAJKI;AADJxD,O;;;eANuDuD,C,EAAAA;mBACnCA,CAAAA,CAAAA,G;;;;QAnBrBzG,CAAAA,GAASwC,iBAAAA,CAAkB2D,CAAlB3D,C;QAET4D,CAAAA,GAAmB,IAAI/P,GAAJ,E;QAEnBgQ,CAAAA,GAAmB,IAAIhQ,GAAJ,E;QAEnBiQ,CAAAA,GAAiClO,CAAAA,E;QAEjCmO,CAAAA,GAAuCnO,CAAAA,E;qBAkEtCuM,C,EAAAA;eAKHrL,GAAAA,CAAAA,CAAAA,CAAAA,CADA+L,GAAAA,CAAAA,CAAAA,CAAAA,CADAA,GAAAA,CAAAA,CAAAA,CAAAA,CADAV,CACAU,CACAA,CACA/L,C","sourcesContent":["import {\n  NamedTypeNode,\n  NameNode,\n  SelectionNode,\n  SelectionSetNode,\n  InlineFragmentNode,\n  FieldNode,\n  FragmentDefinitionNode,\n  GraphQLOutputType,\n  Kind,\n  isWrappingType,\n} from 'graphql';\n\nimport { SelectionSet, GraphQLFlatType } from '../types';\n\n/** Returns the name of a given node */\nexport const getName = (node: { name: NameNode }): string => node.name.value;\n\nexport const getFragmentTypeName = (node: FragmentDefinitionNode): string =>\n  node.typeCondition.name.value;\n\n/** Returns either the field's name or the field's alias */\nexport const getFieldAlias = (node: FieldNode): string =>\n  node.alias !== undefined ? node.alias.value : getName(node);\n\n/** Returns the SelectionSet for a given inline or defined fragment node */\nexport const getSelectionSet = (node: {\n  selectionSet?: SelectionSetNode;\n}): SelectionSet =>\n  node.selectionSet !== undefined ? node.selectionSet.selections : [];\n\nexport const getTypeCondition = ({\n  typeCondition,\n}: {\n  typeCondition?: NamedTypeNode;\n}): string | null =>\n  typeCondition !== undefined ? getName(typeCondition) : null;\n\nexport const isFieldNode = (node: SelectionNode): node is FieldNode =>\n  node.kind === Kind.FIELD;\n\nexport const isInlineFragment = (\n  node: SelectionNode\n): node is InlineFragmentNode => node.kind === Kind.INLINE_FRAGMENT;\n\nexport const unwrapType = (\n  type: null | undefined | GraphQLOutputType\n): GraphQLFlatType | null => {\n  if (isWrappingType(type)) {\n    return unwrapType(type.ofType);\n  }\n\n  return type || null;\n};\n","// These are guards that are used throughout the codebase to warn or error on\n// unexpected behaviour or conditions.\n// Every warning and error comes with a number that uniquely identifies them.\n// You can read more about the messages themselves in `docs/help.md`\n\nimport { Kind, ExecutableDefinitionNode, InlineFragmentNode } from 'graphql';\nimport { ErrorCode } from '../types';\n\ntype DebugNode = ExecutableDefinitionNode | InlineFragmentNode;\n\nconst helpUrl =\n  '\\nhttps://github.com/FormidableLabs/urql-exchange-graphcache/blob/master/docs/help.md#';\nconst cache = new Set<string>();\n\nexport const currentDebugStack: string[] = [];\n\nexport const pushDebugNode = (typename: void | string, node: DebugNode) => {\n  let identifier = '';\n  if (node.kind === Kind.INLINE_FRAGMENT) {\n    identifier = typename\n      ? `Inline Fragment on \"${typename}\"`\n      : 'Inline Fragment';\n  } else if (node.kind === Kind.OPERATION_DEFINITION) {\n    const name = node.name ? `\"${node.name.value}\"` : 'Unnamed';\n    identifier = `${name} ${node.operation}`;\n  } else if (node.kind === Kind.FRAGMENT_DEFINITION) {\n    identifier = `\"${node.name.value}\" Fragment`;\n  }\n\n  if (identifier) {\n    currentDebugStack.push(identifier);\n  }\n};\n\nconst getDebugOutput = (): string =>\n  currentDebugStack.length\n    ? '\\n(Caused At: ' + currentDebugStack.join(', ') + ')'\n    : '';\n\nexport function invariant(\n  condition: any,\n  message: string,\n  code: ErrorCode\n): asserts condition {\n  if (!condition) {\n    let errorMessage = message || 'Minfied Error #' + code + '\\n';\n    if (process.env.NODE_ENV !== 'production') {\n      errorMessage += getDebugOutput();\n    }\n\n    const error = new Error(errorMessage + helpUrl + code);\n    error.name = 'Graphcache Error';\n    throw error;\n  }\n}\n\nexport function warn(message: string, code: ErrorCode) {\n  if (!cache.has(message)) {\n    console.warn(message + getDebugOutput() + helpUrl + code);\n    cache.add(message);\n  }\n}\n","import { stringifyVariables } from 'urql/core';\nimport { Variables, FieldInfo } from '../types';\n\nexport const keyOfField = (fieldName: string, args?: null | Variables) =>\n  args ? `${fieldName}(${stringifyVariables(args)})` : fieldName;\n\nexport const fieldInfoOfKey = (fieldKey: string): FieldInfo => {\n  const parenIndex = fieldKey.indexOf('(');\n  if (parenIndex > -1) {\n    return {\n      fieldKey,\n      fieldName: fieldKey.slice(0, parenIndex),\n      arguments: JSON.parse(fieldKey.slice(parenIndex + 1, -1)),\n    };\n  } else {\n    return {\n      fieldKey,\n      fieldName: fieldKey,\n      arguments: null,\n    };\n  }\n};\n\nexport const joinKeys = (parentKey: string, key: string) =>\n  `${parentKey}.${key}`;\n\n/** Prefix key with its owner type Link / Record */\nexport const prefixKey = (owner: 'l' | 'r', key: string) => `${owner}|${key}`;\n","export const defer: (fn: () => void) => void =\n  process.env.NODE_ENV === 'production' && typeof Promise !== 'undefined'\n    ? Promise.prototype.then.bind(Promise.resolve())\n    : fn => setTimeout(fn, 0);\n","import {\n  Link,\n  EntityField,\n  FieldInfo,\n  StorageAdapter,\n  SerializedEntries,\n} from '../types';\nimport { invariant, currentDebugStack } from '../helpers/help';\nimport { fieldInfoOfKey, joinKeys, prefixKey } from './keys';\nimport { defer } from './timing';\n\ntype Dict<T> = Record<string, T>;\ntype KeyMap<T> = Map<string, T>;\ntype OptimisticMap<T> = Record<number, T>;\n\ninterface NodeMap<T> {\n  optimistic: OptimisticMap<KeyMap<Dict<T | undefined>>>;\n  base: KeyMap<Dict<T>>;\n  keys: number[];\n}\n\nexport interface InMemoryData {\n  persistenceScheduled: boolean;\n  persistenceBatch: SerializedEntries;\n  gcScheduled: boolean;\n  gcBatch: Set<string>;\n  queryRootKey: string;\n  refCount: Dict<number>;\n  refLock: OptimisticMap<Dict<number>>;\n  records: NodeMap<EntityField>;\n  links: NodeMap<Link>;\n  storage: StorageAdapter | null;\n}\n\nexport const makeDict = (): any => Object.create(null);\n\nlet currentData: null | InMemoryData = null;\nlet currentDependencies: null | Set<string> = null;\nlet currentOptimisticKey: null | number = null;\n\nconst makeNodeMap = <T>(): NodeMap<T> => ({\n  optimistic: makeDict(),\n  base: new Map(),\n  keys: [],\n});\n\n/** Before reading or writing the global state needs to be initialised */\nexport const initDataState = (\n  data: InMemoryData,\n  optimisticKey: number | null\n) => {\n  currentData = data;\n  currentDependencies = new Set();\n  currentOptimisticKey = optimisticKey;\n  if (process.env.NODE_ENV !== 'production') {\n    currentDebugStack.length = 0;\n  }\n};\n\n/** Reset the data state after read/write is complete */\nexport const clearDataState = () => {\n  const data = currentData!;\n\n  if (!data.gcScheduled && data.gcBatch.size > 0) {\n    data.gcScheduled = true;\n    defer(() => {\n      gc(data);\n    });\n  }\n\n  if (data.storage && !data.persistenceScheduled) {\n    data.persistenceScheduled = true;\n    defer(() => {\n      data.storage!.write(data.persistenceBatch);\n      data.persistenceScheduled = false;\n      data.persistenceBatch = makeDict();\n    });\n  }\n\n  currentData = null;\n  currentDependencies = null;\n  currentOptimisticKey = null;\n  if (process.env.NODE_ENV !== 'production') {\n    currentDebugStack.length = 0;\n  }\n};\n\n/** As we're writing, we keep around all the records and links we've read or have written to */\nexport const getCurrentDependencies = (): Set<string> => {\n  invariant(\n    currentDependencies !== null,\n    'Invalid Cache call: The cache may only be accessed or mutated during' +\n      'operations like write or query, or as part of its resolvers, updaters, ' +\n      'or optimistic configs.',\n    2\n  );\n\n  return currentDependencies;\n};\n\nexport const make = (queryRootKey: string): InMemoryData => ({\n  persistenceScheduled: false,\n  persistenceBatch: makeDict(),\n  gcScheduled: false,\n  queryRootKey,\n  gcBatch: new Set(),\n  refCount: makeDict(),\n  refLock: makeDict(),\n  links: makeNodeMap(),\n  records: makeNodeMap(),\n  storage: null,\n});\n\n/** Adds a node value to a NodeMap (taking optimistic values into account */\nconst setNode = <T>(\n  map: NodeMap<T>,\n  entityKey: string,\n  fieldKey: string,\n  value: T\n) => {\n  // Optimistic values are written to a map in the optimistic dict\n  // All other values are written to the base map\n  let keymap: KeyMap<Dict<T | undefined>>;\n  if (currentOptimisticKey) {\n    // If the optimistic map doesn't exist yet, it' created, and\n    // the optimistic key is stored (in order of priority)\n    if (map.optimistic[currentOptimisticKey] === undefined) {\n      map.optimistic[currentOptimisticKey] = new Map();\n      map.keys.unshift(currentOptimisticKey);\n    }\n\n    keymap = map.optimistic[currentOptimisticKey];\n  } else {\n    keymap = map.base;\n  }\n\n  // On the map itself we get or create the entity as a dict\n  let entity = keymap.get(entityKey) as Dict<T | undefined>;\n  if (entity === undefined) {\n    keymap.set(entityKey, (entity = makeDict()));\n  }\n\n  // If we're setting undefined we delete the node's entry\n  // On optimistic layers we actually set undefined so it can\n  // override the base value\n  if (value === undefined && !currentOptimisticKey) {\n    delete entity[fieldKey];\n  } else {\n    entity[fieldKey] = value;\n  }\n};\n\n/** Gets a node value from a NodeMap (taking optimistic values into account */\nconst getNode = <T>(\n  map: NodeMap<T>,\n  entityKey: string,\n  fieldKey: string\n): T | undefined => {\n  // This first iterates over optimistic layers (in order)\n  for (let i = 0, l = map.keys.length; i < l; i++) {\n    const optimistic = map.optimistic[map.keys[i]];\n    const node = optimistic.get(entityKey);\n    // If the node and node value exists it is returned, including undefined\n    if (node !== undefined && fieldKey in node) {\n      return node[fieldKey];\n    }\n  }\n\n  // Otherwise we read the non-optimistic base value\n  const node = map.base.get(entityKey);\n  return node !== undefined ? node[fieldKey] : undefined;\n};\n\n/** Clears an optimistic layers from a NodeMap */\nconst clearOptimisticNodes = <T>(map: NodeMap<T>, optimisticKey: number) => {\n  // Check whether the optimistic layer exists on the NodeMap\n  const index = map.keys.indexOf(optimisticKey);\n  if (index > -1) {\n    // Then delete it and splice out the optimisticKey\n    delete map.optimistic[optimisticKey];\n    map.keys.splice(index, 1);\n  }\n};\n\n/** Adjusts the reference count of an entity on a refCount dict by \"by\" and updates the gcBatch */\nconst updateRCForEntity = (\n  gcBatch: void | Set<string>,\n  refCount: Dict<number>,\n  entityKey: string,\n  by: number\n) => {\n  // Retrieve the reference count\n  const count = refCount[entityKey] !== undefined ? refCount[entityKey] : 0;\n  // Adjust it by the \"by\" value\n  const newCount = (refCount[entityKey] = (count + by) | 0);\n  // Add it to the garbage collection batch if it needs to be deleted or remove it\n  // from the batch if it needs to be kept\n  if (gcBatch !== undefined) {\n    if (newCount <= 0) gcBatch.add(entityKey);\n    else if (count <= 0 && newCount > 0) gcBatch.delete(entityKey);\n  }\n};\n\n/** Adjusts the reference counts of all entities of a link on a refCount dict by \"by\" and updates the gcBatch */\nconst updateRCForLink = (\n  gcBatch: void | Set<string>,\n  refCount: Dict<number>,\n  link: Link | undefined,\n  by: number\n) => {\n  if (typeof link === 'string') {\n    updateRCForEntity(gcBatch, refCount, link, by);\n  } else if (Array.isArray(link)) {\n    for (let i = 0, l = link.length; i < l; i++) {\n      const entityKey = link[i];\n      if (entityKey) {\n        updateRCForEntity(gcBatch, refCount, entityKey, by);\n      }\n    }\n  }\n};\n\n/** Writes all parsed FieldInfo objects of a given node dict to a given array if it hasn't been seen */\nconst extractNodeFields = <T>(\n  fieldInfos: FieldInfo[],\n  seenFieldKeys: Set<string>,\n  node: Dict<T> | undefined\n) => {\n  if (node !== undefined) {\n    for (const fieldKey in node) {\n      if (!seenFieldKeys.has(fieldKey)) {\n        // If the node hasn't been seen the serialized fieldKey is turnt back into\n        // a rich FieldInfo object that also contains the field's name and arguments\n        fieldInfos.push(fieldInfoOfKey(fieldKey));\n        seenFieldKeys.add(fieldKey);\n      }\n    }\n  }\n};\n\n/** Writes all parsed FieldInfo objects of all nodes in a NodeMap to a given array */\nconst extractNodeMapFields = <T>(\n  fieldInfos: FieldInfo[],\n  seenFieldKeys: Set<string>,\n  entityKey: string,\n  map: NodeMap<T>\n) => {\n  // Extracts FieldInfo for the entity in the base map\n  extractNodeFields(fieldInfos, seenFieldKeys, map.base.get(entityKey));\n\n  // Then extracts FieldInfo for the entity from the optimistic maps\n  for (let i = 0, l = map.keys.length; i < l; i++) {\n    const optimistic = map.optimistic[map.keys[i]];\n    extractNodeFields(fieldInfos, seenFieldKeys, optimistic.get(entityKey));\n  }\n};\n\n/** Garbage collects all entities that have been marked as having no references */\nexport const gc = (data: InMemoryData) => {\n  // Reset gcScheduled flag\n  data.gcScheduled = false;\n  // Iterate over all entities that have been marked for deletion\n  // Entities have been marked for deletion in `updateRCForEntity` if\n  // their reference count dropped to 0\n  data.gcBatch.forEach(entityKey => {\n    // Check first whether the reference count is still 0\n    const rc = data.refCount[entityKey] || 0;\n    if (rc <= 0) {\n      // Each optimistic layer may also still contain some references to marked entities\n      for (const optimisticKey in data.refLock) {\n        const refCount = data.refLock[optimisticKey];\n        const locks = refCount[entityKey] || 0;\n        // If the optimistic layer has any references to the entity, don't GC it,\n        // otherwise delete the reference count from the optimistic layer\n        if (locks > 0) return;\n        delete refCount[entityKey];\n      }\n\n      // All conditions are met: The entity can be deleted\n\n      // Delete the reference count, and delete the entity from the GC batch\n      delete data.refCount[entityKey];\n      data.gcBatch.delete(entityKey);\n\n      // Delete the record and for each of its fields, delete them on the persistence\n      // layer if one is present\n      // No optimistic data needs to be deleted, as the entity is not being referenced by\n      // anything and optimistic layers will eventually be deleted anyway\n      const recordsNode = data.records.base.get(entityKey);\n      if (recordsNode !== undefined) {\n        data.records.base.delete(entityKey);\n        if (data.storage) {\n          for (const fieldKey in recordsNode) {\n            const key = prefixKey('r', joinKeys(entityKey, fieldKey));\n            data.persistenceBatch[key] = undefined;\n          }\n        }\n      }\n\n      // Delete all the entity's links, but also update the reference count\n      // for those links (which can lead to an unrolled recursive GC of the children)\n      const linkNode = data.links.base.get(entityKey);\n      if (linkNode !== undefined) {\n        data.links.base.delete(entityKey);\n        for (const fieldKey in linkNode) {\n          // Delete all links from the persistence layer if one is present\n          if (data.storage) {\n            const key = prefixKey('l', joinKeys(entityKey, fieldKey));\n            data.persistenceBatch[key] = undefined;\n          }\n\n          updateRCForLink(data.gcBatch, data.refCount, linkNode[fieldKey], -1);\n        }\n      }\n    } else {\n      data.gcBatch.delete(entityKey);\n    }\n  });\n};\n\nconst updateDependencies = (entityKey: string, fieldKey?: string) => {\n  if (fieldKey !== '__typename') {\n    if (entityKey !== currentData!.queryRootKey) {\n      currentDependencies!.add(entityKey);\n    } else if (fieldKey !== undefined) {\n      currentDependencies!.add(joinKeys(entityKey, fieldKey));\n    }\n  }\n};\n\n/** Reads an entity's field (a \"record\") from data */\nexport const readRecord = (\n  entityKey: string,\n  fieldKey: string\n): EntityField => {\n  updateDependencies(entityKey, fieldKey);\n  return getNode(currentData!.records, entityKey, fieldKey);\n};\n\n/** Reads an entity's link from data */\nexport const readLink = (\n  entityKey: string,\n  fieldKey: string\n): Link | undefined => {\n  updateDependencies(entityKey, fieldKey);\n  return getNode(currentData!.links, entityKey, fieldKey);\n};\n\n/** Writes an entity's field (a \"record\") to data */\nexport const writeRecord = (\n  entityKey: string,\n  fieldKey: string,\n  value: EntityField\n) => {\n  updateDependencies(entityKey, fieldKey);\n  setNode(currentData!.records, entityKey, fieldKey, value);\n  if (currentData!.storage && !currentOptimisticKey) {\n    const key = prefixKey('r', joinKeys(entityKey, fieldKey));\n    currentData!.persistenceBatch[key] = value;\n  }\n};\n\nexport const hasField = (entityKey: string, fieldKey: string): boolean =>\n  readRecord(entityKey, fieldKey) !== undefined ||\n  readLink(entityKey, fieldKey) !== undefined;\n\n/** Writes an entity's link to data */\nexport const writeLink = (\n  entityKey: string,\n  fieldKey: string,\n  link: Link | undefined\n) => {\n  const data = currentData!;\n  // Retrieve the reference counting dict or the optimistic reference locking dict\n  let refCount: Dict<number>;\n  // Retrive the link NodeMap from either an optimistic or the base layer\n  let links: KeyMap<Dict<Link | undefined>> | undefined;\n  // Set the GC batch if we're not optimistically updating\n  let gcBatch: void | Set<string>;\n  if (currentOptimisticKey) {\n    // The refLock counters are also reference counters, but they prevent\n    // garbage collection instead of being used to trigger it\n    refCount =\n      data.refLock[currentOptimisticKey] ||\n      (data.refLock[currentOptimisticKey] = makeDict());\n    links = data.links.optimistic[currentOptimisticKey];\n  } else {\n    if (data.storage) {\n      const key = prefixKey('l', joinKeys(entityKey, fieldKey));\n      data.persistenceBatch[key] = link;\n    }\n    refCount = data.refCount;\n    links = data.links.base;\n    gcBatch = data.gcBatch;\n  }\n\n  // Retrieve the previous link for this field\n  const prevLinkNode = links !== undefined ? links.get(entityKey) : undefined;\n  const prevLink = prevLinkNode !== undefined ? prevLinkNode[fieldKey] : null;\n\n  // Update dependencies\n  updateDependencies(entityKey, fieldKey);\n  // Update the link\n  setNode(data.links, entityKey, fieldKey, link);\n  // First decrease the reference count for the previous link\n  updateRCForLink(gcBatch, refCount, prevLink, -1);\n  // Then increase the reference count for the new link\n  updateRCForLink(gcBatch, refCount, link, 1);\n};\n\n/** Removes an optimistic layer of links and records */\nexport const clearOptimistic = (data: InMemoryData, optimisticKey: number) => {\n  // We also delete the optimistic reference locks\n  delete data.refLock[optimisticKey];\n  clearOptimisticNodes(data.records, optimisticKey);\n  clearOptimisticNodes(data.links, optimisticKey);\n};\n\n/** Return an array of FieldInfo (info on all the fields and their arguments) for a given entity */\nexport const inspectFields = (entityKey: string): FieldInfo[] => {\n  const { links, records } = currentData!;\n  const fieldInfos: FieldInfo[] = [];\n  const seenFieldKeys: Set<string> = new Set();\n  // Update dependencies\n  updateDependencies(entityKey);\n  // Extract FieldInfos to the fieldInfos array for links and records\n  // This also deduplicates by keeping track of fieldKeys in the seenFieldKeys Set\n  extractNodeMapFields(fieldInfos, seenFieldKeys, entityKey, links);\n  extractNodeMapFields(fieldInfos, seenFieldKeys, entityKey, records);\n  return fieldInfos;\n};\n\nexport const hydrateData = (\n  data: InMemoryData,\n  storage: StorageAdapter,\n  entries: SerializedEntries\n) => {\n  initDataState(data, 0);\n  for (const key in entries) {\n    const dotIndex = key.indexOf('.');\n    const entityKey = key.slice(2, dotIndex);\n    const fieldKey = key.slice(dotIndex + 1);\n    switch (key.charCodeAt(0)) {\n      case 108:\n        writeLink(entityKey, fieldKey, entries[key] as Link);\n        break;\n      case 114:\n        writeRecord(entityKey, fieldKey, entries[key]);\n        break;\n    }\n  }\n  clearDataState();\n  data.storage = storage;\n};\n","import { FieldNode, InlineFragmentNode, FragmentDefinitionNode } from 'graphql';\n\nimport { warn, pushDebugNode } from '../helpers/help';\nimport { hasField } from '../store/data';\nimport { Store, keyOfField } from '../store';\n\nimport {\n  Fragments,\n  Variables,\n  SelectionSet,\n  DataField,\n  NullArray,\n  Data,\n} from '../types';\n\nimport {\n  SchemaPredicates,\n  getTypeCondition,\n  getFieldArguments,\n  shouldInclude,\n  isFieldNode,\n  isInlineFragment,\n  getSelectionSet,\n  getName,\n} from '../ast';\n\ninterface Context {\n  store: Store;\n  variables: Variables;\n  fragments: Fragments;\n  schemaPredicates?: SchemaPredicates;\n}\n\nconst isFragmentHeuristicallyMatching = (\n  node: InlineFragmentNode | FragmentDefinitionNode,\n  typename: void | string,\n  entityKey: string,\n  ctx: Context\n) => {\n  if (!typename) return false;\n  const typeCondition = getTypeCondition(node);\n  if (typename === typeCondition) return true;\n\n  warn(\n    'Heuristic Fragment Matching: A fragment is trying to match against the `' +\n      typename +\n      '` type, ' +\n      'but the type condition is `' +\n      typeCondition +\n      '`. Since GraphQL allows for interfaces `' +\n      typeCondition +\n      '` may be an' +\n      'interface.\\nA schema needs to be defined for this match to be deterministic, ' +\n      'otherwise the fragment will be matched heuristically!',\n    16\n  );\n\n  return !getSelectionSet(node).some(node => {\n    if (!isFieldNode(node)) return false;\n    const fieldKey = keyOfField(\n      getName(node),\n      getFieldArguments(node, ctx.variables)\n    );\n    return !hasField(entityKey, fieldKey);\n  });\n};\n\nexport class SelectionIterator {\n  typename: void | string;\n  entityKey: string;\n  indexStack: number[];\n  context: Context;\n  selectionStack: SelectionSet[];\n\n  constructor(\n    typename: void | string,\n    entityKey: string,\n    select: SelectionSet,\n    ctx: Context\n  ) {\n    this.typename = typename;\n    this.entityKey = entityKey;\n    this.context = ctx;\n    this.indexStack = [0];\n    this.selectionStack = [select];\n  }\n\n  next(): void | FieldNode {\n    while (this.indexStack.length !== 0) {\n      const index = this.indexStack[this.indexStack.length - 1]++;\n      const select = this.selectionStack[this.selectionStack.length - 1];\n      if (index >= select.length) {\n        this.indexStack.pop();\n        this.selectionStack.pop();\n        continue;\n      } else {\n        const node = select[index];\n        if (!shouldInclude(node, this.context.variables)) {\n          continue;\n        } else if (!isFieldNode(node)) {\n          // A fragment is either referred to by FragmentSpread or inline\n          const fragmentNode = !isInlineFragment(node)\n            ? this.context.fragments[getName(node)]\n            : node;\n\n          if (fragmentNode !== undefined) {\n            if (process.env.NODE_ENV !== 'production') {\n              pushDebugNode(this.typename, fragmentNode);\n            }\n\n            const isMatching =\n              this.context.schemaPredicates !== undefined\n                ? this.context.schemaPredicates.isInterfaceOfType(\n                    getTypeCondition(fragmentNode),\n                    this.typename\n                  )\n                : isFragmentHeuristicallyMatching(\n                    fragmentNode,\n                    this.typename,\n                    this.entityKey,\n                    this.context\n                  );\n\n            if (isMatching) {\n              this.indexStack.push(0);\n              this.selectionStack.push(getSelectionSet(fragmentNode));\n            }\n          }\n\n          continue;\n        } else if (getName(node) === '__typename') {\n          continue;\n        } else {\n          return node;\n        }\n      }\n    }\n\n    return undefined;\n  }\n}\n\nexport const ensureData = (x: DataField): Data | NullArray<Data> | null =>\n  x === undefined ? null : (x as Data | NullArray<Data>);\n","import {\n  SelectionNode,\n  DefinitionNode,\n  DocumentNode,\n  FragmentDefinitionNode,\n  OperationDefinitionNode,\n  valueFromASTUntyped,\n  Kind,\n} from 'graphql';\n\nimport { invariant } from '../helpers/help';\nimport { getName } from './node';\nimport { Fragments, Variables } from '../types';\n\nconst isFragmentNode = (node: DefinitionNode): node is FragmentDefinitionNode =>\n  node.kind === Kind.FRAGMENT_DEFINITION;\n\n/** Returns the main operation's definition */\nexport const getMainOperation = (\n  doc: DocumentNode\n): OperationDefinitionNode => {\n  const operation = doc.definitions.find(\n    node => node.kind === Kind.OPERATION_DEFINITION\n  ) as OperationDefinitionNode;\n\n  invariant(\n    !!operation,\n    'Invalid GraphQL document: All GraphQL documents must contain an OperationDefinition' +\n      'node for a query, subscription, or mutation.',\n    1\n  );\n\n  return operation;\n};\n\n/** Returns a mapping from fragment names to their selections */\nexport const getFragments = (doc: DocumentNode): Fragments =>\n  doc.definitions.filter(isFragmentNode).reduce((map: Fragments, node) => {\n    map[getName(node)] = node;\n    return map;\n  }, {});\n\nexport const shouldInclude = (\n  node: SelectionNode,\n  vars: Variables\n): boolean => {\n  const { directives } = node;\n  if (directives === undefined) {\n    return true;\n  }\n\n  // Finds any @include or @skip directive that forces the node to be skipped\n  for (let i = 0, l = directives.length; i < l; i++) {\n    const directive = directives[i];\n    const name = getName(directive);\n\n    // Ignore other directives\n    const isInclude = name === 'include';\n    if (!isInclude && name !== 'skip') continue;\n\n    // Get the first argument and expect it to be named \"if\"\n    const arg = directive.arguments ? directive.arguments[0] : null;\n    if (!arg || getName(arg) !== 'if') continue;\n\n    const value = valueFromASTUntyped(arg.value, vars);\n    if (typeof value !== 'boolean' && value !== null) continue;\n\n    // Return whether this directive forces us to skip\n    // `@include(if: false)` or `@skip(if: true)`\n    return isInclude ? !!value : !value;\n  }\n\n  return true;\n};\n","import { FieldNode, DocumentNode, FragmentDefinitionNode } from 'graphql';\n\nimport {\n  getFieldAlias,\n  getFragments,\n  getMainOperation,\n  getSelectionSet,\n  normalizeVariables,\n  getFragmentTypeName,\n  getName,\n  getFieldArguments,\n  SchemaPredicates,\n} from '../ast';\n\nimport {\n  NullArray,\n  Fragments,\n  Variables,\n  Data,\n  Link,\n  SelectionSet,\n  OperationRequest,\n} from '../types';\n\nimport {\n  Store,\n  getCurrentDependencies,\n  initDataState,\n  clearDataState,\n  makeDict,\n  joinKeys,\n  keyOfField,\n} from '../store';\n\nimport * as InMemoryData from '../store/data';\nimport { invariant, warn, pushDebugNode } from '../helpers/help';\nimport { SelectionIterator, ensureData } from './shared';\n\nexport interface WriteResult {\n  dependencies: Set<string>;\n}\n\ninterface Context {\n  parentTypeName: string;\n  parentKey: string;\n  parentFieldKey: string;\n  fieldName: string;\n  result: WriteResult;\n  store: Store;\n  variables: Variables;\n  fragments: Fragments;\n  optimistic?: boolean;\n  schemaPredicates?: SchemaPredicates;\n}\n\n/** Writes a request given its response to the store */\nexport const write = (\n  store: Store,\n  request: OperationRequest,\n  data: Data\n): WriteResult => {\n  initDataState(store.data, 0);\n  const result = startWrite(store, request, data);\n  clearDataState();\n  return result;\n};\n\nexport const startWrite = (\n  store: Store,\n  request: OperationRequest,\n  data: Data\n) => {\n  const operation = getMainOperation(request.query);\n  const result: WriteResult = { dependencies: getCurrentDependencies() };\n\n  const select = getSelectionSet(operation);\n  const operationName = store.getRootKey(operation.operation);\n\n  const ctx: Context = {\n    parentTypeName: operationName,\n    parentKey: operationName,\n    parentFieldKey: '',\n    fieldName: '',\n    variables: normalizeVariables(operation, request.variables),\n    fragments: getFragments(request.query),\n    result,\n    store,\n    schemaPredicates: store.schemaPredicates,\n  };\n\n  if (process.env.NODE_ENV !== 'production') {\n    pushDebugNode(operationName, operation);\n  }\n\n  if (operationName === ctx.store.getRootKey('query')) {\n    writeSelection(ctx, operationName, select, data);\n  } else {\n    writeRoot(ctx, operationName, select, data);\n  }\n\n  return result;\n};\n\nexport const writeOptimistic = (\n  store: Store,\n  request: OperationRequest,\n  optimisticKey: number\n): WriteResult => {\n  initDataState(store.data, optimisticKey);\n\n  const operation = getMainOperation(request.query);\n  const result: WriteResult = { dependencies: getCurrentDependencies() };\n\n  const mutationRootKey = store.getRootKey('mutation');\n  const operationName = store.getRootKey(operation.operation);\n  invariant(\n    operationName === mutationRootKey,\n    'writeOptimistic(...) was called with an operation that is not a mutation.\\n' +\n      'This case is unsupported and should never occur.',\n    10\n  );\n\n  if (process.env.NODE_ENV !== 'production') {\n    pushDebugNode(operationName, operation);\n  }\n\n  const ctx: Context = {\n    parentTypeName: mutationRootKey,\n    parentKey: mutationRootKey,\n    parentFieldKey: '',\n    fieldName: '',\n    variables: normalizeVariables(operation, request.variables),\n    fragments: getFragments(request.query),\n    result,\n    store,\n    schemaPredicates: store.schemaPredicates,\n    optimistic: true,\n  };\n\n  const data = makeDict();\n  const iter = new SelectionIterator(\n    operationName,\n    operationName,\n    getSelectionSet(operation),\n    ctx\n  );\n\n  let node: FieldNode | void;\n  while ((node = iter.next()) !== undefined) {\n    if (node.selectionSet !== undefined) {\n      const fieldName = getName(node);\n      const resolver = ctx.store.optimisticMutations[fieldName];\n\n      if (resolver !== undefined) {\n        // We have to update the context to reflect up-to-date ResolveInfo\n        ctx.fieldName = fieldName;\n\n        const fieldArgs = getFieldArguments(node, ctx.variables);\n        const resolverValue = resolver(fieldArgs || makeDict(), ctx.store, ctx);\n        const resolverData = ensureData(resolverValue);\n        writeRootField(ctx, resolverData, getSelectionSet(node));\n        data[fieldName] = resolverValue;\n        const updater = ctx.store.updates[mutationRootKey][fieldName];\n        if (updater !== undefined) {\n          updater(data, fieldArgs || makeDict(), ctx.store, ctx);\n        }\n      }\n    }\n  }\n\n  clearDataState();\n  return result;\n};\n\nexport const writeFragment = (\n  store: Store,\n  query: DocumentNode,\n  data: Data,\n  variables?: Variables\n) => {\n  const fragments = getFragments(query);\n  const names = Object.keys(fragments);\n  const fragment = fragments[names[0]] as FragmentDefinitionNode;\n  if (fragment === undefined) {\n    return warn(\n      'writeFragment(...) was called with an empty fragment.\\n' +\n        'You have to call it with at least one fragment in your GraphQL document.',\n      11\n    );\n  }\n\n  const typename = getFragmentTypeName(fragment);\n  const writeData = { __typename: typename, ...data } as Data;\n  const entityKey = store.keyOfEntity(writeData);\n  if (!entityKey) {\n    return warn(\n      \"Can't generate a key for writeFragment(...) data.\\n\" +\n        'You have to pass an `id` or `_id` field or create a custom `keys` config for `' +\n        typename +\n        '`.',\n      12\n    );\n  }\n\n  if (process.env.NODE_ENV !== 'production') {\n    pushDebugNode(typename, fragment);\n  }\n\n  const ctx: Context = {\n    parentTypeName: typename,\n    parentKey: entityKey,\n    parentFieldKey: '',\n    fieldName: '',\n    variables: variables || {},\n    fragments,\n    result: { dependencies: getCurrentDependencies() },\n    store,\n    schemaPredicates: store.schemaPredicates,\n  };\n\n  writeSelection(ctx, entityKey, getSelectionSet(fragment), writeData);\n};\n\nconst writeSelection = (\n  ctx: Context,\n  entityKey: string,\n  select: SelectionSet,\n  data: Data\n) => {\n  const isQuery = entityKey === ctx.store.getRootKey('query');\n  const typename = isQuery ? entityKey : data.__typename;\n  if (typeof typename !== 'string') return;\n\n  InMemoryData.writeRecord(entityKey, '__typename', typename);\n\n  const iter = new SelectionIterator(typename, entityKey, select, ctx);\n\n  let node: FieldNode | void;\n  while ((node = iter.next()) !== undefined) {\n    const fieldName = getName(node);\n    const fieldArgs = getFieldArguments(node, ctx.variables);\n    const fieldKey = keyOfField(fieldName, fieldArgs);\n    const fieldValue = data[getFieldAlias(node)];\n    const key = joinKeys(entityKey, fieldKey);\n\n    if (process.env.NODE_ENV !== 'production') {\n      if (fieldValue === undefined) {\n        const advice = ctx.optimistic\n          ? '\\nYour optimistic result may be missing a field!'\n          : '';\n\n        const expected =\n          node.selectionSet === undefined\n            ? 'scalar (number, boolean, etc)'\n            : 'selection set';\n\n        warn(\n          'Invalid undefined: The field at `' +\n            fieldKey +\n            '` is `undefined`, but the GraphQL query expects a ' +\n            expected +\n            ' for this field.' +\n            advice,\n          13\n        );\n\n        continue; // Skip this field\n      } else if (ctx.schemaPredicates && typename) {\n        ctx.schemaPredicates.isFieldAvailableOnType(typename, fieldName);\n      }\n    }\n\n    if (node.selectionSet === undefined) {\n      // This is a leaf node, so we're setting the field's value directly\n      InMemoryData.writeRecord(entityKey, fieldKey, fieldValue);\n    } else {\n      // Process the field and write links for the child entities that have been written\n      const fieldData = ensureData(fieldValue);\n      const link = writeField(ctx, key, getSelectionSet(node), fieldData);\n      InMemoryData.writeLink(entityKey, fieldKey, link);\n    }\n  }\n};\n\nconst writeField = (\n  ctx: Context,\n  parentFieldKey: string,\n  select: SelectionSet,\n  data: null | Data | NullArray<Data>\n): Link => {\n  if (Array.isArray(data)) {\n    const newData = new Array(data.length);\n    for (let i = 0, l = data.length; i < l; i++) {\n      const item = data[i];\n      // Append the current index to the parentFieldKey fallback\n      const indexKey = joinKeys(parentFieldKey, `${i}`);\n      // Recursively write array data\n      const links = writeField(ctx, indexKey, select, item);\n      // Link cannot be expressed as a recursive type\n      newData[i] = links as string | null;\n    }\n\n    return newData;\n  } else if (data === null) {\n    return null;\n  }\n\n  const entityKey = ctx.store.keyOfEntity(data);\n  const key = entityKey !== null ? entityKey : parentFieldKey;\n  const typename = data.__typename;\n\n  if (\n    ctx.store.keys[data.__typename] === undefined &&\n    entityKey === null &&\n    typeof typename === 'string' &&\n    !typename.endsWith('Connection') &&\n    !typename.endsWith('Edge') &&\n    typename !== 'PageInfo'\n  ) {\n    warn(\n      'Invalid key: The GraphQL query at the field at `' +\n        parentFieldKey +\n        '` has a selection set, ' +\n        'but no key could be generated for the data at this field.\\n' +\n        'You have to request `id` or `_id` fields for all selection sets or create ' +\n        'a custom `keys` config for `' +\n        typename +\n        '`.\\n' +\n        'Entities without keys will be embedded directly on the parent entity. ' +\n        'If this is intentional, create a `keys` config for `' +\n        typename +\n        '` that always returns null.',\n      15\n    );\n  }\n\n  writeSelection(ctx, key, select, data);\n  return key;\n};\n\n// This is like writeSelection but assumes no parent entity exists\nconst writeRoot = (\n  ctx: Context,\n  typename: string,\n  select: SelectionSet,\n  data: Data\n) => {\n  const isRootField =\n    typename === ctx.store.getRootKey('mutation') ||\n    typename === ctx.store.getRootKey('subscription');\n\n  const iter = new SelectionIterator(typename, typename, select, ctx);\n\n  let node: FieldNode | void;\n  while ((node = iter.next()) !== undefined) {\n    const fieldName = getName(node);\n    const fieldArgs = getFieldArguments(node, ctx.variables);\n    const fieldKey = joinKeys(typename, keyOfField(fieldName, fieldArgs));\n    if (node.selectionSet !== undefined) {\n      const fieldValue = ensureData(data[getFieldAlias(node)]);\n      writeRootField(ctx, fieldValue, getSelectionSet(node));\n    }\n\n    if (isRootField) {\n      // We have to update the context to reflect up-to-date ResolveInfo\n      ctx.parentTypeName = typename;\n      ctx.parentKey = typename;\n      ctx.parentFieldKey = fieldKey;\n      ctx.fieldName = fieldName;\n\n      // We run side-effect updates after the default, normalized updates\n      // so that the data is already available in-store if necessary\n      const updater = ctx.store.updates[typename][fieldName];\n      if (updater !== undefined) {\n        updater(data, fieldArgs || makeDict(), ctx.store, ctx);\n      }\n    }\n  }\n};\n\n// This is like writeField but doesn't fall back to a generated key\nconst writeRootField = (\n  ctx: Context,\n  data: null | Data | NullArray<Data>,\n  select: SelectionSet\n) => {\n  if (Array.isArray(data)) {\n    const newData = new Array(data.length);\n    for (let i = 0, l = data.length; i < l; i++)\n      newData[i] = writeRootField(ctx, data[i], select);\n    return newData;\n  } else if (data === null) {\n    return;\n  }\n\n  // Write entity to key that falls back to the given parentFieldKey\n  const entityKey = ctx.store.keyOfEntity(data);\n  if (entityKey !== null) {\n    writeSelection(ctx, entityKey, select, data);\n  } else {\n    const typename = data.__typename;\n    writeRoot(ctx, typename, select, data);\n  }\n};\n","import { DocumentNode } from 'graphql';\nimport { createRequest } from 'urql/core';\n\nimport {\n  Cache,\n  FieldInfo,\n  ResolverConfig,\n  DataField,\n  Variables,\n  Data,\n  QueryInput,\n  UpdatesConfig,\n  OptimisticMutationConfig,\n  KeyingConfig,\n} from '../types';\n\nimport { read, readFragment } from '../operations/query';\nimport { writeFragment, startWrite } from '../operations/write';\nimport { invalidate } from '../operations/invalidate';\nimport { SchemaPredicates } from '../ast';\nimport { keyOfField } from './keys';\nimport * as InMemoryData from './data';\n\ntype RootField = 'query' | 'mutation' | 'subscription';\n\nexport class Store implements Cache {\n  data: InMemoryData.InMemoryData;\n\n  resolvers: ResolverConfig;\n  updates: UpdatesConfig;\n  optimisticMutations: OptimisticMutationConfig;\n  keys: KeyingConfig;\n  schemaPredicates?: SchemaPredicates;\n\n  rootFields: { query: string; mutation: string; subscription: string };\n  rootNames: { [name: string]: RootField };\n\n  constructor(\n    schemaPredicates?: SchemaPredicates,\n    resolvers?: ResolverConfig,\n    updates?: Partial<UpdatesConfig>,\n    optimisticMutations?: OptimisticMutationConfig,\n    keys?: KeyingConfig\n  ) {\n    this.resolvers = resolvers || {};\n    this.optimisticMutations = optimisticMutations || {};\n    this.keys = keys || {};\n    this.schemaPredicates = schemaPredicates;\n\n    this.updates = {\n      Mutation: (updates && updates.Mutation) || {},\n      Subscription: (updates && updates.Subscription) || {},\n    } as UpdatesConfig;\n\n    if (schemaPredicates) {\n      const { schema } = schemaPredicates;\n      const queryType = schema.getQueryType();\n      const mutationType = schema.getMutationType();\n      const subscriptionType = schema.getSubscriptionType();\n\n      const queryName = queryType ? queryType.name : 'Query';\n      const mutationName = mutationType ? mutationType.name : 'Mutation';\n      const subscriptionName = subscriptionType\n        ? subscriptionType.name\n        : 'Subscription';\n\n      this.rootFields = {\n        query: queryName,\n        mutation: mutationName,\n        subscription: subscriptionName,\n      };\n\n      this.rootNames = {\n        [queryName]: 'query',\n        [mutationName]: 'mutation',\n        [subscriptionName]: 'subscription',\n      };\n    } else {\n      this.rootFields = {\n        query: 'Query',\n        mutation: 'Mutation',\n        subscription: 'Subscription',\n      };\n\n      this.rootNames = {\n        Query: 'query',\n        Mutation: 'mutation',\n        Subscription: 'subscription',\n      };\n    }\n\n    this.data = InMemoryData.make(this.getRootKey('query'));\n  }\n\n  gcScheduled = false;\n  gc = () => {\n    InMemoryData.gc(this.data);\n    this.gcScheduled = false;\n  };\n\n  keyOfField = keyOfField;\n\n  getRootKey(name: RootField) {\n    return this.rootFields[name];\n  }\n\n  keyOfEntity(data: Data) {\n    const { __typename: typename, id, _id } = data;\n    if (!typename) {\n      return null;\n    } else if (this.rootNames[typename] !== undefined) {\n      return typename;\n    }\n\n    let key: string | null | void;\n    if (this.keys[typename]) {\n      key = this.keys[typename](data);\n    } else if (id !== undefined && id !== null) {\n      key = `${id}`;\n    } else if (_id !== undefined && _id !== null) {\n      key = `${_id}`;\n    }\n\n    return key ? `${typename}:${key}` : null;\n  }\n\n  resolveFieldByKey(entity: Data | string | null, fieldKey: string): DataField {\n    const entityKey =\n      entity !== null && typeof entity !== 'string'\n        ? this.keyOfEntity(entity)\n        : entity;\n    if (entityKey === null) return null;\n    const fieldValue = InMemoryData.readRecord(entityKey, fieldKey);\n    if (fieldValue !== undefined) return fieldValue;\n    const link = InMemoryData.readLink(entityKey, fieldKey);\n    return link ? link : null;\n  }\n\n  resolve(\n    entity: Data | string | null,\n    field: string,\n    args?: Variables\n  ): DataField {\n    return this.resolveFieldByKey(entity, keyOfField(field, args));\n  }\n\n  invalidateQuery(query: string | DocumentNode, variables?: Variables) {\n    invalidate(this, createRequest(query, variables));\n  }\n\n  inspectFields(entity: Data | string | null): FieldInfo[] {\n    const entityKey =\n      entity !== null && typeof entity !== 'string'\n        ? this.keyOfEntity(entity)\n        : entity;\n    return entityKey !== null ? InMemoryData.inspectFields(entityKey) : [];\n  }\n\n  updateQuery(\n    input: QueryInput,\n    updater: (data: Data | null) => Data | null\n  ): void {\n    const request = createRequest(input.query, input.variables);\n    const output = updater(this.readQuery(request as QueryInput));\n    if (output !== null) {\n      startWrite(this, request, output);\n    }\n  }\n\n  readQuery(input: QueryInput): Data | null {\n    return read(this, createRequest(input.query, input.variables)).data;\n  }\n\n  readFragment(\n    dataFragment: DocumentNode,\n    entity: string | Data,\n    variables?: Variables\n  ): Data | null {\n    return readFragment(this, dataFragment, entity, variables);\n  }\n\n  writeFragment(\n    dataFragment: DocumentNode,\n    data: Data,\n    variables?: Variables\n  ): void {\n    writeFragment(this, dataFragment, data, variables);\n  }\n}\n","import { FieldNode } from 'graphql';\n\nimport {\n  getMainOperation,\n  normalizeVariables,\n  getFragments,\n  getSelectionSet,\n  getName,\n  getFieldArguments,\n} from '../ast';\n\nimport {\n  EntityField,\n  OperationRequest,\n  Variables,\n  Fragments,\n  SelectionSet,\n} from '../types';\n\nimport * as InMemoryData from '../store/data';\nimport { Store, keyOfField } from '../store';\nimport { SchemaPredicates } from '../ast';\nimport { SelectionIterator } from './shared';\n\ninterface Context {\n  store: Store;\n  variables: Variables;\n  fragments: Fragments;\n  schemaPredicates?: SchemaPredicates;\n}\n\nexport const invalidate = (store: Store, request: OperationRequest) => {\n  const operation = getMainOperation(request.query);\n\n  const ctx: Context = {\n    variables: normalizeVariables(operation, request.variables),\n    fragments: getFragments(request.query),\n    store,\n    schemaPredicates: store.schemaPredicates,\n  };\n\n  invalidateSelection(\n    ctx,\n    ctx.store.getRootKey('query'),\n    getSelectionSet(operation)\n  );\n};\n\nexport const invalidateSelection = (\n  ctx: Context,\n  entityKey: string,\n  select: SelectionSet\n) => {\n  const isQuery = entityKey === 'Query';\n\n  let typename: EntityField;\n  if (!isQuery) {\n    typename = InMemoryData.readRecord(entityKey, '__typename');\n    if (typeof typename !== 'string') {\n      return;\n    } else {\n      InMemoryData.writeRecord(entityKey, '__typename', undefined);\n    }\n  } else {\n    typename = entityKey;\n  }\n\n  const iter = new SelectionIterator(typename, entityKey, select, ctx);\n\n  let node: FieldNode | void;\n  while ((node = iter.next()) !== undefined) {\n    const fieldName = getName(node);\n    const fieldKey = keyOfField(\n      fieldName,\n      getFieldArguments(node, ctx.variables)\n    );\n\n    if (\n      process.env.NODE_ENV !== 'production' &&\n      ctx.schemaPredicates &&\n      typename\n    ) {\n      ctx.schemaPredicates.isFieldAvailableOnType(typename, fieldName);\n    }\n\n    if (node.selectionSet === undefined) {\n      InMemoryData.writeRecord(entityKey, fieldKey, undefined);\n    } else {\n      const fieldSelect = getSelectionSet(node);\n      const link = InMemoryData.readLink(entityKey, fieldKey);\n\n      InMemoryData.writeLink(entityKey, fieldKey, undefined);\n      InMemoryData.writeRecord(entityKey, fieldKey, undefined);\n\n      if (Array.isArray(link)) {\n        for (let i = 0, l = link.length; i < l; i++) {\n          const childLink = link[i];\n          if (childLink !== null) {\n            invalidateSelection(ctx, childLink, fieldSelect);\n          }\n        }\n      } else if (link) {\n        invalidateSelection(ctx, link, fieldSelect);\n      }\n    }\n  }\n};\n","import { FieldNode, DocumentNode, FragmentDefinitionNode } from 'graphql';\n\nimport {\n  getFragments,\n  getMainOperation,\n  getSelectionSet,\n  normalizeVariables,\n  getName,\n  getFieldArguments,\n  getFieldAlias,\n  getFragmentTypeName,\n} from '../ast';\n\nimport {\n  Fragments,\n  Variables,\n  Data,\n  DataField,\n  Link,\n  SelectionSet,\n  OperationRequest,\n  NullArray,\n} from '../types';\n\nimport {\n  Store,\n  getCurrentDependencies,\n  initDataState,\n  clearDataState,\n  makeDict,\n  joinKeys,\n  keyOfField,\n} from '../store';\n\nimport * as InMemoryData from '../store/data';\nimport { warn, pushDebugNode } from '../helpers/help';\nimport { SelectionIterator, ensureData } from './shared';\nimport { SchemaPredicates } from '../ast';\n\nexport interface QueryResult {\n  dependencies: Set<string>;\n  partial: boolean;\n  data: null | Data;\n}\n\ninterface Context {\n  parentTypeName: string;\n  parentKey: string;\n  parentFieldKey: string;\n  fieldName: string;\n  partial: boolean;\n  store: Store;\n  variables: Variables;\n  fragments: Fragments;\n  schemaPredicates?: SchemaPredicates;\n}\n\nexport const query = (\n  store: Store,\n  request: OperationRequest,\n  data?: Data\n): QueryResult => {\n  initDataState(store.data, 0);\n  const result = read(store, request, data);\n  clearDataState();\n  return result;\n};\n\nexport const read = (\n  store: Store,\n  request: OperationRequest,\n  input?: Data\n): QueryResult => {\n  const operation = getMainOperation(request.query);\n  const rootKey = store.getRootKey(operation.operation);\n  const rootSelect = getSelectionSet(operation);\n\n  const ctx: Context = {\n    parentTypeName: rootKey,\n    parentKey: rootKey,\n    parentFieldKey: '',\n    fieldName: '',\n    variables: normalizeVariables(operation, request.variables),\n    fragments: getFragments(request.query),\n    partial: false,\n    store,\n    schemaPredicates: store.schemaPredicates,\n  };\n\n  if (process.env.NODE_ENV !== 'production') {\n    pushDebugNode(rootKey, operation);\n  }\n\n  let data = input || makeDict();\n  data =\n    rootKey !== ctx.store.getRootKey('query')\n      ? readRoot(ctx, rootKey, rootSelect, data)\n      : readSelection(ctx, rootKey, rootSelect, data);\n\n  return {\n    dependencies: getCurrentDependencies(),\n    partial: data === undefined ? false : ctx.partial,\n    data: data === undefined ? null : data,\n  };\n};\n\nconst readRoot = (\n  ctx: Context,\n  entityKey: string,\n  select: SelectionSet,\n  originalData: Data\n): Data => {\n  if (typeof originalData.__typename !== 'string') {\n    return originalData;\n  }\n\n  const iter = new SelectionIterator(entityKey, entityKey, select, ctx);\n  const data = makeDict();\n  data.__typename = originalData.__typename;\n\n  let node: FieldNode | void;\n  while ((node = iter.next()) !== undefined) {\n    const fieldAlias = getFieldAlias(node);\n    const fieldValue = originalData[fieldAlias];\n    if (node.selectionSet !== undefined && fieldValue !== null) {\n      const fieldData = ensureData(fieldValue);\n      data[fieldAlias] = readRootField(ctx, getSelectionSet(node), fieldData);\n    } else {\n      data[fieldAlias] = fieldValue;\n    }\n  }\n\n  return data;\n};\n\nconst readRootField = (\n  ctx: Context,\n  select: SelectionSet,\n  originalData: null | Data | NullArray<Data>\n): Data | NullArray<Data> | null => {\n  if (Array.isArray(originalData)) {\n    const newData = new Array(originalData.length);\n    for (let i = 0, l = originalData.length; i < l; i++)\n      newData[i] = readRootField(ctx, select, originalData[i]);\n    return newData;\n  } else if (originalData === null) {\n    return null;\n  }\n\n  // Write entity to key that falls back to the given parentFieldKey\n  const entityKey = ctx.store.keyOfEntity(originalData);\n  if (entityKey !== null) {\n    // We assume that since this is used for result data this can never be undefined,\n    // since the result data has already been written to the cache\n    const fieldValue = readSelection(ctx, entityKey, select, makeDict());\n    return fieldValue === undefined ? null : fieldValue;\n  } else {\n    return readRoot(ctx, originalData.__typename, select, originalData);\n  }\n};\n\nexport const readFragment = (\n  store: Store,\n  query: DocumentNode,\n  entity: Data | string,\n  variables?: Variables\n): Data | null => {\n  const fragments = getFragments(query);\n  const names = Object.keys(fragments);\n  const fragment = fragments[names[0]] as FragmentDefinitionNode;\n  if (fragment === undefined) {\n    warn(\n      'readFragment(...) was called with an empty fragment.\\n' +\n        'You have to call it with at least one fragment in your GraphQL document.',\n      6\n    );\n\n    return null;\n  }\n\n  const typename = getFragmentTypeName(fragment);\n  if (typeof entity !== 'string' && !entity.__typename) {\n    entity.__typename = typename;\n  }\n\n  const entityKey =\n    typeof entity !== 'string'\n      ? store.keyOfEntity({ __typename: typename, ...entity } as Data)\n      : entity;\n\n  if (!entityKey) {\n    warn(\n      \"Can't generate a key for readFragment(...).\\n\" +\n        'You have to pass an `id` or `_id` field or create a custom `keys` config for `' +\n        typename +\n        '`.',\n      7\n    );\n\n    return null;\n  }\n\n  if (process.env.NODE_ENV !== 'production') {\n    pushDebugNode(typename, fragment);\n  }\n\n  const ctx: Context = {\n    parentTypeName: typename,\n    parentKey: entityKey,\n    parentFieldKey: '',\n    fieldName: '',\n    variables: variables || {},\n    fragments,\n    partial: false,\n    store,\n    schemaPredicates: store.schemaPredicates,\n  };\n\n  return (\n    readSelection(ctx, entityKey, getSelectionSet(fragment), makeDict()) || null\n  );\n};\n\nconst readSelection = (\n  ctx: Context,\n  entityKey: string,\n  select: SelectionSet,\n  data: Data\n): Data | undefined => {\n  const { store, schemaPredicates } = ctx;\n  const isQuery = entityKey === store.getRootKey('query');\n\n  // Get the __typename field for a given entity to check that it exists\n  const typename = !isQuery\n    ? InMemoryData.readRecord(entityKey, '__typename')\n    : entityKey;\n  if (typeof typename !== 'string') {\n    return undefined;\n  }\n\n  data.__typename = typename;\n  const iter = new SelectionIterator(typename, entityKey, select, ctx);\n\n  let node: FieldNode | void;\n  let hasFields = false;\n  let hasPartials = false;\n  while ((node = iter.next()) !== undefined) {\n    // Derive the needed data from our node.\n    const fieldName = getName(node);\n    const fieldArgs = getFieldArguments(node, ctx.variables);\n    const fieldAlias = getFieldAlias(node);\n    const fieldKey = keyOfField(fieldName, fieldArgs);\n    const fieldValue = InMemoryData.readRecord(entityKey, fieldKey);\n    const key = joinKeys(entityKey, fieldKey);\n\n    if (process.env.NODE_ENV !== 'production' && schemaPredicates && typename) {\n      schemaPredicates.isFieldAvailableOnType(typename, fieldName);\n    }\n\n    // We temporarily store the data field in here, but undefined\n    // means that the value is missing from the cache\n    let dataFieldValue: void | DataField;\n\n    const resolvers = store.resolvers[typename];\n    if (resolvers !== undefined && typeof resolvers[fieldName] === 'function') {\n      // We have to update the information in context to reflect the info\n      // that the resolver will receive\n      ctx.parentTypeName = typename;\n      ctx.parentKey = entityKey;\n      ctx.parentFieldKey = key;\n      ctx.fieldName = fieldName;\n\n      // We have a resolver for this field.\n      // Prepare the actual fieldValue, so that the resolver can use it\n      if (fieldValue !== undefined) {\n        data[fieldAlias] = fieldValue;\n      }\n\n      dataFieldValue = resolvers[fieldName](\n        data,\n        fieldArgs || makeDict(),\n        store,\n        ctx\n      );\n\n      if (node.selectionSet !== undefined) {\n        // When it has a selection set we are resolving an entity with a\n        // subselection. This can either be a list or an object.\n        dataFieldValue = resolveResolverResult(\n          ctx,\n          typename,\n          fieldName,\n          key,\n          getSelectionSet(node),\n          (data[fieldAlias] as Data) || makeDict(),\n          dataFieldValue\n        );\n      }\n\n      if (\n        schemaPredicates !== undefined &&\n        dataFieldValue === null &&\n        !schemaPredicates.isFieldNullable(typename, fieldName)\n      ) {\n        // Special case for when null is not a valid value for the\n        // current field\n        return undefined;\n      }\n    } else if (node.selectionSet === undefined) {\n      // The field is a scalar and can be retrieved directly\n      dataFieldValue = fieldValue;\n    } else {\n      // We have a selection set which means that we'll be checking for links\n      const link = InMemoryData.readLink(entityKey, fieldKey);\n      if (link !== undefined) {\n        dataFieldValue = resolveLink(\n          ctx,\n          link,\n          typename,\n          fieldName,\n          getSelectionSet(node),\n          data[fieldAlias] as Data\n        );\n      } else if (typeof fieldValue === 'object' && fieldValue !== null) {\n        // The entity on the field was invalid but can still be recovered\n        dataFieldValue = fieldValue;\n      }\n    }\n\n    // Now that dataFieldValue has been retrieved it'll be set on data\n    // If it's uncached (undefined) but nullable we can continue assembling\n    // a partial query result\n    if (\n      dataFieldValue === undefined &&\n      schemaPredicates !== undefined &&\n      schemaPredicates.isFieldNullable(typename, fieldName)\n    ) {\n      // The field is uncached but we have a schema that says it's nullable\n      // Set the field to null and continue\n      hasPartials = true;\n      data[fieldAlias] = null;\n    } else if (dataFieldValue === undefined) {\n      // The field is uncached and not nullable; return undefined\n      return undefined;\n    } else {\n      // Otherwise continue as usual\n      hasFields = true;\n      data[fieldAlias] = dataFieldValue;\n    }\n  }\n\n  if (hasPartials) ctx.partial = true;\n  return isQuery && hasPartials && !hasFields ? undefined : data;\n};\n\nconst readResolverResult = (\n  ctx: Context,\n  key: string,\n  select: SelectionSet,\n  data: Data,\n  result: Data\n): Data | undefined => {\n  const { store, schemaPredicates } = ctx;\n  const entityKey = store.keyOfEntity(result) || key;\n  const resolvedTypename = result.__typename;\n  const typename =\n    InMemoryData.readRecord(entityKey, '__typename') || resolvedTypename;\n\n  if (\n    typeof typename !== 'string' ||\n    (resolvedTypename && typename !== resolvedTypename)\n  ) {\n    // TODO: This may be an invalid error for resolvers that return interfaces\n    warn(\n      'Invalid resolver data: The resolver at `' +\n        entityKey +\n        '` returned an ' +\n        'invalid typename that could not be reconciled with the cache.',\n      8\n    );\n\n    return undefined;\n  }\n\n  // The following closely mirrors readSelection, but differs only slightly for the\n  // sake of resolving from an existing resolver result\n  data.__typename = typename;\n  const iter = new SelectionIterator(typename, entityKey, select, ctx);\n\n  let node: FieldNode | void;\n  let hasFields = false;\n  let hasPartials = false;\n  while ((node = iter.next()) !== undefined) {\n    // Derive the needed data from our node.\n    const fieldName = getName(node);\n    const fieldAlias = getFieldAlias(node);\n    const fieldKey = keyOfField(\n      fieldName,\n      getFieldArguments(node, ctx.variables)\n    );\n    const key = joinKeys(entityKey, fieldKey);\n    const fieldValue = InMemoryData.readRecord(entityKey, fieldKey);\n    const resultValue = result[fieldName];\n\n    if (process.env.NODE_ENV !== 'production' && schemaPredicates && typename) {\n      schemaPredicates.isFieldAvailableOnType(typename, fieldName);\n    }\n\n    // We temporarily store the data field in here, but undefined\n    // means that the value is missing from the cache\n    let dataFieldValue: void | DataField;\n    if (resultValue !== undefined && node.selectionSet === undefined) {\n      // The field is a scalar and can be retrieved directly from the result\n      dataFieldValue = resultValue;\n    } else if (node.selectionSet === undefined) {\n      // The field is a scalar but isn't on the result, so it's retrieved from the cache\n      dataFieldValue = fieldValue;\n    } else if (resultValue !== undefined) {\n      // We start walking the nested resolver result here\n      dataFieldValue = resolveResolverResult(\n        ctx,\n        typename,\n        fieldName,\n        key,\n        getSelectionSet(node),\n        data[fieldAlias] as Data,\n        resultValue\n      );\n    } else {\n      // Otherwise we attempt to get the missing field from the cache\n      const link = InMemoryData.readLink(entityKey, fieldKey);\n\n      if (link !== undefined) {\n        dataFieldValue = resolveLink(\n          ctx,\n          link,\n          typename,\n          fieldName,\n          getSelectionSet(node),\n          data[fieldAlias] as Data\n        );\n      } else if (typeof fieldValue === 'object' && fieldValue !== null) {\n        // The entity on the field was invalid but can still be recovered\n        dataFieldValue = fieldValue;\n      }\n    }\n\n    // Now that dataFieldValue has been retrieved it'll be set on data\n    // If it's uncached (undefined) but nullable we can continue assembling\n    // a partial query result\n    if (\n      dataFieldValue === undefined &&\n      schemaPredicates !== undefined &&\n      schemaPredicates.isFieldNullable(typename, fieldName)\n    ) {\n      // The field is uncached but we have a schema that says it's nullable\n      // Set the field to null and continue\n      hasPartials = true;\n      data[fieldAlias] = null;\n    } else if (dataFieldValue === undefined) {\n      // The field is uncached and not nullable; return undefined\n      return undefined;\n    } else {\n      // Otherwise continue as usual\n      hasFields = true;\n      data[fieldAlias] = dataFieldValue;\n    }\n  }\n\n  if (hasPartials) ctx.partial = true;\n  return !hasFields ? undefined : data;\n};\n\nconst resolveResolverResult = (\n  ctx: Context,\n  typename: string,\n  fieldName: string,\n  key: string,\n  select: SelectionSet,\n  prevData: void | Data | Data[],\n  result: void | DataField\n): DataField | void => {\n  if (Array.isArray(result)) {\n    const { schemaPredicates } = ctx;\n    // Check whether values of the list may be null; for resolvers we assume\n    // that they can be, since it's user-provided data\n    const isListNullable =\n      schemaPredicates === undefined ||\n      schemaPredicates.isListNullable(typename, fieldName);\n    const data = new Array(result.length);\n    for (let i = 0, l = result.length; i < l; i++) {\n      // Recursively read resolver result\n      const childResult = resolveResolverResult(\n        ctx,\n        typename,\n        fieldName,\n        joinKeys(key, `${i}`),\n        select,\n        // Get the inner previous data from prevData\n        prevData !== undefined ? prevData[i] : undefined,\n        result[i]\n      );\n\n      if (childResult === undefined && !isListNullable) {\n        return undefined;\n      } else {\n        data[i] = childResult !== undefined ? childResult : null;\n      }\n    }\n\n    return data;\n  } else if (result === null || result === undefined) {\n    return result;\n  } else if (isDataOrKey(result)) {\n    const data = prevData === undefined ? makeDict() : prevData;\n    return typeof result === 'string'\n      ? readSelection(ctx, result, select, data)\n      : readResolverResult(ctx, key, select, data, result);\n  } else {\n    warn(\n      'Invalid resolver value: The field at `' +\n        key +\n        '` is a scalar (number, boolean, etc)' +\n        ', but the GraphQL query expects a selection set for this field.',\n      9\n    );\n\n    return undefined;\n  }\n};\n\nconst resolveLink = (\n  ctx: Context,\n  link: Link | Link[],\n  typename: string,\n  fieldName: string,\n  select: SelectionSet,\n  prevData: void | Data | Data[]\n): DataField | undefined => {\n  if (Array.isArray(link)) {\n    const { schemaPredicates } = ctx;\n    const isListNullable =\n      schemaPredicates !== undefined &&\n      schemaPredicates.isListNullable(typename, fieldName);\n    const newLink = new Array(link.length);\n    for (let i = 0, l = link.length; i < l; i++) {\n      const childLink = resolveLink(\n        ctx,\n        link[i],\n        typename,\n        fieldName,\n        select,\n        prevData !== undefined ? prevData[i] : undefined\n      );\n      if (childLink === undefined && !isListNullable) {\n        return undefined;\n      } else {\n        newLink[i] = childLink !== undefined ? childLink : null;\n      }\n    }\n\n    return newLink;\n  } else if (link === null) {\n    return null;\n  } else {\n    return readSelection(\n      ctx,\n      link,\n      select,\n      prevData === undefined ? makeDict() : prevData\n    );\n  }\n};\n\nconst isDataOrKey = (x: any): x is string | Data =>\n  typeof x === 'string' ||\n  (typeof x === 'object' && typeof (x as any).__typename === 'string');\n","import {\n  FieldNode,\n  OperationDefinitionNode,\n  valueFromASTUntyped,\n} from 'graphql';\n\nimport { getName } from './node';\nimport { makeDict } from '../store';\nimport { Variables } from '../types';\n\n/** Evaluates a fields arguments taking vars into account */\nexport const getFieldArguments = (\n  node: FieldNode,\n  vars: Variables\n): null | Variables => {\n  if (node.arguments === undefined || node.arguments.length === 0) {\n    return null;\n  }\n\n  const args = makeDict();\n  let argsSize = 0;\n\n  for (let i = 0, l = node.arguments.length; i < l; i++) {\n    const arg = node.arguments[i];\n    const value = valueFromASTUntyped(arg.value, vars);\n    if (value !== undefined && value !== null) {\n      args[getName(arg)] = value;\n      argsSize++;\n    }\n  }\n\n  return argsSize > 0 ? args : null;\n};\n\n/** Returns a normalized form of variables with defaulted values */\nexport const normalizeVariables = (\n  node: OperationDefinitionNode,\n  input: void | object\n): Variables => {\n  if (node.variableDefinitions === undefined) {\n    return {};\n  }\n\n  const args: Variables = (input as Variables) || {};\n\n  return node.variableDefinitions.reduce((vars, def) => {\n    const name = getName(def.variable);\n    let value = args[name];\n    if (value === undefined) {\n      if (def.defaultValue !== undefined) {\n        value = valueFromASTUntyped(def.defaultValue, args);\n      } else {\n        return vars;\n      }\n    }\n\n    vars[name] = value;\n    return vars;\n  }, makeDict());\n};\n","import {\n  buildClientSchema,\n  isNullableType,\n  isListType,\n  isNonNullType,\n  GraphQLSchema,\n  GraphQLAbstractType,\n  GraphQLObjectType,\n  GraphQLInterfaceType,\n  GraphQLUnionType,\n} from 'graphql';\n\nimport { invariant, warn } from '../helpers/help';\n\nexport class SchemaPredicates {\n  schema: GraphQLSchema;\n\n  constructor(schema: object) {\n    this.schema = buildClientSchema(schema as any);\n  }\n\n  isFieldNullable(typename: string, fieldName: string): boolean {\n    const field = getField(this.schema, typename, fieldName);\n    if (field === undefined) return false;\n    return isNullableType(field.type);\n  }\n\n  isListNullable(typename: string, fieldName: string): boolean {\n    const field = getField(this.schema, typename, fieldName);\n    if (field === undefined) return false;\n    const ofType = isNonNullType(field.type) ? field.type.ofType : field.type;\n    return isListType(ofType) && isNullableType(ofType.ofType);\n  }\n\n  isFieldAvailableOnType(typename: string, fieldname: string): boolean {\n    return !!getField(this.schema, typename, fieldname);\n  }\n\n  isInterfaceOfType(\n    typeCondition: null | string,\n    typename: string | void\n  ): boolean {\n    if (!typename || !typeCondition) return false;\n    if (typename === typeCondition) return true;\n\n    const abstractType = this.schema.getType(typeCondition);\n    const objectType = this.schema.getType(typename);\n\n    if (abstractType instanceof GraphQLObjectType) {\n      return abstractType === objectType;\n    }\n\n    expectAbstractType(abstractType, typeCondition);\n    expectObjectType(objectType, typename);\n    return this.schema.isPossibleType(abstractType, objectType);\n  }\n}\n\nconst getField = (\n  schema: GraphQLSchema,\n  typename: string,\n  fieldName: string\n) => {\n  const object = schema.getType(typename);\n  expectObjectType(object, typename);\n\n  const field = object.getFields()[fieldName];\n  if (field === undefined) {\n    warn(\n      'Invalid field: The field `' +\n        fieldName +\n        '` does not exist on `' +\n        typename +\n        '`, ' +\n        'but the GraphQL document expects it to exist.\\n' +\n        'Traversal will continue, however this may lead to undefined behavior!',\n      4\n    );\n\n    return undefined;\n  }\n\n  return field;\n};\n\nfunction expectObjectType(x: any, typename: string): asserts x is GraphQLObjectType {\n  invariant(\n    x instanceof GraphQLObjectType,\n    'Invalid Object type: The type `' +\n      typename +\n      '` is not an object in the defined schema, ' +\n      'but the GraphQL document is traversing it.',\n    3\n  );\n}\n\nfunction expectAbstractType(x: any, typename: string): asserts x is GraphQLAbstractType {\n  invariant(\n    x instanceof GraphQLInterfaceType || x instanceof GraphQLUnionType,\n    'Invalid Abstract type: The type `' +\n      typename +\n      '` is not an Interface or Union type in the defined schema, ' +\n      'but a fragment in the GraphQL document is using it as a type condition.',\n    5\n  );\n}\n","import { IntrospectionQuery } from 'graphql';\n\nimport {\n  Exchange,\n  formatDocument,\n  Operation,\n  OperationResult,\n  RequestPolicy,\n  CacheOutcome,\n} from 'urql/core';\n\nimport {\n  filter,\n  map,\n  merge,\n  pipe,\n  share,\n  tap,\n  fromPromise,\n  fromArray,\n  buffer,\n  take,\n  mergeMap,\n  concat,\n  empty,\n  Source,\n} from 'wonka';\n\nimport { query, write, writeOptimistic } from './operations';\nimport { SchemaPredicates } from './ast';\nimport { hydrateData } from './store/data';\nimport { makeDict, Store, clearOptimistic } from './store';\n\nimport {\n  UpdatesConfig,\n  ResolverConfig,\n  OptimisticMutationConfig,\n  KeyingConfig,\n  StorageAdapter,\n} from './types';\n\ntype OperationResultWithMeta = OperationResult & {\n  outcome: CacheOutcome;\n};\n\ntype OperationMap = Map<number, Operation>;\n\ninterface DependentOperations {\n  [key: string]: number[];\n}\n\n// Returns the given operation result with added cacheOutcome meta field\nconst addCacheOutcome = (op: Operation, outcome: CacheOutcome): Operation => ({\n  ...op,\n  context: {\n    ...op.context,\n    meta: {\n      ...op.context.meta,\n      cacheOutcome: outcome,\n    },\n  },\n});\n\n// Returns the given operation with added __typename fields on its query\nconst addTypeNames = (op: Operation): Operation => ({\n  ...op,\n  query: formatDocument(op.query),\n});\n\n// Retrieves the requestPolicy from an operation\nconst getRequestPolicy = (op: Operation) => op.context.requestPolicy;\n\n// Returns whether an operation is a query\nconst isQueryOperation = (op: Operation): boolean =>\n  op.operationName === 'query';\n\n// Returns whether an operation is a mutation\nconst isMutationOperation = (op: Operation): boolean =>\n  op.operationName === 'mutation';\n\n// Returns whether an operation can potentially be read from cache\nconst isCacheableQuery = (op: Operation): boolean => {\n  return isQueryOperation(op) && getRequestPolicy(op) !== 'network-only';\n};\n\n// Returns whether an operation potentially triggers an optimistic update\nconst isOptimisticMutation = (op: Operation): boolean => {\n  return isMutationOperation(op) && getRequestPolicy(op) !== 'network-only';\n};\n\n// Copy an operation and change the requestPolicy to skip the cache\nconst toRequestPolicy = (\n  operation: Operation,\n  requestPolicy: RequestPolicy\n): Operation => ({\n  ...operation,\n  context: {\n    ...operation.context,\n    requestPolicy,\n  },\n});\n\nexport interface CacheExchangeOpts {\n  updates?: Partial<UpdatesConfig>;\n  resolvers?: ResolverConfig;\n  optimistic?: OptimisticMutationConfig;\n  keys?: KeyingConfig;\n  schema?: IntrospectionQuery;\n  storage?: StorageAdapter;\n}\n\nexport const cacheExchange = (opts?: CacheExchangeOpts): Exchange => ({\n  forward,\n  client,\n}) => {\n  if (!opts) opts = {};\n\n  const store = new Store(\n    opts.schema ? new SchemaPredicates(opts.schema) : undefined,\n    opts.resolvers,\n    opts.updates,\n    opts.optimistic,\n    opts.keys\n  );\n\n  let hydration: void | Promise<void>;\n  if (opts.storage) {\n    const storage = opts.storage;\n    hydration = storage.read().then(entries => {\n      hydrateData(store.data, storage, entries);\n    });\n  }\n\n  const optimisticKeys = new Set();\n  const ops: OperationMap = new Map();\n  const deps: DependentOperations = makeDict();\n\n  const collectPendingOperations = (\n    pendingOperations: Set<number>,\n    dependencies: void | Set<string>\n  ) => {\n    if (dependencies !== undefined) {\n      // Collect operations that will be updated due to cache changes\n      dependencies.forEach(dep => {\n        const keys = deps[dep];\n        if (keys !== undefined) {\n          deps[dep] = [];\n          for (let i = 0, l = keys.length; i < l; i++) {\n            pendingOperations.add(keys[i]);\n          }\n        }\n      });\n    }\n  };\n\n  const executePendingOperations = (\n    operation: Operation,\n    pendingOperations: Set<number>\n  ) => {\n    // Reexecute collected operations and delete them from the mapping\n    pendingOperations.forEach(key => {\n      if (key !== operation.key) {\n        const op = ops.get(key);\n        if (op !== undefined) {\n          ops.delete(key);\n          client.reexecuteOperation(toRequestPolicy(op, 'cache-first'));\n        }\n      }\n    });\n  };\n\n  // This executes an optimistic update for mutations and registers it if necessary\n  const optimisticUpdate = (operation: Operation) => {\n    if (isOptimisticMutation(operation)) {\n      const { key } = operation;\n      const { dependencies } = writeOptimistic(store, operation, key);\n      if (dependencies.size !== 0) {\n        optimisticKeys.add(key);\n        const pendingOperations = new Set<number>();\n        collectPendingOperations(pendingOperations, dependencies);\n        executePendingOperations(operation, pendingOperations);\n      }\n    }\n  };\n\n  // This updates the known dependencies for the passed operation\n  const updateDependencies = (op: Operation, dependencies: Set<string>) => {\n    dependencies.forEach(dep => {\n      const keys = deps[dep] || (deps[dep] = []);\n      keys.push(op.key);\n\n      if (!ops.has(op.key)) {\n        ops.set(\n          op.key,\n          getRequestPolicy(op) === 'network-only'\n            ? toRequestPolicy(op, 'cache-and-network')\n            : op\n        );\n      }\n    });\n  };\n\n  // Retrieves a query result from cache and adds an `isComplete` hint\n  // This hint indicates whether the result is \"complete\" or not\n  const operationResultFromCache = (\n    operation: Operation\n  ): OperationResultWithMeta => {\n    const { data, dependencies, partial } = query(store, operation);\n    let cacheOutcome: CacheOutcome;\n\n    if (data === null) {\n      cacheOutcome = 'miss';\n    } else {\n      updateDependencies(operation, dependencies);\n      cacheOutcome =\n        !partial || getRequestPolicy(operation) === 'cache-only'\n          ? 'hit'\n          : 'partial';\n    }\n\n    return {\n      outcome: cacheOutcome,\n      operation,\n      data,\n    };\n  };\n\n  // Take any OperationResult and update the cache with it\n  const updateCacheWithResult = (result: OperationResult): OperationResult => {\n    const { operation, error, extensions } = result;\n    const isQuery = isQueryOperation(operation);\n    let { data } = result;\n\n    // Clear old optimistic values from the store\n    const { key } = operation;\n    if (optimisticKeys.has(key)) {\n      optimisticKeys.delete(key);\n      clearOptimistic(store.data, key);\n    }\n\n    let writeDependencies: Set<string> | void;\n    let queryDependencies: Set<string> | void;\n    if (data !== null && data !== undefined) {\n      writeDependencies = write(store, operation, data).dependencies;\n\n      if (isQuery) {\n        const queryResult = query(store, operation);\n        data = queryResult.data;\n        queryDependencies = queryResult.dependencies;\n      } else {\n        data = query(store, operation, data).data;\n      }\n    }\n\n    // Collect all write dependencies and query dependencies for queries\n    const pendingOperations = new Set<number>();\n    collectPendingOperations(pendingOperations, writeDependencies);\n    if (isQuery) {\n      collectPendingOperations(pendingOperations, queryDependencies);\n    }\n\n    // Execute all pending operations related to changed dependencies\n    executePendingOperations(result.operation, pendingOperations);\n\n    // Update this operation's dependencies if it's a query\n    if (isQuery && queryDependencies !== undefined) {\n      updateDependencies(result.operation, queryDependencies);\n    }\n\n    return { data, error, extensions, operation };\n  };\n\n  return ops$ => {\n    const sharedOps$ = pipe(ops$, share);\n\n    // Buffer operations while waiting on hydration to finish\n    // If no hydration takes place we replace this stream with an empty one\n    const bufferedOps$ = hydration\n      ? pipe(\n          sharedOps$,\n          buffer(fromPromise(hydration)),\n          take(1),\n          mergeMap(fromArray)\n        )\n      : (empty as Source<Operation>);\n\n    const inputOps$ = pipe(\n      concat([bufferedOps$, sharedOps$]),\n      map(addTypeNames),\n      tap(optimisticUpdate),\n      share\n    );\n\n    // Filter by operations that are cacheable and attempt to query them from the cache\n    const cache$ = pipe(\n      inputOps$,\n      filter(op => isCacheableQuery(op)),\n      map(operationResultFromCache),\n      share\n    );\n\n    // Rebound operations that are incomplete, i.e. couldn't be queried just from the cache\n    const cacheOps$ = pipe(\n      cache$,\n      filter(res => res.outcome === 'miss'),\n      map(res => addCacheOutcome(res.operation, res.outcome))\n    );\n\n    // Resolve OperationResults that the cache was able to assemble completely and trigger\n    // a network request if the current operation's policy is cache-and-network\n    const cacheResult$ = pipe(\n      cache$,\n      filter(res => res.outcome !== 'miss'),\n      map(\n        (res: OperationResultWithMeta): OperationResult => {\n          const { operation, outcome } = res;\n          const policy = getRequestPolicy(operation);\n          const result: OperationResult = {\n            operation: addCacheOutcome(operation, outcome),\n            data: res.data,\n            error: res.error,\n            extensions: res.extensions,\n          };\n\n          if (\n            policy === 'cache-and-network' ||\n            (policy === 'cache-first' && outcome === 'partial')\n          ) {\n            result.stale = true;\n            client.reexecuteOperation(\n              toRequestPolicy(operation, 'network-only')\n            );\n          }\n\n          return result;\n        }\n      )\n    );\n\n    // Forward operations that aren't cacheable and rebound operations\n    // Also update the cache with any network results\n    const result$ = pipe(\n      forward(\n        merge([\n          pipe(\n            inputOps$,\n            filter(op => !isCacheableQuery(op))\n          ),\n          cacheOps$,\n        ])\n      ),\n      map(updateCacheWithResult)\n    );\n\n    return merge([result$, cacheResult$]);\n  };\n};\n","import {\n  DocumentNode,\n  buildClientSchema,\n  visitWithTypeInfo,\n  TypeInfo,\n  FragmentDefinitionNode,\n  GraphQLSchema,\n  IntrospectionQuery,\n  FragmentSpreadNode,\n  NameNode,\n  ASTNode,\n  isCompositeType,\n  isAbstractType,\n  Kind,\n  visit,\n} from 'graphql';\n\nimport { pipe, tap, map } from 'wonka';\nimport { Exchange, Operation } from 'urql/core';\n\nimport { getName, getSelectionSet, unwrapType } from './ast';\nimport { makeDict } from './store';\nimport { invariant, warn } from './helpers/help';\n\ninterface PopulateExchangeOpts {\n  schema: IntrospectionQuery;\n}\n\n/** An exchange for auto-populating mutations with a required response body. */\nexport const populateExchange = ({\n  schema: ogSchema,\n}: PopulateExchangeOpts): Exchange => ({ forward }) => {\n  const schema = buildClientSchema(ogSchema);\n  /** List of operation keys that have already been parsed. */\n  const parsedOperations = new Set<number>();\n  /** List of operation keys that have not been torn down. */\n  const activeOperations = new Set<number>();\n  /** Collection of fragments used by the user. */\n  const userFragments: UserFragmentMap = makeDict();\n  /** Collection of actively in use type fragments. */\n  const activeTypeFragments: TypeFragmentMap = makeDict();\n\n  /** Handle mutation and inject selections + fragments. */\n  const handleIncomingMutation = (op: Operation) => {\n    if (op.operationName !== 'mutation') {\n      return op;\n    }\n\n    const activeSelections: TypeFragmentMap = makeDict();\n    for (const name in activeTypeFragments) {\n      activeSelections[name] = activeTypeFragments[name].filter(s =>\n        activeOperations.has(s.key)\n      );\n    }\n\n    return {\n      ...op,\n      query: addFragmentsToQuery(\n        schema,\n        op.query,\n        activeSelections,\n        userFragments\n      ),\n    };\n  };\n\n  /** Handle query and extract fragments. */\n  const handleIncomingQuery = ({ key, operationName, query }: Operation) => {\n    if (operationName !== 'query') {\n      return;\n    }\n\n    activeOperations.add(key);\n    if (parsedOperations.has(key)) {\n      return;\n    }\n\n    parsedOperations.add(key);\n\n    const [extractedFragments, newFragments] = extractSelectionsFromQuery(\n      schema,\n      query\n    );\n\n    for (let i = 0, l = extractedFragments.length; i < l; i++) {\n      const fragment = extractedFragments[i];\n      userFragments[getName(fragment)] = fragment;\n    }\n\n    for (let i = 0, l = newFragments.length; i < l; i++) {\n      const fragment = newFragments[i];\n      const type = getName(fragment.typeCondition);\n      const current =\n        activeTypeFragments[type] || (activeTypeFragments[type] = []);\n\n      (fragment as any).name.value += current.length;\n      current.push({ key, fragment });\n    }\n  };\n\n  const handleIncomingTeardown = ({ key, operationName }: Operation) => {\n    if (operationName === 'teardown') {\n      activeOperations.delete(key);\n    }\n  };\n\n  return ops$ => {\n    return pipe(\n      ops$,\n      tap(handleIncomingQuery),\n      tap(handleIncomingTeardown),\n      map(handleIncomingMutation),\n      forward\n    );\n  };\n};\n\ntype UserFragmentMap<T extends string = string> = Record<\n  T,\n  FragmentDefinitionNode\n>;\n\ntype TypeFragmentMap<T extends string = string> = Record<T, TypeFragment[]>;\n\ninterface TypeFragment {\n  /** Operation key where selection set is being used. */\n  key: number;\n  /** Selection set. */\n  fragment: FragmentDefinitionNode;\n}\n\n/** Gets typed selection sets and fragments from query */\nexport const extractSelectionsFromQuery = (\n  schema: GraphQLSchema,\n  query: DocumentNode\n) => {\n  const extractedFragments: FragmentDefinitionNode[] = [];\n  const newFragments: FragmentDefinitionNode[] = [];\n  const typeInfo = new TypeInfo(schema);\n\n  visit(\n    query,\n    visitWithTypeInfo(typeInfo, {\n      Field: node => {\n        if (node.selectionSet) {\n          const type = getTypeName(typeInfo);\n          newFragments.push({\n            kind: Kind.FRAGMENT_DEFINITION,\n            typeCondition: {\n              kind: Kind.NAMED_TYPE,\n              name: nameNode(type),\n            },\n            name: nameNode(`${type}_PopulateFragment_`),\n            selectionSet: node.selectionSet,\n          });\n        }\n      },\n      FragmentDefinition: node => {\n        extractedFragments.push(node);\n      },\n    })\n  );\n\n  return [extractedFragments, newFragments];\n};\n\n/** Replaces populate decorator with fragment spreads + fragments. */\nexport const addFragmentsToQuery = (\n  schema: GraphQLSchema,\n  query: DocumentNode,\n  activeTypeFragments: TypeFragmentMap,\n  userFragments: UserFragmentMap\n) => {\n  const typeInfo = new TypeInfo(schema);\n\n  const requiredUserFragments: Record<\n    string,\n    FragmentDefinitionNode\n  > = makeDict();\n\n  const additionalFragments: Record<\n    string,\n    FragmentDefinitionNode\n  > = makeDict();\n\n  /** Fragments provided and used by the current query */\n  const existingFragmentsForQuery: Set<string> = new Set();\n\n  return visit(\n    query,\n    visitWithTypeInfo(typeInfo, {\n      Field: {\n        enter: node => {\n          if (!node.directives) {\n            return;\n          }\n\n          const directives = node.directives.filter(\n            d => getName(d) !== 'populate'\n          );\n          if (directives.length === node.directives.length) {\n            return;\n          }\n\n          const possibleTypes = getTypes(schema, typeInfo);\n          const newSelections = possibleTypes.reduce((p, possibleType) => {\n            const typeFrags = activeTypeFragments[possibleType.name];\n            if (!typeFrags) {\n              return p;\n            }\n\n            for (let i = 0, l = typeFrags.length; i < l; i++) {\n              const { fragment } = typeFrags[i];\n              const fragmentName = getName(fragment);\n              const usedFragments = getUsedFragments(fragment);\n\n              // Add used fragment for insertion at Document node\n              for (let j = 0, l = usedFragments.length; j < l; j++) {\n                const name = usedFragments[j];\n                if (!existingFragmentsForQuery.has(name)) {\n                  requiredUserFragments[name] = userFragments[name];\n                }\n              }\n\n              // Add fragment for insertion at Document node\n              additionalFragments[fragmentName] = fragment;\n\n              p.push({\n                kind: Kind.FRAGMENT_SPREAD,\n                name: nameNode(fragmentName),\n              });\n            }\n\n            return p;\n          }, [] as FragmentSpreadNode[]);\n\n          const existingSelections = getSelectionSet(node);\n\n          const selections =\n            existingSelections.length + newSelections.length !== 0\n              ? [...newSelections, ...existingSelections]\n              : [\n                  {\n                    kind: Kind.FIELD,\n                    name: nameNode('__typename'),\n                  },\n                ];\n\n          return {\n            ...node,\n            directives,\n            selectionSet: {\n              kind: Kind.SELECTION_SET,\n              selections,\n            },\n          };\n        },\n      },\n      Document: {\n        enter: node => {\n          node.definitions.reduce((set, definition) => {\n            if (definition.kind === 'FragmentDefinition') {\n              set.add(definition.name.value);\n            }\n            return set;\n          }, existingFragmentsForQuery);\n        },\n        leave: node => {\n          const definitions = [...node.definitions];\n          for (const key in additionalFragments)\n            definitions.push(additionalFragments[key]);\n          for (const key in requiredUserFragments)\n            definitions.push(requiredUserFragments[key]);\n          return { ...node, definitions };\n        },\n      },\n    })\n  );\n};\n\nconst nameNode = (value: string): NameNode => ({\n  kind: Kind.NAME,\n  value,\n});\n\n/** Get all possible types for node with TypeInfo. */\nconst getTypes = (schema: GraphQLSchema, typeInfo: TypeInfo) => {\n  const type = unwrapType(typeInfo.getType());\n  if (!isCompositeType(type)) {\n    warn(\n      'Invalid type: The type ` + type + ` is used with @populate but does not exist.',\n      17\n    );\n    return [];\n  }\n\n  return isAbstractType(type) ? schema.getPossibleTypes(type) : [type];\n};\n\n/** Get name of non-abstract type for adding to 'activeTypeFragments'. */\nconst getTypeName = (typeInfo: TypeInfo) => {\n  const type = unwrapType(typeInfo.getType());\n  invariant(\n    type && !isAbstractType(type),\n    'Invalid TypeInfo state: Found no flat schema type when one was expected.',\n    18\n  );\n\n  return type.toString();\n};\n\n/** Get fragment names referenced by node. */\nconst getUsedFragments = (node: ASTNode) => {\n  const names: string[] = [];\n\n  visit(node, {\n    FragmentSpread: f => {\n      names.push(getName(f));\n    },\n  });\n\n  return names;\n};\n"]},"metadata":{},"sourceType":"module"}